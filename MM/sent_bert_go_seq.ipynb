{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.layers import  GlobalAveragePooling1D, Input, Activation, MaxPooling1D, BatchNormalization, Dense, Dropout, Conv1D,GlobalMaxPooling1D\n",
    "from keras.layers import GRU,AveragePooling1D,CuDNNGRU\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model \n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "alphabet = np.array(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "                     'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y'])\n",
    "\n",
    "def label_sequence(line, MAX_SEQ_LEN, smi_ch_ind):\n",
    "\tX = np.zeros(MAX_SEQ_LEN)\n",
    "\n",
    "\tfor i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
    "\t\tX[i] = smi_ch_ind[ch]\n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "def letter_one_hot(aa):\n",
    "    one_hot = np.zeros(20)\n",
    "    for idx, letter in enumerate(alphabet):\n",
    "        if aa == letter:\n",
    "            one_hot[idx] = 1\n",
    "            return one_hot\n",
    "\n",
    "\n",
    "# Convert an entire protein to one-hot representation.\n",
    "def protein_one_hot(protein_sequence, MAX_SEQ_LEN):\n",
    "    #  Remove non-specific AA codes (very few are actually present in this dataset)\n",
    "    protein_sequence = protein_sequence.replace('B', '')\n",
    "    protein_sequence = protein_sequence.replace('J', '')\n",
    "    protein_sequence = protein_sequence.replace('O', '')\n",
    "    protein_sequence = protein_sequence.replace('U', '')\n",
    "    protein_sequence = protein_sequence.replace('X', '')\n",
    "    protein_sequence = protein_sequence.replace('Z', '')\n",
    "    one_hot_seq = np.zeros( (MAX_SEQ_LEN, 20))\n",
    "    for idx, aa in enumerate(protein_sequence[:MAX_SEQ_LEN]):\n",
    "        one_hot_seq[idx, :] = letter_one_hot(aa)\n",
    "    return one_hot_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f44c81eacd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "seed = 777\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_embedding(words4sent, max_seq_len, feature_dim,   to_reverse=0):\n",
    "    length = []\n",
    "    output = []\n",
    "    \n",
    "    for words in words4sent:\n",
    "        if to_reverse:\n",
    "            words = np.flip(words, 0)\n",
    "        length.append( words.shape[0])\n",
    "        if  words.shape[0] < max_seq_len:\n",
    "            wordList = np.concatenate([words,np.zeros([max_seq_len - words.shape[0],feature_dim])])\n",
    "        output.append(wordList)\n",
    "    return np.array(output),np.array(length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pool(x, lengths):\n",
    "    out = torch.FloatTensor(x.size(1), x.size(2)).zero_() # BxF\n",
    "    for i in range(x.size(1)):\n",
    "        out[i] = torch.mean(x[:lengths[i],i,:], 0)\n",
    "    return out\n",
    "\n",
    "\n",
    "class RandLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, num_layers, output_dim,  bidirectional=False):\n",
    "        super(RandLSTM, self).__init__()\n",
    "        \n",
    "\n",
    "        self.bidirectional = bidirectional\n",
    "        self.max_seq_len = 128\n",
    "        self.input_dim = input_dim\n",
    "         \n",
    "\n",
    "        self.e_hid_init = torch.zeros(1, 1, output_dim)\n",
    "        self.e_cell_init = torch.zeros(1, 1, output_dim)\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lm = nn.LSTM(input_dim, output_dim, num_layers=num_layers,\n",
    "                          bidirectional= self.bidirectional, batch_first=True)\n",
    "\n",
    "        self.bidirectional += 1\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "   \n",
    "\n",
    "    def lstm(self, inputs, lengths):\n",
    "        bsz, max_len, _ = inputs.size()\n",
    "        in_embs = inputs\n",
    "        lens, indices = torch.sort(lengths, 0, True)\n",
    "\n",
    "        e_hid_init = self.e_hid_init.expand(1*self.num_layers*self.bidirectional, bsz, self.output_dim).contiguous()\n",
    "        e_cell_init = self.e_cell_init.expand(1*self.num_layers*self.bidirectional, bsz, self.output_dim).contiguous()\n",
    "        all_hids, (enc_last_hid, _) = self.lm(pack(in_embs[indices],\n",
    "                                                        lens.tolist(), batch_first=True), (e_hid_init, e_cell_init))\n",
    "        _, _indices = torch.sort(indices, 0)\n",
    "        all_hids = unpack(all_hids, batch_first=True)[0][_indices]\n",
    "\n",
    "        return all_hids\n",
    "\n",
    "    def forward(self, words4sent):\n",
    "        \n",
    "        out, lengths = gen_embedding(words4sent, self.max_seq_len, self.input_dim)\n",
    "        out = torch.from_numpy(out).float()\n",
    "        lengths = torch.from_numpy(np.array(lengths))\n",
    "        out = self.lstm(out, lengths)\n",
    "#         print(\"output size:\",out.size())\n",
    "        out = out.transpose(1,0)\n",
    "        out = mean_pool(out, lengths)\n",
    "        return out\n",
    "\n",
    "    def encode(self, batch):\n",
    "        return self.forward(batch).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from six.moves import cPickle as pickle #for performance\n",
    "\n",
    " \n",
    "def save_dict(di_, filename_):\n",
    "    with open(filename_, 'wb') as f:\n",
    "        pickle.dump(di_, f)\n",
    "\n",
    "def load_dict(filename_):\n",
    "    with open(filename_, 'rb') as f:\n",
    "        ret_di = pickle.load(f)\n",
    "    return ret_di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract w2v model\n",
    "from gensim.models import Word2Vec \n",
    "\n",
    "w2vmodel =  Word2Vec.load('/home/xhh/PMC_model/PMC_model.txt')\n",
    "def vector_name(name): \n",
    "    s = name.split(' ')\n",
    "    vectors = [] \n",
    "    for word in s: \n",
    "        if w2vmodel.wv.__contains__(word):   \n",
    "            vectors.append(w2vmodel.wv[word]) \n",
    "    else: \n",
    "        clear_words = re.sub('[^A-Za-z0-9]+', ' ', word) \n",
    "        clear_words = clear_words.lstrip().rstrip().split(' ')\n",
    "        for w in clear_words: \n",
    "            if w2vmodel.wv.__contains__(w): \n",
    "                vectors.append(w2vmodel.wv[w]) \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read go.obo obtain ontology type\n",
    " \n",
    "obo_file = '../cross-species/go.obo'\n",
    "fp=open(obo_file,'r')\n",
    "obo_txt=fp.read()\n",
    "fp.close()\n",
    "obo_txt=obo_txt[obo_txt.find(\"[Term]\")-1:]\n",
    "obo_txt=obo_txt[:obo_txt.find(\"[Typedef]\")]\n",
    "# obo_dict=parse_obo_txt(obo_txt)\n",
    "id_name_dicts = {}\n",
    "for Term_txt in obo_txt.split(\"[Term]\\n\"):\n",
    "    if not Term_txt.strip():\n",
    "        continue\n",
    "    name = ''\n",
    "    ids = []\n",
    "    for line in Term_txt.splitlines():\n",
    "        if   line.startswith(\"id: \"):\n",
    "            ids.append(line[len(\"id: \"):])     \n",
    "        elif line.startswith(\"name: \"):\n",
    "             name=line[len(\"name: \"):]\n",
    "        elif line.startswith(\"alt_id: \"):\n",
    "            ids.append(line[len(\"alt_id: \"):])\n",
    "    \n",
    "    for t_id in ids:\n",
    "        id_name_dicts[t_id] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "protein2go =  load_dict('MMprot2go.pkl')\n",
    "prot2emb_w2v = {}\n",
    "project_dim = 2048\n",
    "num_layers = 1\n",
    "max_go_len = 1024\n",
    "max_protlen = 0\n",
    "w2vlstm = RandLSTM(200,num_layers,  project_dim, bidirectional = False)\n",
    "\n",
    "\n",
    "for key, value in protein2go.items(): \n",
    "    allgos = value.split(',') \n",
    "    allgos = list(set(allgos))\n",
    "    count = 0\n",
    "    words4sent = []\n",
    "    for  go in  allgos:\n",
    "        if len(go) > 2:\n",
    "            feature = np.array(vector_name(id_name_dicts[go]))\n",
    "            if feature.shape[0] > 0:\n",
    "                words4sent.append(feature)\n",
    "            \n",
    "        count += feature.shape[0]\n",
    "    if len(words4sent) > 0:\n",
    "        sent_embedding = w2vlstm.encode(words4sent)\n",
    "    else:\n",
    "        sent_embedding = np.zeros((1, project_dim))\n",
    "    if max_protlen < sent_embedding.shape[0]:\n",
    "        max_protlen = sent_embedding.shape[0]\n",
    "    prot2emb_w2v[key] = sent_embedding \n",
    "\n",
    "del w2vmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n"
     ]
    }
   ],
   "source": [
    "print(max_protlen)\n",
    "w2v_len = max_protlen\n",
    "# w2v_len = 211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot2emb_bert = {}\n",
    "max_protlen = 0\n",
    "input_dim = 768\n",
    " \n",
    "bertlstm = RandLSTM(input_dim,num_layers,  project_dim, bidirectional = False)\n",
    "for key, value in protein2go.items():\n",
    "     \n",
    "    allgos = value.split(',') \n",
    "    allgos = list(set(allgos))\n",
    "    count = 0\n",
    "    words4sent = []\n",
    "    for  go in  allgos:\n",
    "        if len(go) > 2:\n",
    "            feature = np.load('../ncbi_allfeatures4go/'+go+'_0.npy')[1:-1]\n",
    "            words4sent.append(feature)\n",
    "        count += feature.shape[0] \n",
    "    if len(words4sent) > 0:\n",
    "        sent_embedding = bertlstm.encode(words4sent)\n",
    "    else:\n",
    "        sent_embedding = np.zeros((1, project_dim))\n",
    "    if max_protlen < sent_embedding.shape[0]:\n",
    "        max_protlen = sent_embedding.shape[0]\n",
    "    prot2emb_bert[key] = sent_embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n"
     ]
    }
   ],
   "source": [
    "print(max_protlen)\n",
    "bert_len = max_protlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "feature_len = 768\n",
    "\n",
    "max_seq_len = 1000\n",
    "# max_protlen = 32\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self,  ppi_pair_file, batch_size=128):\n",
    "        'Initialization' \n",
    "        self.batch_size = batch_size\n",
    "        self.ppi_pair_file = ppi_pair_file\n",
    "        input_dim = 768\n",
    "        num_layers = 1\n",
    "         \n",
    "        \n",
    "        \n",
    "        self.projection_dim = project_dim\n",
    "        self.bert_len = bert_len\n",
    "        self.w2v_len = w2v_len\n",
    "        self.max_seqlen = max_seq_len\n",
    "        self.protein2seq = load_dict('MMprot2seq.pkl')\n",
    "        self.read_ppi()\n",
    "        self.protein2onehot = {}\n",
    "        self.onehot_seqs()\n",
    "        self.prot2emb_bert =  prot2emb_bert\n",
    "        self.prot2emb_w2v = prot2emb_w2v\n",
    "         \n",
    "#         self.prot2embedding() \n",
    "         \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def read_ppi(self):\n",
    "        with open(self.ppi_pair_file, 'r') as f:\n",
    "            self.ppi_pairs  =  f.readlines()\n",
    "    \n",
    "    def onehot_seqs(self):\n",
    "        for key, value in self.protein2seq.items():\n",
    "            self.protein2onehot[key] =  protein_one_hot(value, self.max_seqlen) \n",
    "    \n",
    "#     def prot2embedding(self):\n",
    "#         for key, value in self.protein2go.items():\n",
    "#             X_go1 =  np.zeros((1,768))\n",
    "#             allgos = value.split(',') \n",
    "#             allgos = list(set(allgos))\n",
    "#             count = 0\n",
    "#             words4sent = []\n",
    "#             for  go in  allgos:\n",
    "#                 if len(go) > 2:\n",
    "#                     feature = np.load('../ncbi_allfeatures4go/'+go+'_0.npy')[1:-1]\n",
    "#                     words4sent.append(feature)\n",
    "#                 if count + feature.shape[0] > max_go_len:\n",
    "#                     break    \n",
    "#                 count += feature.shape[0] \n",
    "#             if len(words4sent) > 0:\n",
    "#                 sent_embedding = self.bertlstm.encode(words4sent)\n",
    "#             else:\n",
    "#                 sent_embedding = np.zeros((1, self.projection_dim))\n",
    "#             self.prot2emb[key] = sent_embedding \n",
    "    \n",
    "   \n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.ppi_pairs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.ppi_pairs))\n",
    "         \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "\n",
    "         \n",
    "        X_seq1 = np.empty((self.batch_size, self.max_seqlen,20))\n",
    "        X_seq2 = np.empty((self.batch_size, self.max_seqlen,20))\n",
    "        y = np.empty((self.batch_size))\n",
    "        X_go1 = np.empty((self.batch_size, self.bert_len + self.w2v_len,self.projection_dim))\n",
    "        X_go2 = np.empty((self.batch_size, self.bert_len + self.w2v_len,self.projection_dim))\n",
    "\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            ppi_pair = self.ppi_pairs[ID]\n",
    "            p1, p2, label = ppi_pair.rstrip().split('\\t')\n",
    "            if label == '+':\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "            X_seq1[i] =  self.protein2onehot[p1]\n",
    "            X_seq2[i] =  self.protein2onehot[p2]\n",
    "            \n",
    "            prot1emb_bert = self.prot2emb_bert[p1]\n",
    "            X_go1[i,:prot1emb_bert.shape[0]] = prot1emb_bert\n",
    "            \n",
    "            prot2emb_bert = self.prot2emb_bert[p2]\n",
    "            X_go2[i,:prot2emb_bert.shape[0]] = prot2emb_bert\n",
    "            \n",
    "            prot1emb_w2v = self.prot2emb_w2v[p1]\n",
    "            X_go1[i,prot1emb_bert.shape[0]:prot1emb_w2v.shape[0] + prot1emb_bert.shape[0]] = prot1emb_w2v\n",
    "            \n",
    "            prot2emb_w2v = self.prot2emb_w2v[p2]\n",
    "            X_go2[i,prot2emb_bert.shape[0]:prot2emb_bert.shape[0] + prot2emb_w2v.shape[0] ] = prot2emb_w2v\n",
    "            \n",
    "             \n",
    "            \n",
    "            \n",
    "        return [X_go1, X_go2,  X_seq1, X_seq2] ,  y\n",
    "\n",
    "\n",
    "\n",
    "    def all_data(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "\n",
    "         \n",
    "        X_seq1 = np.empty((len(list_IDs_temp), self.max_seqlen,20))\n",
    "\n",
    "         \n",
    "        X_seq2 = np.empty((len(list_IDs_temp), self.max_seqlen,20))\n",
    "        y = np.empty((len(list_IDs_temp)))\n",
    "        X_go1 = np.empty((len(list_IDs_temp), self.bert_len + self.w2v_len,self.projection_dim))\n",
    "        X_go2 = np.empty((len(list_IDs_temp), self.bert_len + self.w2v_len,self.projection_dim))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            ppi_pair = self.ppi_pairs[ID]\n",
    "            p1, p2, label = ppi_pair.rstrip().split('\\t')\n",
    "            if label == '+':\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "            X_seq1[i] =  self.protein2onehot[p1]\n",
    "            X_seq2[i] =  self.protein2onehot[p2]\n",
    "            \n",
    "            prot1emb_bert = self.prot2emb_bert[p1]\n",
    "            X_go1[i,:prot1emb_bert.shape[0]] = prot1emb_bert\n",
    "            \n",
    "            prot2emb_bert = self.prot2emb_bert[p2]\n",
    "            X_go2[i,:prot2emb_bert.shape[0]] = prot2emb_bert\n",
    "            \n",
    "            prot1emb_w2v = self.prot2emb_w2v[p1]\n",
    "            X_go1[i,prot1emb_bert.shape[0]:prot1emb_w2v.shape[0] + prot1emb_bert.shape[0]] = prot1emb_w2v\n",
    "            \n",
    "            prot2emb_w2v = self.prot2emb_w2v[p2]\n",
    "            X_go2[i,prot2emb_bert.shape[0]:prot2emb_bert.shape[0] + prot2emb_w2v.shape[0] ] = prot2emb_w2v\n",
    "            \n",
    "           \n",
    "        return [X_go1, X_go2,  X_seq1, X_seq2] ,  y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K, initializers, regularizers, constraints\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        # todo: check that this is correct\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True,\n",
    "                 return_attention=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Note: The layer has been tested with Keras 1.x\n",
    "        Example:\n",
    "            # 1\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "            # next add a Dense layer (for classification/regression) or whatever...\n",
    "            # 2 - Get the attention scores\n",
    "            hidden = LSTM(64, return_sequences=True)(words)\n",
    "            sentence, word_scores = Attention(return_attention=True)(hidden)\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        weighted_input = x * K.expand_dims(a)\n",
    "\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [result, a]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], input_shape[-1]),\n",
    "                    (input_shape[0], input_shape[1])]\n",
    "        else:\n",
    "            return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           (None, 1000, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_139 (Conv1D)             (None, 1000, 16)     976         input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_141 (Conv1D)             (None, 1000, 16)     336         input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           (None, 504, 2048)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 504, 2048)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           (None, 1000, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_140 (Conv1D)             (None, 1000, 16)     1296        conv1d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_142 (Conv1D)             (None, 1000, 16)     784         conv1d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_143 (Conv1D)             (None, 1000, 16)     976         input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_144 (Conv1D)             (None, 1000, 16)     336         input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_121 (Conv1D)             (None, 504, 32)      196640      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_123 (Conv1D)             (None, 504, 32)      65568       input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_127 (Conv1D)             (None, 504, 32)      196640      input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_129 (Conv1D)             (None, 504, 32)      65568       input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_133 (Conv1D)             (None, 1000, 16)     976         input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_135 (Conv1D)             (None, 1000, 16)     336         input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 1000, 64)     0           conv1d_140[0][0]                 \n",
      "                                                                 conv1d_142[0][0]                 \n",
      "                                                                 conv1d_143[0][0]                 \n",
      "                                                                 conv1d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_122 (Conv1D)             (None, 504, 32)      5152        conv1d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_124 (Conv1D)             (None, 504, 32)      3104        conv1d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_125 (Conv1D)             (None, 504, 32)      196640      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_126 (Conv1D)             (None, 504, 32)      65568       input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_128 (Conv1D)             (None, 504, 32)      5152        conv1d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_130 (Conv1D)             (None, 504, 32)      3104        conv1d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_131 (Conv1D)             (None, 504, 32)      196640      input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_132 (Conv1D)             (None, 504, 32)      65568       input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_134 (Conv1D)             (None, 1000, 16)     1296        conv1d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_136 (Conv1D)             (None, 1000, 16)     784         conv1d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_137 (Conv1D)             (None, 1000, 16)     976         input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_138 (Conv1D)             (None, 1000, 16)     336         input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 64)     0           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 504, 128)     0           conv1d_122[0][0]                 \n",
      "                                                                 conv1d_124[0][0]                 \n",
      "                                                                 conv1d_125[0][0]                 \n",
      "                                                                 conv1d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 504, 64)      399744      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 504, 128)     0           conv1d_128[0][0]                 \n",
      "                                                                 conv1d_130[0][0]                 \n",
      "                                                                 conv1d_131[0][0]                 \n",
      "                                                                 conv1d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 504, 64)      399744      input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 1000, 64)     0           conv1d_134[0][0]                 \n",
      "                                                                 conv1d_136[0][0]                 \n",
      "                                                                 conv1d_137[0][0]                 \n",
      "                                                                 conv1d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 1000, 128)    33024       input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 1000, 128)    49920       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 504, 128)     0           concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 504, 64)      0           bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 504, 128)     0           concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 504, 64)      0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1000, 64)     0           concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000, 128)    0           bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000, 128)    0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_41 (Gl (None, 128)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_41 (Global (None, 128)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_41 (Attention)        (None, 128)          632         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_42 (Gl (None, 64)           0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_42 (Global (None, 64)           0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_42 (Attention)        (None, 64)           568         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_43 (Gl (None, 128)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_43 (Global (None, 128)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_43 (Attention)        (None, 128)          632         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_44 (Gl (None, 64)           0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_44 (Global (None, 64)           0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_44 (Attention)        (None, 64)           568         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_45 (Gl (None, 64)           0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_45 (Global (None, 64)           0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_45 (Attention)        (None, 64)           1064        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_46 (Gl (None, 128)          0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_46 (Global (None, 128)          0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_46 (Attention)        (None, 128)          1128        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_47 (Gl (None, 64)           0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_47 (Global (None, 64)           0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_47 (Attention)        (None, 64)           1064        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_48 (Gl (None, 128)          0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_48 (Global (None, 128)          0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_48 (Attention)        (None, 128)          1128        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 576)          0           global_average_pooling1d_41[0][0]\n",
      "                                                                 global_max_pooling1d_41[0][0]    \n",
      "                                                                 attention_41[0][0]               \n",
      "                                                                 global_average_pooling1d_42[0][0]\n",
      "                                                                 global_max_pooling1d_42[0][0]    \n",
      "                                                                 attention_42[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 576)          0           global_average_pooling1d_43[0][0]\n",
      "                                                                 global_max_pooling1d_43[0][0]    \n",
      "                                                                 attention_43[0][0]               \n",
      "                                                                 global_average_pooling1d_44[0][0]\n",
      "                                                                 global_max_pooling1d_44[0][0]    \n",
      "                                                                 attention_44[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 576)          0           global_average_pooling1d_45[0][0]\n",
      "                                                                 global_max_pooling1d_45[0][0]    \n",
      "                                                                 attention_45[0][0]               \n",
      "                                                                 global_average_pooling1d_46[0][0]\n",
      "                                                                 global_max_pooling1d_46[0][0]    \n",
      "                                                                 attention_46[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 576)          0           global_average_pooling1d_47[0][0]\n",
      "                                                                 global_max_pooling1d_47[0][0]    \n",
      "                                                                 attention_47[0][0]               \n",
      "                                                                 global_average_pooling1d_48[0][0]\n",
      "                                                                 global_max_pooling1d_48[0][0]    \n",
      "                                                                 attention_48[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 256)          147712      concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 256)          147712      concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 256)          147712      concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 256)          147712      concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 1024)         0           dense_41[0][0]                   \n",
      "                                                                 dense_42[0][0]                   \n",
      "                                                                 dense_43[0][0]                   \n",
      "                                                                 dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 1024)         1049600     concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1024)         0           dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 1024)         1049600     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 1024)         0           dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 512)          524800      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 1)            513         dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1)            0           dense_48[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,179,329\n",
      "Trainable params: 5,179,329\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import   Embedding\n",
    "from keras.layers import  GRU, Bidirectional, CuDNNGRU, Lambda, Flatten\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "def inception_block(input_tensor, output_size):\n",
    "    \"\"\"\"\"\"\n",
    "    con1d_filters = int(output_size/4)\n",
    "    y = Conv1D(con1d_filters, 3, activation=\"relu\", padding='same')(input_tensor)\n",
    "    x1 = Conv1D(con1d_filters, 5, activation=\"relu\", padding='same')(y)\n",
    "\n",
    "    y = Conv1D(con1d_filters, 1, activation=\"relu\", padding='valid')(input_tensor)\n",
    "    x2 = Conv1D(con1d_filters, 3, activation=\"relu\", padding='same')(y)\n",
    "\n",
    "    x3 = Conv1D(con1d_filters, 3, activation=\"relu\", padding='same')(input_tensor)\n",
    "    x4 = Conv1D(con1d_filters, 1, activation=\"relu\", padding='same')(input_tensor)\n",
    "\n",
    "    y = Concatenate()([x1, x2, x3, x4])\n",
    "#     y = MaxPooling1D(4)(mix0)\n",
    "    # y = AveragePooling1D()(mix0)\n",
    "#     y = BatchNormalization()(y)\n",
    "\n",
    "    return y\n",
    "\n",
    " \n",
    "\n",
    "def build_model():\n",
    "    con_filters = 128\n",
    "    left_input_go = Input(shape=(bert_len+w2v_len,project_dim))\n",
    "    right_input_go = Input(shape=(bert_len+w2v_len,project_dim))\n",
    "    \n",
    "    \n",
    "    left_input_seq = Input(shape=(max_seq_len,20))\n",
    "    right_input_seq = Input(shape=(max_seq_len,20))\n",
    "    \n",
    "    x = inception_block(left_input_go,con_filters )\n",
    "    x = Dropout(0.3)(x)\n",
    "    x_gru = Bidirectional(CuDNNGRU(32, return_sequences=True))(left_input_go)\n",
    "    x_gru = Dropout(0.3)(x_gru)\n",
    "     \n",
    "    x_a = GlobalAveragePooling1D()(x)\n",
    "    x_b = GlobalMaxPooling1D()(x)\n",
    "    x_c = Attention()(x)\n",
    "    x_gru_a = GlobalAveragePooling1D()(x_gru)\n",
    "    x_gru_b = GlobalMaxPooling1D()(x_gru)\n",
    "    x_gru_c = Attention()(x_gru)\n",
    "    left_x_go = Concatenate()([ x_a, x_b, x_c,  x_gru_a, x_gru_b, x_gru_c])\n",
    "    left_x_go = Dense(256, activation='relu')(left_x_go)\n",
    "     \n",
    " \n",
    "    x = inception_block(right_input_go,con_filters )\n",
    "    x = Dropout(0.3)(x)\n",
    "    x_gru =Bidirectional(CuDNNGRU(32, return_sequences=True))(right_input_go)\n",
    "    x_gru = Dropout(0.3)(x_gru)\n",
    "     \n",
    "\n",
    "    x_a = GlobalAveragePooling1D()(x)\n",
    "    x_b = GlobalMaxPooling1D()(x)\n",
    "    x_c = Attention()(x)\n",
    "    x_gru_a = GlobalAveragePooling1D()(x_gru)\n",
    "    x_gru_b = GlobalMaxPooling1D()(x_gru)\n",
    "    x_gru_c = Attention()(x_gru)\n",
    "    right_x_go = Concatenate()([x_a, x_b, x_c,  x_gru_a, x_gru_b, x_gru_c])\n",
    "    right_x_go = Dense(256, activation='relu')(right_x_go)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = inception_block(left_input_seq,con_filters//2)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x_gru = Bidirectional(CuDNNGRU(64, return_sequences=True))(left_input_seq)\n",
    "    x_gru = Dropout(0.3)(x_gru)\n",
    "     \n",
    "\n",
    "    x_a = GlobalAveragePooling1D()(x)\n",
    "    x_b = GlobalMaxPooling1D()(x)\n",
    "    x_c = Attention()(x)\n",
    "    x_gru_a = GlobalAveragePooling1D()(x_gru)\n",
    "    x_gru_b = GlobalMaxPooling1D()(x_gru)\n",
    "    x_gru_c = Attention()(x_gru)\n",
    "    left_x_seq = Concatenate()([x_a, x_b, x_c,  x_gru_a, x_gru_b, x_gru_c])\n",
    "    left_x_seq = Dense(256, activation='relu')(left_x_seq)\n",
    "#      \n",
    " \n",
    "    x = inception_block(right_input_seq,con_filters//2)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x_gru =Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "    x_gru = Dropout(0.3)(x_gru)\n",
    "     \n",
    "    x_a = GlobalAveragePooling1D()(x)\n",
    "    x_b = GlobalMaxPooling1D()(x)\n",
    "    x_c = Attention()(x)\n",
    "    x_gru_a = GlobalAveragePooling1D()(x_gru)\n",
    "    x_gru_b = GlobalMaxPooling1D()(x_gru)\n",
    "    x_gru_c = Attention()(x_gru)\n",
    "    right_x_seq= Concatenate()([ x_a, x_b, x_c, x_gru_a, x_gru_b, x_gru_c])\n",
    "    right_x_seq = Dense(256, activation='relu')(right_x_seq)\n",
    "    \n",
    "    \n",
    "   \n",
    "   \n",
    "    x =   Concatenate()([left_x_go  , right_x_go, left_x_seq, right_x_seq])\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "  \n",
    "     \n",
    "    x = Dense(1)(x)\n",
    "    output = Activation('sigmoid')(x)\n",
    "    # model = Model([left_input_go, right_input_go], output)\n",
    "  \n",
    "    model = Model([left_input_go, right_input_go, left_input_seq, right_input_seq], output)\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.7504 - acc: 0.5065 - val_loss: 0.7234 - val_acc: 0.3906\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6909 - acc: 0.5456 - val_loss: 0.7308 - val_acc: 0.4219\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6631 - acc: 0.6120 - val_loss: 0.8125 - val_acc: 0.4219\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6672 - acc: 0.5924 - val_loss: 0.6555 - val_acc: 0.6875\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5944 - acc: 0.6914 - val_loss: 0.6349 - val_acc: 0.6719\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5208 - acc: 0.7253 - val_loss: 0.5707 - val_acc: 0.6875\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4709 - acc: 0.7812 - val_loss: 0.5742 - val_acc: 0.7656\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4501 - acc: 0.7812 - val_loss: 0.5633 - val_acc: 0.7500\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3627 - acc: 0.8333 - val_loss: 0.6897 - val_acc: 0.6562\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3073 - acc: 0.8698 - val_loss: 1.0364 - val_acc: 0.5625\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3018 - acc: 0.8698 - val_loss: 0.9832 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3165 - acc: 0.8581 - val_loss: 1.0281 - val_acc: 0.5156\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2029 - acc: 0.9271 - val_loss: 0.9303 - val_acc: 0.7812\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2790 - acc: 0.8763 - val_loss: 0.6622 - val_acc: 0.7500\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2672 - acc: 0.9049 - val_loss: 0.8272 - val_acc: 0.6719\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1076 - acc: 0.9635 - val_loss: 1.7436 - val_acc: 0.6094\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1135 - acc: 0.9531 - val_loss: 1.5564 - val_acc: 0.5625\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1229 - acc: 0.9557 - val_loss: 1.2118 - val_acc: 0.6719\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1131 - acc: 0.9505 - val_loss: 1.4945 - val_acc: 0.6094\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1325 - acc: 0.9479 - val_loss: 0.9936 - val_acc: 0.7812\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0997 - acc: 0.9635 - val_loss: 1.2605 - val_acc: 0.6094\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0760 - acc: 0.9688 - val_loss: 1.4178 - val_acc: 0.6562\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0347 - acc: 0.9896 - val_loss: 1.9482 - val_acc: 0.6094\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.971997\n",
      "ACC: 0.820000\n",
      "MCC : 0.693950\n",
      "TPR:0.678571\n",
      "FPR:0.000000\n",
      "Pre:1.000000\n",
      "F1:0.808511\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.7115 - acc: 0.5208 - val_loss: 0.6961 - val_acc: 0.4688\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6930 - acc: 0.5000 - val_loss: 0.6889 - val_acc: 0.6094\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6922 - acc: 0.5352 - val_loss: 0.6873 - val_acc: 0.4844\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6628 - acc: 0.5898 - val_loss: 0.6175 - val_acc: 0.6719\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6262 - acc: 0.6406 - val_loss: 0.5928 - val_acc: 0.6562\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5567 - acc: 0.7070 - val_loss: 0.5625 - val_acc: 0.7031\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5165 - acc: 0.7500 - val_loss: 0.5774 - val_acc: 0.7188\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5003 - acc: 0.7630 - val_loss: 0.7188 - val_acc: 0.6875\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4824 - acc: 0.7643 - val_loss: 0.5406 - val_acc: 0.7188\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4825 - acc: 0.7461 - val_loss: 0.6245 - val_acc: 0.6562\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4252 - acc: 0.8034 - val_loss: 0.6590 - val_acc: 0.7031\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3515 - acc: 0.8424 - val_loss: 0.7994 - val_acc: 0.7344\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3004 - acc: 0.8763 - val_loss: 0.8310 - val_acc: 0.6250\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5108 - acc: 0.8086 - val_loss: 0.6061 - val_acc: 0.6719\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3474 - acc: 0.8555 - val_loss: 0.8182 - val_acc: 0.6875\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3702 - acc: 0.8333 - val_loss: 0.6705 - val_acc: 0.7188\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2388 - acc: 0.9245 - val_loss: 0.8543 - val_acc: 0.7344\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2288 - acc: 0.9115 - val_loss: 0.8164 - val_acc: 0.7344\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1817 - acc: 0.9245 - val_loss: 1.0299 - val_acc: 0.7188\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1852 - acc: 0.9362 - val_loss: 0.6629 - val_acc: 0.7500\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1495 - acc: 0.9492 - val_loss: 0.9421 - val_acc: 0.7344\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1284 - acc: 0.9518 - val_loss: 0.6887 - val_acc: 0.7812\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1145 - acc: 0.9518 - val_loss: 0.8861 - val_acc: 0.7188\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0870 - acc: 0.9701 - val_loss: 0.8219 - val_acc: 0.7500\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0795 - acc: 0.9688 - val_loss: 0.9524 - val_acc: 0.7812\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1753 - acc: 0.9271 - val_loss: 0.7628 - val_acc: 0.7344\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1930 - acc: 0.9271 - val_loss: 0.7678 - val_acc: 0.6562\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1003 - acc: 0.9674 - val_loss: 1.1732 - val_acc: 0.6875\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0531 - acc: 0.9831 - val_loss: 1.3075 - val_acc: 0.7031\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0542 - acc: 0.9818 - val_loss: 1.0588 - val_acc: 0.7656\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0508 - acc: 0.9805 - val_loss: 0.9663 - val_acc: 0.7188\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0687 - acc: 0.9727 - val_loss: 1.0486 - val_acc: 0.7656\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.919887\n",
      "ACC: 0.870000\n",
      "MCC : 0.744133\n",
      "TPR:0.833333\n",
      "FPR:0.086957\n",
      "Pre:0.918367\n",
      "F1:0.873786\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.7706 - acc: 0.4922 - val_loss: 0.6914 - val_acc: 0.5625\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6908 - acc: 0.5391 - val_loss: 0.6843 - val_acc: 0.5625\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6790 - acc: 0.5586 - val_loss: 0.7130 - val_acc: 0.4844\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6642 - acc: 0.5872 - val_loss: 0.6668 - val_acc: 0.5625\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6366 - acc: 0.6276 - val_loss: 0.6591 - val_acc: 0.6094\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5638 - acc: 0.7057 - val_loss: 0.6932 - val_acc: 0.5625\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5236 - acc: 0.7318 - val_loss: 0.6601 - val_acc: 0.6094\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5339 - acc: 0.7279 - val_loss: 0.6873 - val_acc: 0.5938\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4518 - acc: 0.7773 - val_loss: 0.7753 - val_acc: 0.5625\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3576 - acc: 0.8424 - val_loss: 0.7826 - val_acc: 0.6094\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4197 - acc: 0.8073 - val_loss: 0.5951 - val_acc: 0.7031\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3081 - acc: 0.8685 - val_loss: 0.7888 - val_acc: 0.6875\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2699 - acc: 0.8802 - val_loss: 0.7706 - val_acc: 0.6250\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2100 - acc: 0.9167 - val_loss: 0.7652 - val_acc: 0.6250\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1512 - acc: 0.9414 - val_loss: 1.1796 - val_acc: 0.5469\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1503 - acc: 0.9427 - val_loss: 0.9569 - val_acc: 0.6094\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1633 - acc: 0.9349 - val_loss: 0.9137 - val_acc: 0.6250\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2096 - acc: 0.9010 - val_loss: 0.9649 - val_acc: 0.5781\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1094 - acc: 0.9505 - val_loss: 1.0170 - val_acc: 0.6719\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0684 - acc: 0.9727 - val_loss: 1.3694 - val_acc: 0.6562\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2063 - acc: 0.9310 - val_loss: 1.1125 - val_acc: 0.5781\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.913097\n",
      "ACC: 0.850000\n",
      "MCC : 0.698443\n",
      "TPR:0.720930\n",
      "FPR:0.052632\n",
      "Pre:0.911765\n",
      "F1:0.805195\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 27s 2s/step - loss: 0.7151 - acc: 0.5104 - val_loss: 0.6880 - val_acc: 0.5312\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6962 - acc: 0.4935 - val_loss: 0.6866 - val_acc: 0.6719\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6826 - acc: 0.5781 - val_loss: 0.6785 - val_acc: 0.5156\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6491 - acc: 0.6250 - val_loss: 0.6794 - val_acc: 0.5781\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6859 - acc: 0.5977 - val_loss: 0.6694 - val_acc: 0.6562\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6572 - acc: 0.5755 - val_loss: 0.6476 - val_acc: 0.6719\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6186 - acc: 0.6979 - val_loss: 0.6710 - val_acc: 0.6406\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5791 - acc: 0.6836 - val_loss: 0.6733 - val_acc: 0.5469\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5618 - acc: 0.7018 - val_loss: 0.6203 - val_acc: 0.6562\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5497 - acc: 0.7096 - val_loss: 0.6105 - val_acc: 0.6875\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4824 - acc: 0.7773 - val_loss: 0.6533 - val_acc: 0.7344\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3972 - acc: 0.8164 - val_loss: 0.6537 - val_acc: 0.7188\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3536 - acc: 0.8411 - val_loss: 0.7292 - val_acc: 0.7656\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2755 - acc: 0.8893 - val_loss: 0.8403 - val_acc: 0.6406\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3211 - acc: 0.8607 - val_loss: 0.6476 - val_acc: 0.7188\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3153 - acc: 0.8594 - val_loss: 0.7010 - val_acc: 0.7031\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1762 - acc: 0.9440 - val_loss: 0.9330 - val_acc: 0.7188\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1531 - acc: 0.9349 - val_loss: 0.9020 - val_acc: 0.6719\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1257 - acc: 0.9492 - val_loss: 1.6549 - val_acc: 0.6406\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2261 - acc: 0.9023 - val_loss: 0.7254 - val_acc: 0.7500\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1102 - acc: 0.9622 - val_loss: 1.2351 - val_acc: 0.6875\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1407 - acc: 0.9479 - val_loss: 1.4450 - val_acc: 0.6562\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2510 - acc: 0.8919 - val_loss: 0.6241 - val_acc: 0.7812\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1669 - acc: 0.9388 - val_loss: 0.9258 - val_acc: 0.7344\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1485 - acc: 0.9414 - val_loss: 1.2913 - val_acc: 0.6250\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0753 - acc: 0.9714 - val_loss: 1.1720 - val_acc: 0.7031\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0622 - acc: 0.9766 - val_loss: 1.3239 - val_acc: 0.7344\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0603 - acc: 0.9792 - val_loss: 1.5079 - val_acc: 0.6562\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0519 - acc: 0.9818 - val_loss: 1.1867 - val_acc: 0.6562\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0268 - acc: 0.9909 - val_loss: 1.5273 - val_acc: 0.6562\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0371 - acc: 0.9831 - val_loss: 2.0380 - val_acc: 0.6250\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0333 - acc: 0.9870 - val_loss: 1.6042 - val_acc: 0.7188\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0359 - acc: 0.9870 - val_loss: 1.5433 - val_acc: 0.7031\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.965986\n",
      "ACC: 0.920000\n",
      "MCC : 0.842887\n",
      "TPR:0.959184\n",
      "FPR:0.117647\n",
      "Pre:0.886792\n",
      "F1:0.921569\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 27s 2s/step - loss: 0.7248 - acc: 0.5078 - val_loss: 0.6890 - val_acc: 0.5312\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6922 - acc: 0.5195 - val_loss: 0.6845 - val_acc: 0.5312\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6850 - acc: 0.5560 - val_loss: 0.6970 - val_acc: 0.4844\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6826 - acc: 0.5599 - val_loss: 0.7038 - val_acc: 0.4688\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6771 - acc: 0.6094 - val_loss: 0.6534 - val_acc: 0.6875\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6172 - acc: 0.6758 - val_loss: 0.6434 - val_acc: 0.6094\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5612 - acc: 0.7174 - val_loss: 0.6358 - val_acc: 0.6875\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4506 - acc: 0.7904 - val_loss: 0.7094 - val_acc: 0.6250\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3898 - acc: 0.8203 - val_loss: 0.7291 - val_acc: 0.6094\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3949 - acc: 0.8086 - val_loss: 0.7133 - val_acc: 0.6562\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3113 - acc: 0.8685 - val_loss: 0.9235 - val_acc: 0.5938\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 12s 1s/step - loss: 0.3503 - acc: 0.8451 - val_loss: 0.8324 - val_acc: 0.5938\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2589 - acc: 0.9010 - val_loss: 0.9883 - val_acc: 0.6250\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2397 - acc: 0.9128 - val_loss: 0.9323 - val_acc: 0.5938\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2109 - acc: 0.9049 - val_loss: 0.9523 - val_acc: 0.6250\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.729167\n",
      "ACC: 0.650000\n",
      "MCC : 0.298376\n",
      "TPR:0.673077\n",
      "FPR:0.375000\n",
      "Pre:0.660377\n",
      "F1:0.666667\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 29s 2s/step - loss: 0.7421 - acc: 0.5326 - val_loss: 0.6902 - val_acc: 0.5625\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6893 - acc: 0.5482 - val_loss: 0.6882 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6638 - acc: 0.5951 - val_loss: 0.6344 - val_acc: 0.6406\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6272 - acc: 0.6523 - val_loss: 0.5948 - val_acc: 0.7656\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5734 - acc: 0.7135 - val_loss: 0.5026 - val_acc: 0.8125\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5191 - acc: 0.7513 - val_loss: 0.4858 - val_acc: 0.7969\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5740 - acc: 0.6862 - val_loss: 0.5389 - val_acc: 0.8125\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4372 - acc: 0.8099 - val_loss: 0.4025 - val_acc: 0.8594\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4885 - acc: 0.7305 - val_loss: 0.6342 - val_acc: 0.5312\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3606 - acc: 0.8385 - val_loss: 0.5391 - val_acc: 0.7188\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2598 - acc: 0.8867 - val_loss: 0.5709 - val_acc: 0.7188\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3200 - acc: 0.8346 - val_loss: 0.4419 - val_acc: 0.7812\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2604 - acc: 0.9049 - val_loss: 0.4305 - val_acc: 0.7969\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1947 - acc: 0.9219 - val_loss: 0.8203 - val_acc: 0.7656\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5645 - acc: 0.7227 - val_loss: 0.5454 - val_acc: 0.8281\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3920 - acc: 0.8607 - val_loss: 0.5101 - val_acc: 0.7344\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2371 - acc: 0.9023 - val_loss: 0.4897 - val_acc: 0.8125\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2471 - acc: 0.8958 - val_loss: 0.6530 - val_acc: 0.7188\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.982048\n",
      "ACC: 0.890000\n",
      "MCC : 0.789812\n",
      "TPR:0.744186\n",
      "FPR:0.000000\n",
      "Pre:1.000000\n",
      "F1:0.853333\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 30s 2s/step - loss: 0.7196 - acc: 0.5000 - val_loss: 0.6850 - val_acc: 0.5312\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6933 - acc: 0.5182 - val_loss: 0.6809 - val_acc: 0.5781\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6741 - acc: 0.5625 - val_loss: 0.6499 - val_acc: 0.6250\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6305 - acc: 0.6510 - val_loss: 0.5909 - val_acc: 0.6406\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5649 - acc: 0.6784 - val_loss: 0.6652 - val_acc: 0.6250\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6184 - acc: 0.6562 - val_loss: 0.6385 - val_acc: 0.5781\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5418 - acc: 0.7083 - val_loss: 0.5227 - val_acc: 0.7344\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4483 - acc: 0.7917 - val_loss: 0.5299 - val_acc: 0.7656\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4732 - acc: 0.7773 - val_loss: 0.4965 - val_acc: 0.7344\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3693 - acc: 0.8359 - val_loss: 0.5311 - val_acc: 0.7031\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3612 - acc: 0.8398 - val_loss: 0.5131 - val_acc: 0.7500\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2850 - acc: 0.8958 - val_loss: 0.6665 - val_acc: 0.7031\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2568 - acc: 0.8854 - val_loss: 0.5850 - val_acc: 0.7031\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2871 - acc: 0.8633 - val_loss: 0.5266 - val_acc: 0.7188\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2284 - acc: 0.9076 - val_loss: 0.5543 - val_acc: 0.7188\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2391 - acc: 0.8945 - val_loss: 1.0021 - val_acc: 0.6562\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2146 - acc: 0.9271 - val_loss: 0.6700 - val_acc: 0.7031\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1597 - acc: 0.9362 - val_loss: 0.7223 - val_acc: 0.7344\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.922003\n",
      "ACC: 0.850000\n",
      "MCC : 0.700673\n",
      "TPR:0.827586\n",
      "FPR:0.119048\n",
      "Pre:0.905660\n",
      "F1:0.864865\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 31s 3s/step - loss: 0.7467 - acc: 0.4779 - val_loss: 0.6875 - val_acc: 0.6250\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6903 - acc: 0.5299 - val_loss: 0.7012 - val_acc: 0.4531\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6860 - acc: 0.5599 - val_loss: 0.6443 - val_acc: 0.6406\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6660 - acc: 0.6094 - val_loss: 0.6500 - val_acc: 0.6094\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6255 - acc: 0.6667 - val_loss: 0.6280 - val_acc: 0.6875\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5302 - acc: 0.7422 - val_loss: 0.5334 - val_acc: 0.7188\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5168 - acc: 0.7786 - val_loss: 0.6911 - val_acc: 0.5938\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4968 - acc: 0.7708 - val_loss: 0.5462 - val_acc: 0.7188\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3778 - acc: 0.8398 - val_loss: 0.5339 - val_acc: 0.7344\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3529 - acc: 0.8477 - val_loss: 0.5174 - val_acc: 0.7031\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4247 - acc: 0.7995 - val_loss: 0.5138 - val_acc: 0.7500\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3044 - acc: 0.8815 - val_loss: 0.7237 - val_acc: 0.6719\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3073 - acc: 0.8750 - val_loss: 0.5061 - val_acc: 0.7344\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2819 - acc: 0.8724 - val_loss: 0.5671 - val_acc: 0.7188\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2627 - acc: 0.8776 - val_loss: 0.6550 - val_acc: 0.7031\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2818 - acc: 0.8724 - val_loss: 0.4932 - val_acc: 0.7500\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1252 - acc: 0.9583 - val_loss: 0.7431 - val_acc: 0.7344\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0715 - acc: 0.9701 - val_loss: 1.0387 - val_acc: 0.6875\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1186 - acc: 0.9544 - val_loss: 0.8100 - val_acc: 0.7188\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1529 - acc: 0.9388 - val_loss: 0.7019 - val_acc: 0.7344\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1181 - acc: 0.9505 - val_loss: 0.9506 - val_acc: 0.7188\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.913061\n",
      "ACC: 0.840000\n",
      "MCC : 0.682938\n",
      "TPR:0.770833\n",
      "FPR:0.096154\n",
      "Pre:0.880952\n",
      "F1:0.822222\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 33s 3s/step - loss: 0.7214 - acc: 0.5130 - val_loss: 0.6938 - val_acc: 0.4688\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6883 - acc: 0.5560 - val_loss: 0.7024 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6784 - acc: 0.5742 - val_loss: 0.6881 - val_acc: 0.5469\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6098 - acc: 0.6732 - val_loss: 0.6701 - val_acc: 0.5156\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5654 - acc: 0.7044 - val_loss: 0.6286 - val_acc: 0.6562\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4895 - acc: 0.7721 - val_loss: 0.6183 - val_acc: 0.6719\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4230 - acc: 0.7930 - val_loss: 0.7039 - val_acc: 0.6094\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3685 - acc: 0.8424 - val_loss: 0.6192 - val_acc: 0.6406\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3146 - acc: 0.8581 - val_loss: 0.6431 - val_acc: 0.6562\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2324 - acc: 0.9154 - val_loss: 0.7279 - val_acc: 0.7500\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4204 - acc: 0.8685 - val_loss: 1.1137 - val_acc: 0.5156\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4007 - acc: 0.8346 - val_loss: 0.5971 - val_acc: 0.6875\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2733 - acc: 0.8854 - val_loss: 0.8921 - val_acc: 0.5938\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2085 - acc: 0.9206 - val_loss: 0.8417 - val_acc: 0.6875\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2145 - acc: 0.9219 - val_loss: 1.0045 - val_acc: 0.5469\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2030 - acc: 0.9141 - val_loss: 0.8271 - val_acc: 0.6562\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1241 - acc: 0.9570 - val_loss: 1.0028 - val_acc: 0.6719\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0973 - acc: 0.9674 - val_loss: 1.3953 - val_acc: 0.6250\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1499 - acc: 0.9362 - val_loss: 0.8765 - val_acc: 0.6875\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1773 - acc: 0.9271 - val_loss: 0.8475 - val_acc: 0.7031\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.933573\n",
      "ACC: 0.840000\n",
      "MCC : 0.692707\n",
      "TPR:0.734694\n",
      "FPR:0.058824\n",
      "Pre:0.923077\n",
      "F1:0.818182\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 34s 3s/step - loss: 0.7186 - acc: 0.4948 - val_loss: 0.6917 - val_acc: 0.5625\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6930 - acc: 0.5286 - val_loss: 0.6848 - val_acc: 0.5625\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6833 - acc: 0.5508 - val_loss: 0.6665 - val_acc: 0.6250\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6738 - acc: 0.5911 - val_loss: 0.6537 - val_acc: 0.6719\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6508 - acc: 0.6237 - val_loss: 0.5895 - val_acc: 0.6875\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5938 - acc: 0.6966 - val_loss: 0.5777 - val_acc: 0.7188\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5760 - acc: 0.7148 - val_loss: 0.6823 - val_acc: 0.5625\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5822 - acc: 0.6706 - val_loss: 0.6122 - val_acc: 0.6719\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5036 - acc: 0.7747 - val_loss: 0.7275 - val_acc: 0.6094\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5043 - acc: 0.7474 - val_loss: 0.5682 - val_acc: 0.7188\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4052 - acc: 0.8164 - val_loss: 0.7346 - val_acc: 0.7188\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3719 - acc: 0.8190 - val_loss: 0.5896 - val_acc: 0.7500\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2720 - acc: 0.8906 - val_loss: 0.8871 - val_acc: 0.6719\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2429 - acc: 0.9089 - val_loss: 0.6337 - val_acc: 0.7344\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1405 - acc: 0.9505 - val_loss: 0.9849 - val_acc: 0.6875\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3342 - acc: 0.8802 - val_loss: 0.7860 - val_acc: 0.6875\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2853 - acc: 0.8802 - val_loss: 0.5660 - val_acc: 0.7500\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1664 - acc: 0.9362 - val_loss: 0.9603 - val_acc: 0.7344\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3283 - acc: 0.8581 - val_loss: 0.5907 - val_acc: 0.6875\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1428 - acc: 0.9544 - val_loss: 0.8471 - val_acc: 0.6719\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0724 - acc: 0.9740 - val_loss: 1.1251 - val_acc: 0.7031\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0710 - acc: 0.9753 - val_loss: 0.9843 - val_acc: 0.6875\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.915064\n",
      "ACC: 0.790000\n",
      "MCC : 0.602763\n",
      "TPR:0.625000\n",
      "FPR:0.057692\n",
      "Pre:0.909091\n",
      "F1:0.740741\n",
      "--------------------------\n",
      "\n",
      "mean AUC: 0.916588\n",
      "mean ACC: 0.832000\n",
      "mean MCC : 0.674668\n",
      "mean TPR:0.756740\n",
      "mean FPR:0.096395\n",
      "mean Pre:0.899608\n",
      "mean F1:0.817507\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 34s 3s/step - loss: 0.7223 - acc: 0.5169 - val_loss: 0.7149 - val_acc: 0.4062\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6926 - acc: 0.5195 - val_loss: 0.7289 - val_acc: 0.4062\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6732 - acc: 0.5768 - val_loss: 0.6675 - val_acc: 0.6250\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6389 - acc: 0.6185 - val_loss: 0.6751 - val_acc: 0.5312\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6058 - acc: 0.6706 - val_loss: 0.7337 - val_acc: 0.4375\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5916 - acc: 0.7122 - val_loss: 0.6176 - val_acc: 0.6875\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4904 - acc: 0.7617 - val_loss: 0.5743 - val_acc: 0.7344\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4512 - acc: 0.7904 - val_loss: 0.6278 - val_acc: 0.6094\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3815 - acc: 0.8451 - val_loss: 0.5407 - val_acc: 0.7656\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3218 - acc: 0.8620 - val_loss: 0.5217 - val_acc: 0.7969\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2736 - acc: 0.8828 - val_loss: 0.6202 - val_acc: 0.7188\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3056 - acc: 0.8919 - val_loss: 0.5606 - val_acc: 0.7188\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3205 - acc: 0.8685 - val_loss: 0.9345 - val_acc: 0.5312\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2215 - acc: 0.9089 - val_loss: 0.8827 - val_acc: 0.6406\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 12s 1s/step - loss: 0.2250 - acc: 0.9023 - val_loss: 0.6365 - val_acc: 0.7344\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1489 - acc: 0.9388 - val_loss: 0.7843 - val_acc: 0.7188\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0824 - acc: 0.9740 - val_loss: 1.2559 - val_acc: 0.6719\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1098 - acc: 0.9505 - val_loss: 0.9265 - val_acc: 0.7188\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0793 - acc: 0.9701 - val_loss: 1.2401 - val_acc: 0.6719\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0866 - acc: 0.9727 - val_loss: 1.0766 - val_acc: 0.6562\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.909675\n",
      "ACC: 0.840000\n",
      "MCC : 0.689305\n",
      "TPR:0.723404\n",
      "FPR:0.056604\n",
      "Pre:0.918919\n",
      "F1:0.809524\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.7221 - acc: 0.4740 - val_loss: 0.6897 - val_acc: 0.5469\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6888 - acc: 0.5312 - val_loss: 0.7352 - val_acc: 0.4688\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6799 - acc: 0.5703 - val_loss: 0.6603 - val_acc: 0.6562\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6505 - acc: 0.6419 - val_loss: 0.6550 - val_acc: 0.5938\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5932 - acc: 0.6589 - val_loss: 0.6024 - val_acc: 0.6875\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5717 - acc: 0.6992 - val_loss: 0.5890 - val_acc: 0.7344\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5116 - acc: 0.7461 - val_loss: 0.5783 - val_acc: 0.7344\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4762 - acc: 0.7565 - val_loss: 0.5426 - val_acc: 0.7188\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4631 - acc: 0.8125 - val_loss: 0.5510 - val_acc: 0.7500\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4395 - acc: 0.7917 - val_loss: 0.5383 - val_acc: 0.7188\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3708 - acc: 0.8255 - val_loss: 0.6597 - val_acc: 0.6719\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2991 - acc: 0.8646 - val_loss: 0.6372 - val_acc: 0.7500\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3272 - acc: 0.8594 - val_loss: 0.8298 - val_acc: 0.7188\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1903 - acc: 0.9154 - val_loss: 0.7762 - val_acc: 0.7188\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1606 - acc: 0.9375 - val_loss: 1.2933 - val_acc: 0.5781\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1261 - acc: 0.9492 - val_loss: 0.9222 - val_acc: 0.7500\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1994 - acc: 0.9141 - val_loss: 1.3660 - val_acc: 0.5469\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1800 - acc: 0.9401 - val_loss: 0.6848 - val_acc: 0.7344\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1263 - acc: 0.9518 - val_loss: 1.0090 - val_acc: 0.7031\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.903434\n",
      "ACC: 0.800000\n",
      "MCC : 0.598070\n",
      "TPR:0.800000\n",
      "FPR:0.200000\n",
      "Pre:0.830189\n",
      "F1:0.814815\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.7306 - acc: 0.4987 - val_loss: 0.6847 - val_acc: 0.5625\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.7076 - acc: 0.4753 - val_loss: 0.6894 - val_acc: 0.5625\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6876 - acc: 0.5677 - val_loss: 0.6943 - val_acc: 0.4688\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6647 - acc: 0.5898 - val_loss: 0.6468 - val_acc: 0.6094\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6127 - acc: 0.7018 - val_loss: 0.7972 - val_acc: 0.4688\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6341 - acc: 0.6328 - val_loss: 0.6172 - val_acc: 0.6719\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5228 - acc: 0.7487 - val_loss: 0.7477 - val_acc: 0.5625\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4967 - acc: 0.7669 - val_loss: 0.6488 - val_acc: 0.6250\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5187 - acc: 0.7396 - val_loss: 0.6005 - val_acc: 0.6875\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4609 - acc: 0.7917 - val_loss: 0.6174 - val_acc: 0.6562\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3722 - acc: 0.8268 - val_loss: 0.6354 - val_acc: 0.6875\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3177 - acc: 0.8672 - val_loss: 0.6942 - val_acc: 0.6562\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2414 - acc: 0.9062 - val_loss: 0.8759 - val_acc: 0.6562\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2290 - acc: 0.9167 - val_loss: 0.7651 - val_acc: 0.6719\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2058 - acc: 0.9167 - val_loss: 0.7173 - val_acc: 0.7031\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2691 - acc: 0.8841 - val_loss: 0.7476 - val_acc: 0.6719\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2434 - acc: 0.9049 - val_loss: 0.6680 - val_acc: 0.6875\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2372 - acc: 0.9010 - val_loss: 0.7117 - val_acc: 0.6875\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0946 - acc: 0.9701 - val_loss: 1.4407 - val_acc: 0.7031\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0831 - acc: 0.9779 - val_loss: 1.1383 - val_acc: 0.7031\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0543 - acc: 0.9779 - val_loss: 1.1127 - val_acc: 0.7188\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1284 - acc: 0.9466 - val_loss: 0.8776 - val_acc: 0.7188\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0762 - acc: 0.9714 - val_loss: 1.2820 - val_acc: 0.6562\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0655 - acc: 0.9766 - val_loss: 1.2977 - val_acc: 0.7188\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1275 - acc: 0.9583 - val_loss: 1.2247 - val_acc: 0.6875\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1561 - acc: 0.9440 - val_loss: 0.9850 - val_acc: 0.6562\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0662 - acc: 0.9805 - val_loss: 1.6512 - val_acc: 0.5781\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1021 - acc: 0.9557 - val_loss: 1.2626 - val_acc: 0.6719\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0336 - acc: 0.9896 - val_loss: 1.4019 - val_acc: 0.7188\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0609 - acc: 0.9805 - val_loss: 1.6339 - val_acc: 0.6250\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0560 - acc: 0.9779 - val_loss: 1.5479 - val_acc: 0.6406\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.927740\n",
      "ACC: 0.890000\n",
      "MCC : 0.784440\n",
      "TPR:0.849057\n",
      "FPR:0.063830\n",
      "Pre:0.937500\n",
      "F1:0.891089\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 38s 3s/step - loss: 0.7146 - acc: 0.4870 - val_loss: 0.6806 - val_acc: 0.5781\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6876 - acc: 0.5378 - val_loss: 0.6552 - val_acc: 0.7656\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6642 - acc: 0.6068 - val_loss: 0.6565 - val_acc: 0.5938\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6037 - acc: 0.6654 - val_loss: 0.5273 - val_acc: 0.7812\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5202 - acc: 0.7396 - val_loss: 0.5939 - val_acc: 0.6875\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4788 - acc: 0.7643 - val_loss: 0.5425 - val_acc: 0.6875\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4651 - acc: 0.7734 - val_loss: 0.5586 - val_acc: 0.7188\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4354 - acc: 0.7904 - val_loss: 0.5870 - val_acc: 0.6406\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3006 - acc: 0.8750 - val_loss: 0.5930 - val_acc: 0.7031\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2817 - acc: 0.8906 - val_loss: 0.6979 - val_acc: 0.6875\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2687 - acc: 0.8958 - val_loss: 0.5394 - val_acc: 0.7969\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2392 - acc: 0.9010 - val_loss: 0.8623 - val_acc: 0.5938\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3337 - acc: 0.8477 - val_loss: 0.4881 - val_acc: 0.7812\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2183 - acc: 0.9076 - val_loss: 0.5195 - val_acc: 0.7656\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1378 - acc: 0.9492 - val_loss: 0.6371 - val_acc: 0.7656\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0906 - acc: 0.9648 - val_loss: 0.7989 - val_acc: 0.7188\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0675 - acc: 0.9753 - val_loss: 0.8204 - val_acc: 0.7344\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3951 - acc: 0.8581 - val_loss: 0.5294 - val_acc: 0.7344\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4034 - acc: 0.8151 - val_loss: 0.5710 - val_acc: 0.6562\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2532 - acc: 0.9128 - val_loss: 0.5627 - val_acc: 0.7500\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1348 - acc: 0.9440 - val_loss: 0.6136 - val_acc: 0.7812\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.956383\n",
      "ACC: 0.870000\n",
      "MCC : 0.746565\n",
      "TPR:0.795918\n",
      "FPR:0.058824\n",
      "Pre:0.928571\n",
      "F1:0.857143\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 39s 3s/step - loss: 0.7395 - acc: 0.4818 - val_loss: 0.7077 - val_acc: 0.3750\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6912 - acc: 0.5247 - val_loss: 0.7296 - val_acc: 0.3750\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6856 - acc: 0.5651 - val_loss: 0.7073 - val_acc: 0.4531\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6854 - acc: 0.5534 - val_loss: 0.6977 - val_acc: 0.4531\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6617 - acc: 0.6146 - val_loss: 0.6378 - val_acc: 0.6406\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6193 - acc: 0.6602 - val_loss: 0.6694 - val_acc: 0.6094\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5582 - acc: 0.7253 - val_loss: 0.7623 - val_acc: 0.5156\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4863 - acc: 0.7604 - val_loss: 0.7431 - val_acc: 0.6250\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4136 - acc: 0.8164 - val_loss: 0.7088 - val_acc: 0.6250\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3509 - acc: 0.8359 - val_loss: 0.7561 - val_acc: 0.6719\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2928 - acc: 0.8737 - val_loss: 0.9294 - val_acc: 0.6250\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3819 - acc: 0.8151 - val_loss: 0.7548 - val_acc: 0.5625\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2922 - acc: 0.8997 - val_loss: 0.9932 - val_acc: 0.6250\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1642 - acc: 0.9336 - val_loss: 1.0807 - val_acc: 0.6094\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1721 - acc: 0.9336 - val_loss: 1.2759 - val_acc: 0.5938\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1845 - acc: 0.9245 - val_loss: 1.1905 - val_acc: 0.5625\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1274 - acc: 0.9531 - val_loss: 1.6584 - val_acc: 0.6094\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1469 - acc: 0.9388 - val_loss: 1.3631 - val_acc: 0.5938\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1390 - acc: 0.9440 - val_loss: 1.1338 - val_acc: 0.6094\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1482 - acc: 0.9336 - val_loss: 0.9561 - val_acc: 0.6406\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.926282\n",
      "ACC: 0.810000\n",
      "MCC : 0.645109\n",
      "TPR:0.692308\n",
      "FPR:0.062500\n",
      "Pre:0.923077\n",
      "F1:0.791209\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 40s 3s/step - loss: 0.7130 - acc: 0.5000 - val_loss: 0.6995 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6908 - acc: 0.5417 - val_loss: 0.6894 - val_acc: 0.5156\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6869 - acc: 0.5208 - val_loss: 0.6762 - val_acc: 0.5312\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6516 - acc: 0.6419 - val_loss: 0.6913 - val_acc: 0.5938\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5816 - acc: 0.7005 - val_loss: 0.6369 - val_acc: 0.6094\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6082 - acc: 0.6914 - val_loss: 0.6322 - val_acc: 0.6406\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5543 - acc: 0.7591 - val_loss: 0.6142 - val_acc: 0.6406\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5075 - acc: 0.7734 - val_loss: 0.6084 - val_acc: 0.6562\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4461 - acc: 0.8047 - val_loss: 0.6177 - val_acc: 0.6406\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4012 - acc: 0.8333 - val_loss: 0.8519 - val_acc: 0.5625\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4938 - acc: 0.7669 - val_loss: 0.5785 - val_acc: 0.6719\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3646 - acc: 0.8438 - val_loss: 0.6335 - val_acc: 0.6875\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2562 - acc: 0.9036 - val_loss: 0.8191 - val_acc: 0.6250\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3621 - acc: 0.8372 - val_loss: 0.5915 - val_acc: 0.7031\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3897 - acc: 0.8190 - val_loss: 0.6063 - val_acc: 0.6719\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2571 - acc: 0.8945 - val_loss: 0.7920 - val_acc: 0.7031\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1746 - acc: 0.9271 - val_loss: 0.7514 - val_acc: 0.6719\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1916 - acc: 0.9219 - val_loss: 0.8373 - val_acc: 0.6562\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2191 - acc: 0.9076 - val_loss: 0.8867 - val_acc: 0.6250\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1648 - acc: 0.9336 - val_loss: 0.8287 - val_acc: 0.6719\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1372 - acc: 0.9505 - val_loss: 0.8284 - val_acc: 0.7188\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1015 - acc: 0.9544 - val_loss: 1.4228 - val_acc: 0.6094\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 12s 1s/step - loss: 0.1292 - acc: 0.9531 - val_loss: 0.7443 - val_acc: 0.7031\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1074 - acc: 0.9544 - val_loss: 1.0593 - val_acc: 0.7188\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0657 - acc: 0.9740 - val_loss: 0.9847 - val_acc: 0.6719\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0836 - acc: 0.9648 - val_loss: 0.9754 - val_acc: 0.6719\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0824 - acc: 0.9727 - val_loss: 1.0232 - val_acc: 0.7188\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0939 - acc: 0.9635 - val_loss: 0.9519 - val_acc: 0.7031\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0712 - acc: 0.9701 - val_loss: 1.3900 - val_acc: 0.6719\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0587 - acc: 0.9727 - val_loss: 1.0685 - val_acc: 0.6875\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0323 - acc: 0.9922 - val_loss: 1.2684 - val_acc: 0.7500\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0373 - acc: 0.9857 - val_loss: 1.6860 - val_acc: 0.6562\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1066 - acc: 0.9583 - val_loss: 1.0033 - val_acc: 0.6719\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0807 - acc: 0.9688 - val_loss: 1.0417 - val_acc: 0.6562\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0408 - acc: 0.9857 - val_loss: 1.1879 - val_acc: 0.6875\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1325 - acc: 0.9544 - val_loss: 1.9684 - val_acc: 0.5938\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1886 - acc: 0.9336 - val_loss: 0.7471 - val_acc: 0.6719\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0732 - acc: 0.9766 - val_loss: 1.4036 - val_acc: 0.6875\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0465 - acc: 0.9844 - val_loss: 1.3708 - val_acc: 0.6875\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0291 - acc: 0.9857 - val_loss: 1.3801 - val_acc: 0.6875\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0560 - acc: 0.9779 - val_loss: 1.4915 - val_acc: 0.6562\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.969400\n",
      "ACC: 0.910000\n",
      "MCC : 0.819471\n",
      "TPR:0.930233\n",
      "FPR:0.105263\n",
      "Pre:0.869565\n",
      "F1:0.898876\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 41s 3s/step - loss: 0.7256 - acc: 0.5026 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6929 - acc: 0.5156 - val_loss: 0.6870 - val_acc: 0.5156\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6877 - acc: 0.5391 - val_loss: 0.6835 - val_acc: 0.4844\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6731 - acc: 0.5599 - val_loss: 0.6448 - val_acc: 0.6094\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6124 - acc: 0.6654 - val_loss: 0.6085 - val_acc: 0.6562\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5380 - acc: 0.7409 - val_loss: 0.6224 - val_acc: 0.6719\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4936 - acc: 0.7591 - val_loss: 0.5879 - val_acc: 0.6562\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4402 - acc: 0.7917 - val_loss: 0.5816 - val_acc: 0.6562\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3728 - acc: 0.8411 - val_loss: 1.2554 - val_acc: 0.5156\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4234 - acc: 0.8060 - val_loss: 0.6854 - val_acc: 0.6562\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3236 - acc: 0.8685 - val_loss: 0.7092 - val_acc: 0.6406\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2941 - acc: 0.8711 - val_loss: 0.7307 - val_acc: 0.6562\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2161 - acc: 0.9284 - val_loss: 0.7672 - val_acc: 0.7188\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2479 - acc: 0.8984 - val_loss: 0.6797 - val_acc: 0.7344\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3309 - acc: 0.8581 - val_loss: 0.8403 - val_acc: 0.5938\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2383 - acc: 0.9076 - val_loss: 0.7222 - val_acc: 0.7500\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1933 - acc: 0.9271 - val_loss: 0.8249 - val_acc: 0.6406\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1003 - acc: 0.9648 - val_loss: 0.9321 - val_acc: 0.7031\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1216 - acc: 0.9531 - val_loss: 0.8590 - val_acc: 0.6719\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0826 - acc: 0.9714 - val_loss: 0.8884 - val_acc: 0.6875\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0523 - acc: 0.9818 - val_loss: 1.0505 - val_acc: 0.6719\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1051 - acc: 0.9609 - val_loss: 1.0305 - val_acc: 0.6719\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0958 - acc: 0.9674 - val_loss: 0.8228 - val_acc: 0.7031\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1267 - acc: 0.9440 - val_loss: 0.9109 - val_acc: 0.7188\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1340 - acc: 0.9479 - val_loss: 0.8937 - val_acc: 0.6250\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0375 - acc: 0.9896 - val_loss: 1.3821 - val_acc: 0.6562\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.939176\n",
      "ACC: 0.860000\n",
      "MCC : 0.733719\n",
      "TPR:0.755102\n",
      "FPR:0.039216\n",
      "Pre:0.948718\n",
      "F1:0.840909\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 42s 3s/step - loss: 0.7156 - acc: 0.5078 - val_loss: 0.6943 - val_acc: 0.4062\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6933 - acc: 0.5195 - val_loss: 0.6917 - val_acc: 0.5156\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6814 - acc: 0.5508 - val_loss: 0.6714 - val_acc: 0.5781\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6282 - acc: 0.6484 - val_loss: 0.6618 - val_acc: 0.5781\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5681 - acc: 0.7109 - val_loss: 0.6012 - val_acc: 0.6250\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4975 - acc: 0.7734 - val_loss: 0.6258 - val_acc: 0.6719\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4838 - acc: 0.7773 - val_loss: 0.6141 - val_acc: 0.6250\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3779 - acc: 0.8359 - val_loss: 0.6992 - val_acc: 0.6094\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3104 - acc: 0.8646 - val_loss: 0.6081 - val_acc: 0.7031\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2917 - acc: 0.8711 - val_loss: 0.5867 - val_acc: 0.7031\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2831 - acc: 0.8776 - val_loss: 0.6403 - val_acc: 0.7031\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2490 - acc: 0.8945 - val_loss: 0.7821 - val_acc: 0.6406\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2141 - acc: 0.9193 - val_loss: 0.6613 - val_acc: 0.7031\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1340 - acc: 0.9583 - val_loss: 0.6930 - val_acc: 0.7500\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1343 - acc: 0.9414 - val_loss: 0.7328 - val_acc: 0.7188\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1234 - acc: 0.9635 - val_loss: 0.7528 - val_acc: 0.7031\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2067 - acc: 0.9219 - val_loss: 0.5879 - val_acc: 0.7031\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1761 - acc: 0.9297 - val_loss: 0.6038 - val_acc: 0.7188\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1602 - acc: 0.9284 - val_loss: 0.6680 - val_acc: 0.7344\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1470 - acc: 0.9388 - val_loss: 0.7957 - val_acc: 0.7344\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1229 - acc: 0.9505 - val_loss: 0.6480 - val_acc: 0.6875\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0585 - acc: 0.9831 - val_loss: 1.3517 - val_acc: 0.6719\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0600 - acc: 0.9766 - val_loss: 0.8091 - val_acc: 0.6875\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0608 - acc: 0.9805 - val_loss: 0.8551 - val_acc: 0.7344\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.971497\n",
      "ACC: 0.940000\n",
      "MCC : 0.879988\n",
      "TPR:0.914894\n",
      "FPR:0.037736\n",
      "Pre:0.955556\n",
      "F1:0.934783\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 43s 4s/step - loss: 0.7142 - acc: 0.5130 - val_loss: 0.6993 - val_acc: 0.4688\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6926 - acc: 0.5339 - val_loss: 0.7060 - val_acc: 0.4844\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6977 - acc: 0.5156 - val_loss: 0.6888 - val_acc: 0.6406\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6705 - acc: 0.6159 - val_loss: 0.7009 - val_acc: 0.5156\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6334 - acc: 0.6393 - val_loss: 0.6542 - val_acc: 0.6562\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5814 - acc: 0.7031 - val_loss: 0.8502 - val_acc: 0.4844\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6271 - acc: 0.6445 - val_loss: 0.6633 - val_acc: 0.5312\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5245 - acc: 0.7591 - val_loss: 0.7444 - val_acc: 0.5781\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4884 - acc: 0.7747 - val_loss: 0.6362 - val_acc: 0.6406\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4249 - acc: 0.7943 - val_loss: 0.7085 - val_acc: 0.6562\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4431 - acc: 0.7786 - val_loss: 0.8357 - val_acc: 0.5156\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3496 - acc: 0.8411 - val_loss: 0.8792 - val_acc: 0.6250\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3227 - acc: 0.8385 - val_loss: 0.7384 - val_acc: 0.6719\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2970 - acc: 0.8763 - val_loss: 0.8484 - val_acc: 0.6719\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3132 - acc: 0.8477 - val_loss: 0.7430 - val_acc: 0.6719\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1854 - acc: 0.9414 - val_loss: 1.4693 - val_acc: 0.6406\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1781 - acc: 0.9271 - val_loss: 1.2559 - val_acc: 0.7031\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1491 - acc: 0.9401 - val_loss: 1.1358 - val_acc: 0.6719\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2280 - acc: 0.9076 - val_loss: 1.2570 - val_acc: 0.5625\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1881 - acc: 0.9193 - val_loss: 1.1303 - val_acc: 0.6406\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0938 - acc: 0.9701 - val_loss: 1.9534 - val_acc: 0.6094\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0788 - acc: 0.9701 - val_loss: 1.4585 - val_acc: 0.6719\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0857 - acc: 0.9701 - val_loss: 1.5715 - val_acc: 0.6562\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0512 - acc: 0.9818 - val_loss: 1.4507 - val_acc: 0.6250\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0457 - acc: 0.9831 - val_loss: 1.6127 - val_acc: 0.6406\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0334 - acc: 0.9883 - val_loss: 1.8614 - val_acc: 0.6250\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0297 - acc: 0.9909 - val_loss: 1.9853 - val_acc: 0.6406\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.955960\n",
      "ACC: 0.880000\n",
      "MCC : 0.771248\n",
      "TPR:0.818182\n",
      "FPR:0.044444\n",
      "Pre:0.957447\n",
      "F1:0.882353\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 44s 4s/step - loss: 0.7204 - acc: 0.5026 - val_loss: 0.6946 - val_acc: 0.4844\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6882 - acc: 0.5625 - val_loss: 0.6945 - val_acc: 0.5156\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6938 - acc: 0.5169 - val_loss: 0.6857 - val_acc: 0.4688\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6825 - acc: 0.5599 - val_loss: 0.6800 - val_acc: 0.6250\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6656 - acc: 0.5990 - val_loss: 0.6730 - val_acc: 0.5781\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6256 - acc: 0.6536 - val_loss: 0.8000 - val_acc: 0.5312\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6702 - acc: 0.5990 - val_loss: 0.6668 - val_acc: 0.5156\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5903 - acc: 0.6797 - val_loss: 0.6004 - val_acc: 0.7031\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5404 - acc: 0.7240 - val_loss: 0.7478 - val_acc: 0.5312\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5714 - acc: 0.6771 - val_loss: 0.6143 - val_acc: 0.7188\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4550 - acc: 0.7786 - val_loss: 0.6200 - val_acc: 0.6875\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4041 - acc: 0.8203 - val_loss: 0.7090 - val_acc: 0.6562\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3293 - acc: 0.8542 - val_loss: 0.9018 - val_acc: 0.6094\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2910 - acc: 0.8724 - val_loss: 0.7507 - val_acc: 0.6094\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2610 - acc: 0.9076 - val_loss: 1.2866 - val_acc: 0.5938\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2111 - acc: 0.9089 - val_loss: 1.0764 - val_acc: 0.6094\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1690 - acc: 0.9284 - val_loss: 1.0634 - val_acc: 0.5938\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1437 - acc: 0.9401 - val_loss: 1.4539 - val_acc: 0.6250\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1642 - acc: 0.9219 - val_loss: 1.3555 - val_acc: 0.5781\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1524 - acc: 0.9336 - val_loss: 1.2556 - val_acc: 0.6406\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.839200\n",
      "ACC: 0.730000\n",
      "MCC : 0.476383\n",
      "TPR:0.600000\n",
      "FPR:0.140000\n",
      "Pre:0.810811\n",
      "F1:0.689655\n",
      "--------------------------\n",
      "\n",
      "mean AUC: 0.929875\n",
      "mean ACC: 0.853000\n",
      "mean MCC : 0.714430\n",
      "mean TPR:0.787910\n",
      "mean FPR:0.080842\n",
      "mean Pre:0.908035\n",
      "mean F1:0.841036\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 45s 4s/step - loss: 0.7133 - acc: 0.4987 - val_loss: 0.6937 - val_acc: 0.4844\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6966 - acc: 0.5221 - val_loss: 0.6805 - val_acc: 0.5781\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 12s 1s/step - loss: 0.6842 - acc: 0.5417 - val_loss: 0.7253 - val_acc: 0.4531\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6406 - acc: 0.6523 - val_loss: 0.7849 - val_acc: 0.4844\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6685 - acc: 0.5859 - val_loss: 0.6743 - val_acc: 0.5625\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5823 - acc: 0.7005 - val_loss: 0.5426 - val_acc: 0.7656\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5818 - acc: 0.7122 - val_loss: 0.6225 - val_acc: 0.6562\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6461 - acc: 0.6081 - val_loss: 0.6575 - val_acc: 0.5781\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5253 - acc: 0.7422 - val_loss: 0.5428 - val_acc: 0.7656\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4863 - acc: 0.7799 - val_loss: 0.5422 - val_acc: 0.7812\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4229 - acc: 0.8190 - val_loss: 0.6589 - val_acc: 0.6719\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3603 - acc: 0.8503 - val_loss: 0.7669 - val_acc: 0.6875\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2766 - acc: 0.8815 - val_loss: 0.5932 - val_acc: 0.7812\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2897 - acc: 0.8802 - val_loss: 0.7203 - val_acc: 0.6719\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2142 - acc: 0.9089 - val_loss: 0.5982 - val_acc: 0.7656\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2919 - acc: 0.8867 - val_loss: 0.6971 - val_acc: 0.7344\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1786 - acc: 0.9388 - val_loss: 1.0402 - val_acc: 0.7031\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1755 - acc: 0.9362 - val_loss: 1.0230 - val_acc: 0.6719\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1211 - acc: 0.9518 - val_loss: 0.7019 - val_acc: 0.7656\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1151 - acc: 0.9492 - val_loss: 0.9332 - val_acc: 0.7031\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.814503\n",
      "ACC: 0.730000\n",
      "MCC : 0.521290\n",
      "TPR:0.458333\n",
      "FPR:0.019231\n",
      "Pre:0.956522\n",
      "F1:0.619718\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 47s 4s/step - loss: 0.7301 - acc: 0.5156 - val_loss: 0.6990 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6997 - acc: 0.4974 - val_loss: 0.6941 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6893 - acc: 0.5430 - val_loss: 0.6841 - val_acc: 0.5938\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6771 - acc: 0.6107 - val_loss: 0.6977 - val_acc: 0.5156\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6550 - acc: 0.6237 - val_loss: 0.6632 - val_acc: 0.6094\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5808 - acc: 0.7018 - val_loss: 0.6991 - val_acc: 0.4844\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5365 - acc: 0.7174 - val_loss: 0.6373 - val_acc: 0.6250\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4236 - acc: 0.8060 - val_loss: 0.7626 - val_acc: 0.6250\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5288 - acc: 0.7474 - val_loss: 0.7251 - val_acc: 0.5625\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3915 - acc: 0.8190 - val_loss: 0.7871 - val_acc: 0.5312\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2709 - acc: 0.8802 - val_loss: 1.0967 - val_acc: 0.5781\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3713 - acc: 0.8203 - val_loss: 0.7346 - val_acc: 0.5625\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2547 - acc: 0.9141 - val_loss: 0.9925 - val_acc: 0.5156\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1651 - acc: 0.9375 - val_loss: 1.2077 - val_acc: 0.5625\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1971 - acc: 0.9115 - val_loss: 0.9839 - val_acc: 0.5781\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1363 - acc: 0.9375 - val_loss: 1.1085 - val_acc: 0.5781\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0981 - acc: 0.9609 - val_loss: 1.6577 - val_acc: 0.5781\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.827200\n",
      "ACC: 0.770000\n",
      "MCC : 0.545371\n",
      "TPR:0.700000\n",
      "FPR:0.160000\n",
      "Pre:0.813953\n",
      "F1:0.752688\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 48s 4s/step - loss: 0.7095 - acc: 0.5052 - val_loss: 0.7231 - val_acc: 0.3281\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6806 - acc: 0.5690 - val_loss: 0.6409 - val_acc: 0.6719\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6671 - acc: 0.5885 - val_loss: 0.6544 - val_acc: 0.6406\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6044 - acc: 0.6667 - val_loss: 0.6462 - val_acc: 0.6562\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5070 - acc: 0.7591 - val_loss: 0.5424 - val_acc: 0.6875\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4531 - acc: 0.7865 - val_loss: 0.6812 - val_acc: 0.5781\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4213 - acc: 0.8034 - val_loss: 0.5393 - val_acc: 0.7344\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3312 - acc: 0.8503 - val_loss: 0.7591 - val_acc: 0.5625\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2783 - acc: 0.8841 - val_loss: 0.6848 - val_acc: 0.7344\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3919 - acc: 0.8529 - val_loss: 0.6874 - val_acc: 0.5781\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4590 - acc: 0.7721 - val_loss: 0.6630 - val_acc: 0.6094\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2585 - acc: 0.8932 - val_loss: 0.7174 - val_acc: 0.7344\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2391 - acc: 0.9049 - val_loss: 0.7155 - val_acc: 0.6406\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1415 - acc: 0.9479 - val_loss: 0.7622 - val_acc: 0.7656\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2002 - acc: 0.9102 - val_loss: 0.6635 - val_acc: 0.7188\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1290 - acc: 0.9557 - val_loss: 0.6838 - val_acc: 0.7656\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1021 - acc: 0.9609 - val_loss: 0.8124 - val_acc: 0.7500\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0724 - acc: 0.9674 - val_loss: 0.7838 - val_acc: 0.7656\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0899 - acc: 0.9688 - val_loss: 0.7247 - val_acc: 0.7344\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0993 - acc: 0.9609 - val_loss: 1.2617 - val_acc: 0.6406\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1881 - acc: 0.9245 - val_loss: 0.8232 - val_acc: 0.7031\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0961 - acc: 0.9701 - val_loss: 0.8945 - val_acc: 0.7188\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0555 - acc: 0.9792 - val_loss: 0.8644 - val_acc: 0.7812\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0238 - acc: 0.9896 - val_loss: 1.1274 - val_acc: 0.7656\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0294 - acc: 0.9883 - val_loss: 1.4607 - val_acc: 0.6875\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0359 - acc: 0.9909 - val_loss: 1.5294 - val_acc: 0.6719\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0264 - acc: 0.9909 - val_loss: 1.0369 - val_acc: 0.7812\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0659 - acc: 0.9779 - val_loss: 1.1776 - val_acc: 0.7344\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0413 - acc: 0.9844 - val_loss: 1.0449 - val_acc: 0.7188\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0541 - acc: 0.9831 - val_loss: 0.9489 - val_acc: 0.7969\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0442 - acc: 0.9805 - val_loss: 0.9902 - val_acc: 0.7344\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0361 - acc: 0.9844 - val_loss: 1.2561 - val_acc: 0.7344\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1060 - acc: 0.9596 - val_loss: 0.9889 - val_acc: 0.7812\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1013 - acc: 0.9596 - val_loss: 1.3649 - val_acc: 0.6719\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0666 - acc: 0.9753 - val_loss: 0.9195 - val_acc: 0.7656\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0351 - acc: 0.9844 - val_loss: 1.2032 - val_acc: 0.7656\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0913 - acc: 0.9661 - val_loss: 1.0259 - val_acc: 0.7188\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1206 - acc: 0.9544 - val_loss: 0.9943 - val_acc: 0.6719\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0599 - acc: 0.9714 - val_loss: 0.7326 - val_acc: 0.7812\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0390 - acc: 0.9831 - val_loss: 0.9952 - val_acc: 0.7500\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.970612\n",
      "ACC: 0.950000\n",
      "MCC : 0.899376\n",
      "TPR:0.934783\n",
      "FPR:0.037037\n",
      "Pre:0.955556\n",
      "F1:0.945055\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 49s 4s/step - loss: 0.7513 - acc: 0.5000 - val_loss: 0.7007 - val_acc: 0.4219\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6985 - acc: 0.4831 - val_loss: 0.6917 - val_acc: 0.5312\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6859 - acc: 0.5560 - val_loss: 0.6680 - val_acc: 0.6406\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6724 - acc: 0.5846 - val_loss: 0.6536 - val_acc: 0.7188\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6515 - acc: 0.6029 - val_loss: 0.6108 - val_acc: 0.7344\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5884 - acc: 0.6927 - val_loss: 0.6433 - val_acc: 0.6250\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5634 - acc: 0.7122 - val_loss: 0.5744 - val_acc: 0.6875\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5135 - acc: 0.7643 - val_loss: 0.5439 - val_acc: 0.7344\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4713 - acc: 0.7904 - val_loss: 0.8154 - val_acc: 0.5938\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3890 - acc: 0.8320 - val_loss: 0.5715 - val_acc: 0.7500\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4835 - acc: 0.7500 - val_loss: 0.7897 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3743 - acc: 0.8424 - val_loss: 0.5680 - val_acc: 0.7656\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3160 - acc: 0.8633 - val_loss: 0.5285 - val_acc: 0.7812\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2420 - acc: 0.8997 - val_loss: 0.6257 - val_acc: 0.7812\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1943 - acc: 0.9089 - val_loss: 1.0100 - val_acc: 0.5938\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1731 - acc: 0.9271 - val_loss: 0.6733 - val_acc: 0.7812\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1433 - acc: 0.9479 - val_loss: 1.1985 - val_acc: 0.6719\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1431 - acc: 0.9362 - val_loss: 0.7593 - val_acc: 0.7344\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0885 - acc: 0.9688 - val_loss: 0.8389 - val_acc: 0.7969\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1072 - acc: 0.9596 - val_loss: 0.9032 - val_acc: 0.7344\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2578 - acc: 0.8997 - val_loss: 0.4800 - val_acc: 0.7812\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1901 - acc: 0.9154 - val_loss: 0.6001 - val_acc: 0.7969\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1205 - acc: 0.9466 - val_loss: 1.0742 - val_acc: 0.6562\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0770 - acc: 0.9727 - val_loss: 0.8188 - val_acc: 0.7812\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1165 - acc: 0.9596 - val_loss: 1.0956 - val_acc: 0.6875\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0691 - acc: 0.9805 - val_loss: 0.8458 - val_acc: 0.7812\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0558 - acc: 0.9766 - val_loss: 1.0267 - val_acc: 0.7656\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0597 - acc: 0.9766 - val_loss: 1.1886 - val_acc: 0.7031\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0955 - acc: 0.9622 - val_loss: 0.8595 - val_acc: 0.7500\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.971889\n",
      "ACC: 0.930000\n",
      "MCC : 0.856030\n",
      "TPR:0.926829\n",
      "FPR:0.067797\n",
      "Pre:0.904762\n",
      "F1:0.915663\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 50s 4s/step - loss: 0.7197 - acc: 0.5169 - val_loss: 0.6940 - val_acc: 0.4844\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6929 - acc: 0.5247 - val_loss: 0.6810 - val_acc: 0.5781\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6832 - acc: 0.5508 - val_loss: 0.6804 - val_acc: 0.5938\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6306 - acc: 0.6549 - val_loss: 0.6401 - val_acc: 0.5938\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5977 - acc: 0.6823 - val_loss: 0.6453 - val_acc: 0.6250\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5529 - acc: 0.7318 - val_loss: 0.6691 - val_acc: 0.5938\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4851 - acc: 0.7826 - val_loss: 0.7152 - val_acc: 0.6094\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4789 - acc: 0.7682 - val_loss: 0.6466 - val_acc: 0.6250\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4198 - acc: 0.8086 - val_loss: 0.6548 - val_acc: 0.6406\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3837 - acc: 0.8242 - val_loss: 0.7812 - val_acc: 0.6094\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3054 - acc: 0.8737 - val_loss: 0.7561 - val_acc: 0.6719\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2903 - acc: 0.8828 - val_loss: 0.8013 - val_acc: 0.6719\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3027 - acc: 0.8711 - val_loss: 0.6893 - val_acc: 0.6406\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2358 - acc: 0.9049 - val_loss: 1.0527 - val_acc: 0.6250\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3910 - acc: 0.8294 - val_loss: 0.8341 - val_acc: 0.5781\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3619 - acc: 0.8659 - val_loss: 0.8466 - val_acc: 0.5938\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 12s 1s/step - loss: 0.2011 - acc: 0.9193 - val_loss: 0.8635 - val_acc: 0.7031\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1249 - acc: 0.9531 - val_loss: 1.0965 - val_acc: 0.6250\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1706 - acc: 0.9362 - val_loss: 0.9387 - val_acc: 0.6250\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1121 - acc: 0.9583 - val_loss: 1.2785 - val_acc: 0.6094\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1049 - acc: 0.9570 - val_loss: 1.5834 - val_acc: 0.5781\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3099 - acc: 0.8789 - val_loss: 0.7817 - val_acc: 0.6094\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1823 - acc: 0.9362 - val_loss: 0.8958 - val_acc: 0.6250\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1106 - acc: 0.9557 - val_loss: 1.3560 - val_acc: 0.6250\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0440 - acc: 0.9870 - val_loss: 1.2625 - val_acc: 0.6719\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0760 - acc: 0.9674 - val_loss: 1.3195 - val_acc: 0.6406\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0390 - acc: 0.9883 - val_loss: 1.5012 - val_acc: 0.6094\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.948592\n",
      "ACC: 0.860000\n",
      "MCC : 0.730135\n",
      "TPR:0.930233\n",
      "FPR:0.192982\n",
      "Pre:0.784314\n",
      "F1:0.851064\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 52s 4s/step - loss: 0.7261 - acc: 0.4935 - val_loss: 0.6977 - val_acc: 0.4688\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6934 - acc: 0.5078 - val_loss: 0.6919 - val_acc: 0.4844\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6867 - acc: 0.5456 - val_loss: 0.6720 - val_acc: 0.6562\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6498 - acc: 0.6224 - val_loss: 0.6458 - val_acc: 0.6719\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6113 - acc: 0.6615 - val_loss: 0.6740 - val_acc: 0.5781\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5371 - acc: 0.7253 - val_loss: 0.5249 - val_acc: 0.6875\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6130 - acc: 0.6576 - val_loss: 0.6321 - val_acc: 0.6094\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5564 - acc: 0.7513 - val_loss: 0.5545 - val_acc: 0.6875\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4444 - acc: 0.7917 - val_loss: 0.5401 - val_acc: 0.7031\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4418 - acc: 0.7839 - val_loss: 0.5123 - val_acc: 0.6719\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3260 - acc: 0.8685 - val_loss: 0.6058 - val_acc: 0.6875\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2547 - acc: 0.8932 - val_loss: 0.6358 - val_acc: 0.6719\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2897 - acc: 0.8659 - val_loss: 0.6214 - val_acc: 0.6875\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1986 - acc: 0.9141 - val_loss: 1.0508 - val_acc: 0.6875\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1638 - acc: 0.9349 - val_loss: 0.7233 - val_acc: 0.6719\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1037 - acc: 0.9622 - val_loss: 0.9610 - val_acc: 0.6250\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2005 - acc: 0.9102 - val_loss: 0.7744 - val_acc: 0.6875\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1875 - acc: 0.9245 - val_loss: 0.7307 - val_acc: 0.7031\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1309 - acc: 0.9440 - val_loss: 1.0310 - val_acc: 0.7031\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.948283\n",
      "ACC: 0.770000\n",
      "MCC : 0.606788\n",
      "TPR:0.600000\n",
      "FPR:0.022222\n",
      "Pre:0.970588\n",
      "F1:0.741573\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 52s 4s/step - loss: 0.7103 - acc: 0.5169 - val_loss: 0.6744 - val_acc: 0.5938\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6939 - acc: 0.5326 - val_loss: 0.6695 - val_acc: 0.6094\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6766 - acc: 0.5820 - val_loss: 0.7389 - val_acc: 0.4375\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6512 - acc: 0.6289 - val_loss: 0.6167 - val_acc: 0.6562\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5654 - acc: 0.7109 - val_loss: 0.5701 - val_acc: 0.7188\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5443 - acc: 0.7448 - val_loss: 0.5947 - val_acc: 0.6562\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4892 - acc: 0.7799 - val_loss: 0.6058 - val_acc: 0.6875\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4195 - acc: 0.8060 - val_loss: 0.5993 - val_acc: 0.6406\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3870 - acc: 0.8242 - val_loss: 0.8840 - val_acc: 0.5312\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3875 - acc: 0.8268 - val_loss: 0.6839 - val_acc: 0.6094\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3034 - acc: 0.8724 - val_loss: 0.6543 - val_acc: 0.6406\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2347 - acc: 0.8971 - val_loss: 0.8411 - val_acc: 0.6094\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2438 - acc: 0.9115 - val_loss: 1.2217 - val_acc: 0.5312\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3878 - acc: 0.8047 - val_loss: 0.6292 - val_acc: 0.6094\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3397 - acc: 0.8594 - val_loss: 0.9918 - val_acc: 0.5625\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.785657\n",
      "ACC: 0.750000\n",
      "MCC : 0.521997\n",
      "TPR:0.634615\n",
      "FPR:0.125000\n",
      "Pre:0.846154\n",
      "F1:0.725275\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 53s 4s/step - loss: 0.7220 - acc: 0.5026 - val_loss: 0.6883 - val_acc: 0.5625\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6950 - acc: 0.5182 - val_loss: 0.6866 - val_acc: 0.5625\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6905 - acc: 0.5299 - val_loss: 0.6934 - val_acc: 0.4688\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6643 - acc: 0.6042 - val_loss: 0.6618 - val_acc: 0.5938\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6426 - acc: 0.6224 - val_loss: 0.6553 - val_acc: 0.6094\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5780 - acc: 0.7044 - val_loss: 0.6293 - val_acc: 0.6250\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5098 - acc: 0.7513 - val_loss: 0.7104 - val_acc: 0.6094\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4576 - acc: 0.7721 - val_loss: 0.6270 - val_acc: 0.6562\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3961 - acc: 0.8190 - val_loss: 0.6359 - val_acc: 0.6875\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3540 - acc: 0.8451 - val_loss: 0.6328 - val_acc: 0.6875\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2615 - acc: 0.8997 - val_loss: 0.7699 - val_acc: 0.7031\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2356 - acc: 0.9023 - val_loss: 1.0865 - val_acc: 0.6875\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2372 - acc: 0.8906 - val_loss: 0.7799 - val_acc: 0.6562\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1646 - acc: 0.9297 - val_loss: 1.2183 - val_acc: 0.6875\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2441 - acc: 0.8997 - val_loss: 0.7502 - val_acc: 0.7344\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2062 - acc: 0.9010 - val_loss: 0.8961 - val_acc: 0.6406\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1760 - acc: 0.9193 - val_loss: 0.9094 - val_acc: 0.6406\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1042 - acc: 0.9596 - val_loss: 1.2678 - val_acc: 0.6406\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1118 - acc: 0.9609 - val_loss: 1.2070 - val_acc: 0.6406\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1610 - acc: 0.9336 - val_loss: 0.9436 - val_acc: 0.6406\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0799 - acc: 0.9740 - val_loss: 1.0965 - val_acc: 0.6406\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0508 - acc: 0.9818 - val_loss: 1.6430 - val_acc: 0.6250\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0365 - acc: 0.9844 - val_loss: 1.4427 - val_acc: 0.6562\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0464 - acc: 0.9831 - val_loss: 1.2797 - val_acc: 0.6406\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0562 - acc: 0.9766 - val_loss: 1.7067 - val_acc: 0.6406\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.961250\n",
      "ACC: 0.890000\n",
      "MCC : 0.772716\n",
      "TPR:0.966667\n",
      "FPR:0.225000\n",
      "Pre:0.865672\n",
      "F1:0.913386\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 55s 5s/step - loss: 0.7111 - acc: 0.5299 - val_loss: 0.6919 - val_acc: 0.5156\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6982 - acc: 0.5169 - val_loss: 0.6950 - val_acc: 0.4844\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6834 - acc: 0.5625 - val_loss: 0.6731 - val_acc: 0.5312\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6792 - acc: 0.6224 - val_loss: 0.7093 - val_acc: 0.5469\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6833 - acc: 0.5573 - val_loss: 0.6748 - val_acc: 0.6562\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6342 - acc: 0.6615 - val_loss: 0.5994 - val_acc: 0.6875\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5645 - acc: 0.7135 - val_loss: 0.6191 - val_acc: 0.6562\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5609 - acc: 0.7174 - val_loss: 0.5393 - val_acc: 0.6719\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4983 - acc: 0.7526 - val_loss: 0.6071 - val_acc: 0.6562\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4637 - acc: 0.7747 - val_loss: 0.4988 - val_acc: 0.6562\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3421 - acc: 0.8516 - val_loss: 0.4869 - val_acc: 0.7188\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.3104 - acc: 0.8672 - val_loss: 0.4703 - val_acc: 0.7656\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2838 - acc: 0.8828 - val_loss: 0.5198 - val_acc: 0.7344\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2214 - acc: 0.9089 - val_loss: 0.5853 - val_acc: 0.7344\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2182 - acc: 0.9049 - val_loss: 0.5351 - val_acc: 0.7500\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1358 - acc: 0.9388 - val_loss: 0.6597 - val_acc: 0.7344\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1542 - acc: 0.9453 - val_loss: 0.6355 - val_acc: 0.7969\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1251 - acc: 0.9492 - val_loss: 0.5762 - val_acc: 0.7969\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0780 - acc: 0.9701 - val_loss: 0.8650 - val_acc: 0.7031\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5216 - acc: 0.8112 - val_loss: 0.5212 - val_acc: 0.7656\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3424 - acc: 0.8737 - val_loss: 0.5204 - val_acc: 0.7344\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1403 - acc: 0.9453 - val_loss: 0.8583 - val_acc: 0.7031\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0732 - acc: 0.9753 - val_loss: 0.8741 - val_acc: 0.7188\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0706 - acc: 0.9727 - val_loss: 0.6126 - val_acc: 0.7812\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0669 - acc: 0.9740 - val_loss: 0.6989 - val_acc: 0.7188\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0478 - acc: 0.9792 - val_loss: 0.7752 - val_acc: 0.7344\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0548 - acc: 0.9805 - val_loss: 0.7855 - val_acc: 0.7500\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.973558\n",
      "ACC: 0.930000\n",
      "MCC : 0.864649\n",
      "TPR:0.884615\n",
      "FPR:0.020833\n",
      "Pre:0.978723\n",
      "F1:0.929293\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 56s 5s/step - loss: 0.7084 - acc: 0.5143 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6940 - acc: 0.5091 - val_loss: 0.6883 - val_acc: 0.5781\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6687 - acc: 0.5964 - val_loss: 0.6726 - val_acc: 0.5469\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.6262 - acc: 0.6458 - val_loss: 0.6218 - val_acc: 0.6562\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5830 - acc: 0.6849 - val_loss: 0.6528 - val_acc: 0.5938\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.5245 - acc: 0.7331 - val_loss: 0.6562 - val_acc: 0.6719\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4806 - acc: 0.7760 - val_loss: 0.5718 - val_acc: 0.6562\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.4171 - acc: 0.8086 - val_loss: 0.5899 - val_acc: 0.7031\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3403 - acc: 0.8542 - val_loss: 0.6385 - val_acc: 0.6719\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.2474 - acc: 0.9115 - val_loss: 0.7726 - val_acc: 0.7500\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.3319 - acc: 0.8633 - val_loss: 0.6860 - val_acc: 0.7188\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.2952 - acc: 0.8711 - val_loss: 0.7215 - val_acc: 0.6875\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1999 - acc: 0.9232 - val_loss: 0.6685 - val_acc: 0.7344\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.1410 - acc: 0.9349 - val_loss: 0.7121 - val_acc: 0.7500\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1475 - acc: 0.9401 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1317 - acc: 0.9388 - val_loss: 0.8716 - val_acc: 0.7031\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.5211 - acc: 0.7643 - val_loss: 0.6857 - val_acc: 0.5312\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4078 - acc: 0.8776 - val_loss: 0.6554 - val_acc: 0.7188\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4936 - acc: 0.8776 - val_loss: 1.4766 - val_acc: 0.5781\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.4674 - acc: 0.8099 - val_loss: 0.5944 - val_acc: 0.6719\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.1879 - acc: 0.9323 - val_loss: 0.8685 - val_acc: 0.7188\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0961 - acc: 0.9596 - val_loss: 0.9003 - val_acc: 0.7344\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 12s 1s/step - loss: 0.0724 - acc: 0.9701 - val_loss: 0.8204 - val_acc: 0.7656\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0797 - acc: 0.9779 - val_loss: 0.7979 - val_acc: 0.7344\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.0939 - acc: 0.9661 - val_loss: 0.8140 - val_acc: 0.7188\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.965074\n",
      "ACC: 0.920000\n",
      "MCC : 0.840482\n",
      "TPR:0.905660\n",
      "FPR:0.063830\n",
      "Pre:0.941176\n",
      "F1:0.923077\n",
      "--------------------------\n",
      "\n",
      "mean AUC: 0.916662\n",
      "mean ACC: 0.850000\n",
      "mean MCC : 0.715883\n",
      "mean TPR:0.794174\n",
      "mean FPR:0.093393\n",
      "mean Pre:0.901742\n",
      "mean F1:0.831679\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "dataset_name = 'MM'\n",
    "for rep in range(3):\n",
    "    n_splits = 10\n",
    "    TPRs =  np.zeros(n_splits)\n",
    "    FPRs = np.zeros(n_splits)\n",
    "    Precs = np.zeros(n_splits)\n",
    "    ACCs = np.zeros(n_splits)\n",
    "    F1s = np.zeros(n_splits)\n",
    "    MCCs = np.zeros(n_splits)\n",
    "    AUCs = np.zeros(n_splits)\n",
    "     \n",
    "    count = 0\n",
    "    for split in range(n_splits):\n",
    "        train_pairs_file = 'CV/train'+str(rep)+'-'+str(split)\n",
    "        test_pairs_file = 'CV/test'+str(rep)+'-'+str(split)\n",
    "        valid_pairs_file = 'CV/valid'+str(rep)+'-'+str(split)\n",
    "\n",
    "        batch_size = 64\n",
    "        train_generator = DataGenerator(   train_pairs_file,batch_size = batch_size )\n",
    "        test_generator = DataGenerator(   test_pairs_file,batch_size = batch_size)\n",
    "        valid_generator = DataGenerator(   valid_pairs_file,batch_size = batch_size)\n",
    "         \n",
    "        # model = build_model_without_att()\n",
    "        model = build_model()\n",
    "        save_model_name = 'CV/fusion_sent_GoplusSeq'+str(rep)+'-'+str(split) + '.hdf5'\n",
    "        \n",
    "        earlyStopping = EarlyStopping(monitor='val_acc', patience=10, verbose=0, mode='max')\n",
    "        save_checkpoint = ModelCheckpoint(save_model_name, save_best_only=True, monitor='val_acc', mode='max', save_weights_only=True)\n",
    "\n",
    "         \n",
    "        # validation_data = (valid_X, valid_Y),  verbose=1,callbacks=[earlyStopping, save_checkpoint]\n",
    "        #  max_queue_size=16, workers=8, use_multiprocessing=True,\n",
    "        # validation_data=valid_generator,callbacks=[earlyStopping, save_checkpoint] \n",
    "        hist = model.fit_generator(generator=train_generator,\n",
    "                    epochs = 50,verbose=1,validation_data=valid_generator,callbacks=[earlyStopping, save_checkpoint])\n",
    "         \n",
    "        \n",
    "        # model = load_model(save_model_name)\n",
    "        model.load_weights(save_model_name)\n",
    "        with open(test_pairs_file, 'r') as f:\n",
    "            test_ppi_pairs  =  f.readlines()\n",
    "\n",
    "        test_len = len(test_ppi_pairs) \n",
    "        list_IDs_temp = np.arange(test_len)\n",
    "\n",
    "        test_x, y_test = test_generator.all_data(list_IDs_temp)\n",
    "\n",
    "        y_pred_prob = model.predict(test_x)\n",
    "\n",
    "       \n",
    "        y_pred = (y_pred_prob > 0.5)\n",
    "        auc = metrics.roc_auc_score(y_test, y_pred_prob) \n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        pre = precision_score(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        precision, recall, _thresholds = metrics.precision_recall_curve(y_test, y_pred_prob)\n",
    "        pr_auc = metrics.auc(recall, precision)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total=tn+fp+fn+tp\n",
    "        sen = float(tp)/float(tp+fn)\n",
    "        sps = float(tn)/float((tn+fp))\n",
    "\n",
    "        tpr = float(tp)/float(tp+fn)\n",
    "        fpr = float(fp)/float((tn+fp))\n",
    "        print('--------------------------\\n')\n",
    "        print ('AUC: %f' % auc)\n",
    "        print ('ACC: %f' % acc) \n",
    "        # print(\"PRAUC: %f\" % pr_auc)\n",
    "        print ('MCC : %f' % mcc)\n",
    "        # print ('SEN: %f' % sen)\n",
    "        # print ('SEP: %f' % sps)\n",
    "        print('TPR:%f'%tpr)\n",
    "        print('FPR:%f'%fpr)\n",
    "        print('Pre:%f'%pre)\n",
    "        print('F1:%f'%f1)\n",
    "        print('--------------------------\\n')\n",
    "        TPRs[count] = tpr\n",
    "        FPRs[count] = fpr\n",
    "        Precs[count] =pre\n",
    "        ACCs[count] =acc\n",
    "        F1s[count] =f1\n",
    "        MCCs[count] =mcc\n",
    "        AUCs[count] =auc\n",
    "        count += 1\n",
    "        del test_x\n",
    "        del y_test\n",
    "    print ('mean AUC: %f' % np.mean(AUCs))\n",
    "    print ('mean ACC: %f' % np.mean(ACCs)) \n",
    "    print ('mean MCC : %f' % np.mean(MCCs))\n",
    "    print('mean TPR:%f'% np.mean(TPRs))\n",
    "    print('mean FPR:%f'% np.mean(FPRs))\n",
    "    print('mean Pre:%f'% np.mean(Precs))\n",
    "    print('mean F1:%f'% np.mean(F1s))\n",
    "    np.savez('fusion_sent_seq_and_go__incep_'+str(rep), AUCs=AUCs, ACCs=ACCs, MCCs=MCCs, TPRs = TPRs, FPRs=FPRs, Precs=Precs, F1s=F1s)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9275020133572374 0.85 0.7131436504501002 0.7804551903319003 0.08284395092462798 0.9086777904244887 0.8287383810334714\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "aucs = 0\n",
    "accs = 0\n",
    "mccs = 0\n",
    "tprs = 0\n",
    "fprs = 0\n",
    "pres = 0\n",
    "f1s  = 0\n",
    "for i in range(3):\n",
    "    for j in range(10):\n",
    "        results_file = 'CV/sent_fusion_'+str(i)+'-'+str(j)+'.npz'\n",
    "        results = np.load(results_file)\n",
    "        aucs += results['AUCs']\n",
    "        accs += results['ACCs']\n",
    "        mccs += results['MCCs']\n",
    "        tprs += results['TPRs']\n",
    "        fprs += results['FPRs']\n",
    "        pres += results['Precs']\n",
    "        f1s += results['F1s']\n",
    "        \n",
    "print(aucs/30, accs/30, mccs/30, tprs/30, fprs/30, pres/30, f1s/30)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
