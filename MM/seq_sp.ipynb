{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.layers import  GlobalAveragePooling1D, Input, Activation, MaxPooling1D, BatchNormalization, Dense, Dropout, Conv1D,GlobalMaxPooling1D\n",
    "from keras.layers import GRU,AveragePooling1D,CuDNNGRU\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model \n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "alphabet = np.array(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "                     'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y'])\n",
    "\n",
    "def label_sequence(line, MAX_SEQ_LEN, smi_ch_ind):\n",
    "\tX = np.zeros(MAX_SEQ_LEN)\n",
    "\n",
    "\tfor i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
    "\t\tX[i] = smi_ch_ind[ch]\n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "def letter_one_hot(aa):\n",
    "    one_hot = np.zeros(20)\n",
    "    for idx, letter in enumerate(alphabet):\n",
    "        if aa == letter:\n",
    "            one_hot[idx] = 1\n",
    "            return one_hot\n",
    "\n",
    "\n",
    "# Convert an entire protein to one-hot representation.\n",
    "def protein_one_hot(protein_sequence, MAX_SEQ_LEN):\n",
    "    #  Remove non-specific AA codes (very few are actually present in this dataset)\n",
    "    protein_sequence = protein_sequence.replace('B', '')\n",
    "    protein_sequence = protein_sequence.replace('J', '')\n",
    "    protein_sequence = protein_sequence.replace('O', '')\n",
    "    protein_sequence = protein_sequence.replace('U', '')\n",
    "    protein_sequence = protein_sequence.replace('X', '')\n",
    "    protein_sequence = protein_sequence.replace('Z', '')\n",
    "    one_hot_seq = np.zeros( (MAX_SEQ_LEN, 20))\n",
    "    for idx, aa in enumerate(protein_sequence[:MAX_SEQ_LEN]):\n",
    "        one_hot_seq[idx, :] = letter_one_hot(aa)\n",
    "    return one_hot_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "feature_len = 768\n",
    "max_go_len = 256\n",
    "max_seq_len = 1000\n",
    "\n",
    "from six.moves import cPickle as pickle #for performance\n",
    "\n",
    " \n",
    "def save_dict(di_, filename_):\n",
    "    with open(filename_, 'wb') as f:\n",
    "        pickle.dump(di_, f)\n",
    "\n",
    "def load_dict(filename_):\n",
    "    with open(filename_, 'rb') as f:\n",
    "        ret_di = pickle.load(f)\n",
    "    return ret_di\n",
    "\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self,  ppi_pair_file, batch_size=128):\n",
    "        'Initialization' \n",
    "        self.batch_size = batch_size\n",
    "        self.ppi_pair_file = ppi_pair_file\n",
    "         \n",
    "        self.max_seqlen = max_seq_len\n",
    "        self.max_golen = max_go_len\n",
    "         \n",
    "        self.protein2seq = load_dict('SPprot2seq.pkl')\n",
    "        self.read_ppi()\n",
    "        self.protein2onehot = {}\n",
    "        self.onehot_seqs()\n",
    "         \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def read_ppi(self):\n",
    "        with open(self.ppi_pair_file, 'r') as f:\n",
    "            self.ppi_pairs  =  f.readlines()\n",
    "    \n",
    "    def onehot_seqs(self):\n",
    "        for key, value in self.protein2seq.items():\n",
    "            self.protein2onehot[key] =  protein_one_hot(value, self.max_seqlen) \n",
    "            \n",
    "    \n",
    "   \n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.ppi_pairs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.ppi_pairs))\n",
    "         \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "\n",
    "         \n",
    "        X_seq1 = np.empty((self.batch_size, self.max_seqlen,20))\n",
    "        X_seq2 = np.empty((self.batch_size, self.max_seqlen,20))\n",
    "        y = np.empty((self.batch_size))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            ppi_pair = self.ppi_pairs[ID]\n",
    "            p1, p2, label = ppi_pair.rstrip().split('\\t')\n",
    "            if label == '+':\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "            X_seq1[i] =  self.protein2onehot[p1]\n",
    "            X_seq2[i] =  self.protein2onehot[p2]\n",
    "             \n",
    "            \n",
    "            \n",
    "        return [  X_seq1, X_seq2] ,  y\n",
    "\n",
    "\n",
    "\n",
    "    def all_data(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "\n",
    "         \n",
    "        X_seq1 = np.empty((len(list_IDs_temp), self.max_seqlen,20))\n",
    "\n",
    "         \n",
    "        X_seq2 = np.empty((len(list_IDs_temp), self.max_seqlen,20))\n",
    "        y = np.empty((len(list_IDs_temp)))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            ppi_pair = self.ppi_pairs[ID]\n",
    "            p1, p2, label = ppi_pair.rstrip().split('\\t')\n",
    "            if label == '+':\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "            X_seq1[i] =  self.protein2onehot[p1]\n",
    "            X_seq2[i] =  self.protein2onehot[p2]\n",
    "           \n",
    "        return [  X_seq1, X_seq2] ,  y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K, initializers, regularizers, constraints\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        # todo: check that this is correct\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True,\n",
    "                 return_attention=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Note: The layer has been tested with Keras 1.x\n",
    "        Example:\n",
    "            # 1\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "            # next add a Dense layer (for classification/regression) or whatever...\n",
    "            # 2 - Get the attention scores\n",
    "            hidden = LSTM(64, return_sequences=True)(words)\n",
    "            sentence, word_scores = Attention(return_attention=True)(hidden)\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        weighted_input = x * K.expand_dims(a)\n",
    "\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [result, a]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], input_shape[-1]),\n",
    "                    (input_shape[0], input_shape[1])]\n",
    "        else:\n",
    "            return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1000, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1000, 32)     1952        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1000, 32)     672         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1000, 32)     1952        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1000, 32)     672         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1000, 32)     5152        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1000, 32)     3104        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1000, 32)     1952        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1000, 32)     672         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1000, 32)     5152        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1000, 32)     3104        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1000, 32)     1952        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1000, 32)     672         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 128)    0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 128)    33024       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 128)    0           conv1d_8[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 128)    33024       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 128)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 128)    0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 128)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000, 128)    0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 128)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 512)          0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 512)          0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         525312      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          524800      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            513         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,406,337\n",
      "Trainable params: 1,406,337\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import   Embedding\n",
    "from keras.layers import  GRU, Bidirectional, CuDNNGRU, Lambda, Flatten\n",
    "from keras.layers.merge import concatenate\n",
    "def inception_block(input_tensor, output_size):\n",
    "    \"\"\"\"\"\"\n",
    "    con1d_filters = int(output_size/4)\n",
    "    y = Conv1D(con1d_filters, 3, activation=\"relu\", padding='same')(input_tensor)\n",
    "    x1 = Conv1D(con1d_filters, 5, activation=\"relu\", padding='same')(y)\n",
    "\n",
    "    y = Conv1D(con1d_filters, 1, activation=\"relu\", padding='valid')(input_tensor)\n",
    "    x2 = Conv1D(con1d_filters, 3, activation=\"relu\", padding='same')(y)\n",
    "\n",
    "    x3 = Conv1D(con1d_filters, 3, activation=\"relu\", padding='same')(input_tensor)\n",
    "    x4 = Conv1D(con1d_filters, 1, activation=\"relu\", padding='same')(input_tensor)\n",
    "\n",
    "    y = Concatenate()([x1, x2, x3, x4])\n",
    "#     y = MaxPooling1D(2)(mix0)\n",
    "    # y = AveragePooling1D()(mix0)\n",
    "#     y = BatchNormalization()(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "def create_share_model():\n",
    "    con_filters = 128\n",
    "    X_input = Input(shape=(max_seq_len,20))\n",
    "    # text-CNN\n",
    "#     卷积池化-全连接 ---拼接-全连接  -双向GRU-全连接\n",
    "    cnn = Conv1D(128, 3)(X_input)\n",
    "#     cnn = BatchNormalization()(cnn)\n",
    "    cnn = Activation('relu')(cnn)\n",
    "     \n",
    "    cnn = GlobalAveragePooling1D()(cnn)\n",
    "    \n",
    "    \n",
    "    model = Model(X_input, cnn)\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_siamese_model():\n",
    "    left_input_seq = Input(shape=(max_seq_len,20))  \n",
    "    right_input_seq = Input(shape=(max_seq_len,20))\n",
    "    \n",
    "    siamese_a = create_share_model()\n",
    "    siamese_b = create_share_model()\n",
    "    \n",
    "\n",
    "    encoded_l = siamese_a(left_input_seq)\n",
    "    encoded_r = siamese_b(right_input_seq)\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "#     dense = Dense(128,activation='relu')(L1_distance)\n",
    "    prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "\n",
    "    siamese_net = Model(inputs=[left_input_seq,right_input_seq],outputs=prediction)\n",
    "    \n",
    "    siamese_net.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return siamese_net\n",
    "\n",
    "def build_model():\n",
    "    con_filters = 128\n",
    "    \n",
    "    left_input_seq = Input(shape=(max_seq_len,20))  \n",
    "    right_input_seq = Input(shape=(max_seq_len,20))\n",
    "    \n",
    "    x = inception_block(left_input_seq,con_filters )\n",
    "    x = Dropout(0.3)(x)\n",
    "    x_gru = Bidirectional(CuDNNGRU(64, return_sequences=True))(left_input_seq)\n",
    "    x_gru = Dropout(0.3)(x_gru)\n",
    "    x_a = GlobalAveragePooling1D()(x)\n",
    "    x_b = GlobalMaxPooling1D()(x)\n",
    "    x_gru_a = GlobalAveragePooling1D()(x_gru)\n",
    "    x_gru_b = GlobalMaxPooling1D()(x_gru)\n",
    "    left_x_seq = Concatenate()([x_a  , x_b, x_gru_a, x_gru_b])\n",
    "    left_x_seq = Dense(256, activation='relu')(left_x_seq)\n",
    "     \n",
    " \n",
    "    x = inception_block(right_input_seq,con_filters )\n",
    "    x = Dropout(0.3)(x)\n",
    "    x_gru =Bidirectional(CuDNNGRU(64, return_sequences=True))(right_input_seq)\n",
    "    x_gru = Dropout(0.3)(x_gru)\n",
    "    x_a = GlobalAveragePooling1D()(x)\n",
    "    x_b = GlobalMaxPooling1D()(x)\n",
    "    x_gru_a = GlobalAveragePooling1D()(x_gru)\n",
    "    x_gru_b = GlobalMaxPooling1D()(x_gru)  \n",
    "    right_x_seq = Concatenate()([x_a  , x_b, x_gru_a, x_gru_b])\n",
    "    right_x_seq = Dense(256, activation='relu')(right_x_seq)\n",
    "     \n",
    "    x =   Concatenate()([left_x_seq, right_x_seq])\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "  \n",
    "    x = Dense(1)(x)\n",
    "    output = Activation('sigmoid')(x)\n",
    "    # model = Model([left_input_go, right_input_go], output)\n",
    "  \n",
    "    model = Model([left_input_seq, right_input_seq], output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.7060 - acc: 0.5161 - val_loss: 0.6933 - val_acc: 0.4883\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6945 - acc: 0.4848 - val_loss: 0.6933 - val_acc: 0.4883\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 7s 226ms/step - loss: 0.6932 - acc: 0.5152 - val_loss: 0.6919 - val_acc: 0.5234\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.6871 - acc: 0.5417 - val_loss: 0.6893 - val_acc: 0.5195\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.6691 - acc: 0.5852 - val_loss: 0.6899 - val_acc: 0.5195\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.5784 - acc: 0.6780 - val_loss: 0.6326 - val_acc: 0.6562\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 8s 246ms/step - loss: 0.5281 - acc: 0.7453 - val_loss: 0.5965 - val_acc: 0.6641\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 8s 238ms/step - loss: 0.4421 - acc: 0.8106 - val_loss: 0.8021 - val_acc: 0.5742\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.5453 - acc: 0.7424 - val_loss: 0.6067 - val_acc: 0.6133\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.3725 - acc: 0.8362 - val_loss: 0.5736 - val_acc: 0.6719\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.3366 - acc: 0.8513 - val_loss: 0.6223 - val_acc: 0.6914\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.2735 - acc: 0.8835 - val_loss: 0.5840 - val_acc: 0.6797\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.2274 - acc: 0.9119 - val_loss: 0.6116 - val_acc: 0.7109\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.2395 - acc: 0.8864 - val_loss: 0.6557 - val_acc: 0.6758\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 5s 162ms/step - loss: 0.1558 - acc: 0.9451 - val_loss: 0.6868 - val_acc: 0.6875\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 7s 204ms/step - loss: 0.2063 - acc: 0.9195 - val_loss: 0.6593 - val_acc: 0.7188\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.2138 - acc: 0.9129 - val_loss: 0.6757 - val_acc: 0.7109\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 7s 222ms/step - loss: 0.1809 - acc: 0.9261 - val_loss: 0.7349 - val_acc: 0.6992\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.0895 - acc: 0.9706 - val_loss: 0.8421 - val_acc: 0.7109\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 8s 253ms/step - loss: 0.1112 - acc: 0.9527 - val_loss: 0.7924 - val_acc: 0.7031\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.964082\n",
      "ACC: 0.893333\n",
      "MCC : 0.784952\n",
      "TPR:0.918033\n",
      "FPR:0.123596\n",
      "Pre:0.835821\n",
      "F1:0.875000\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 12s 363ms/step - loss: 0.7087 - acc: 0.4905 - val_loss: 0.6962 - val_acc: 0.4727\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 8s 254ms/step - loss: 0.6944 - acc: 0.4991 - val_loss: 0.7015 - val_acc: 0.4727\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 8s 254ms/step - loss: 0.6946 - acc: 0.4934 - val_loss: 0.6932 - val_acc: 0.4922\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 9s 258ms/step - loss: 0.6943 - acc: 0.5019 - val_loss: 0.6927 - val_acc: 0.5273\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.6946 - acc: 0.4962 - val_loss: 0.6926 - val_acc: 0.5469\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 195ms/step - loss: 0.6928 - acc: 0.5350 - val_loss: 0.6973 - val_acc: 0.4727\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 5s 162ms/step - loss: 0.6845 - acc: 0.5407 - val_loss: 0.7219 - val_acc: 0.4727\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.6689 - acc: 0.5616 - val_loss: 0.6923 - val_acc: 0.4727\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.6028 - acc: 0.6695 - val_loss: 0.6160 - val_acc: 0.6445\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 5s 162ms/step - loss: 0.5086 - acc: 0.7528 - val_loss: 0.6976 - val_acc: 0.5859\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 7s 223ms/step - loss: 0.4832 - acc: 0.7557 - val_loss: 0.6719 - val_acc: 0.5703\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.4970 - acc: 0.7680 - val_loss: 0.6114 - val_acc: 0.6758\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.4574 - acc: 0.7850 - val_loss: 0.7728 - val_acc: 0.5508\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 8s 237ms/step - loss: 0.4210 - acc: 0.8068 - val_loss: 0.6240 - val_acc: 0.7031\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 8s 239ms/step - loss: 0.3967 - acc: 0.8163 - val_loss: 0.8082 - val_acc: 0.5430\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 8s 241ms/step - loss: 0.3988 - acc: 0.8116 - val_loss: 0.8171 - val_acc: 0.5430\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 8s 241ms/step - loss: 0.3798 - acc: 0.8182 - val_loss: 0.6578 - val_acc: 0.6523\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.3410 - acc: 0.8447 - val_loss: 0.9395 - val_acc: 0.5352\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.3440 - acc: 0.8409 - val_loss: 0.7215 - val_acc: 0.6211\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.3307 - acc: 0.8494 - val_loss: 0.7336 - val_acc: 0.6211\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 6s 188ms/step - loss: 0.3375 - acc: 0.8532 - val_loss: 0.7939 - val_acc: 0.5625\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 6s 170ms/step - loss: 0.3602 - acc: 0.8362 - val_loss: 0.8948 - val_acc: 0.5273\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.905600\n",
      "ACC: 0.826667\n",
      "MCC : 0.673003\n",
      "TPR:0.706667\n",
      "FPR:0.053333\n",
      "Pre:0.929825\n",
      "F1:0.803030\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 10s 302ms/step - loss: 0.7107 - acc: 0.4886 - val_loss: 0.6952 - val_acc: 0.4883\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.6951 - acc: 0.4886 - val_loss: 0.6929 - val_acc: 0.4766\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.6940 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.5117\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.6942 - acc: 0.5009 - val_loss: 0.6937 - val_acc: 0.5117\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.6939 - acc: 0.4924 - val_loss: 0.6943 - val_acc: 0.4883\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.6880 - acc: 0.5256 - val_loss: 0.6886 - val_acc: 0.5859\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.6782 - acc: 0.5985 - val_loss: 0.7034 - val_acc: 0.5117\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.6521 - acc: 0.5900 - val_loss: 0.6577 - val_acc: 0.5859\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.5186 - acc: 0.7405 - val_loss: 0.6089 - val_acc: 0.6875\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.4580 - acc: 0.7661 - val_loss: 0.6171 - val_acc: 0.6172\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 7s 227ms/step - loss: 0.3636 - acc: 0.8523 - val_loss: 0.6312 - val_acc: 0.6289\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.3598 - acc: 0.8362 - val_loss: 0.5941 - val_acc: 0.6641\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 5s 158ms/step - loss: 0.2353 - acc: 0.8977 - val_loss: 0.6945 - val_acc: 0.6328\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.2211 - acc: 0.9195 - val_loss: 1.3319 - val_acc: 0.5430\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.1978 - acc: 0.9167 - val_loss: 0.6586 - val_acc: 0.7031\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 5s 166ms/step - loss: 0.1734 - acc: 0.9318 - val_loss: 0.8513 - val_acc: 0.6406\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 7s 214ms/step - loss: 0.1949 - acc: 0.9290 - val_loss: 0.7416 - val_acc: 0.6445\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 8s 244ms/step - loss: 0.1233 - acc: 0.9593 - val_loss: 1.0285 - val_acc: 0.5898\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.2372 - acc: 0.9034 - val_loss: 0.9251 - val_acc: 0.6016\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 8s 242ms/step - loss: 0.1970 - acc: 0.9148 - val_loss: 0.8662 - val_acc: 0.6094\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 8s 238ms/step - loss: 0.1043 - acc: 0.9697 - val_loss: 0.8819 - val_acc: 0.6641\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 8s 242ms/step - loss: 0.0909 - acc: 0.9659 - val_loss: 0.9008 - val_acc: 0.6758\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.938840\n",
      "ACC: 0.858108\n",
      "MCC : 0.713351\n",
      "TPR:0.848485\n",
      "FPR:0.134146\n",
      "Pre:0.835821\n",
      "F1:0.842105\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 12s 349ms/step - loss: 0.7075 - acc: 0.4943 - val_loss: 0.6910 - val_acc: 0.5703\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 5s 165ms/step - loss: 0.6934 - acc: 0.5152 - val_loss: 0.7116 - val_acc: 0.4297\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.6936 - acc: 0.5180 - val_loss: 0.6977 - val_acc: 0.4297\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 196ms/step - loss: 0.6954 - acc: 0.5170 - val_loss: 0.6872 - val_acc: 0.5703\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.6946 - acc: 0.5019 - val_loss: 0.6942 - val_acc: 0.4297\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 169ms/step - loss: 0.6908 - acc: 0.5417 - val_loss: 0.6884 - val_acc: 0.5391\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 8s 241ms/step - loss: 0.6859 - acc: 0.5843 - val_loss: 0.6813 - val_acc: 0.5742\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 8s 254ms/step - loss: 0.6478 - acc: 0.6108 - val_loss: 0.6480 - val_acc: 0.6367\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.5455 - acc: 0.7244 - val_loss: 0.7989 - val_acc: 0.5430\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 242ms/step - loss: 0.4744 - acc: 0.7869 - val_loss: 0.9140 - val_acc: 0.5039\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 8s 253ms/step - loss: 0.4228 - acc: 0.8087 - val_loss: 0.6957 - val_acc: 0.6133\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 8s 247ms/step - loss: 0.3015 - acc: 0.8693 - val_loss: 1.1372 - val_acc: 0.5625\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.2480 - acc: 0.8977 - val_loss: 0.6620 - val_acc: 0.6992\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.3817 - acc: 0.8324 - val_loss: 0.7254 - val_acc: 0.6055\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.2643 - acc: 0.9044 - val_loss: 0.8257 - val_acc: 0.6172\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.1521 - acc: 0.9470 - val_loss: 1.1932 - val_acc: 0.5977\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 168ms/step - loss: 0.1418 - acc: 0.9460 - val_loss: 1.0768 - val_acc: 0.5938\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 187ms/step - loss: 0.1266 - acc: 0.9517 - val_loss: 0.9504 - val_acc: 0.6992\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.807096\n",
      "ACC: 0.743243\n",
      "MCC : 0.520075\n",
      "TPR:0.647059\n",
      "FPR:0.126984\n",
      "Pre:0.873016\n",
      "F1:0.743243\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 14s 416ms/step - loss: 0.7177 - acc: 0.4981 - val_loss: 0.6921 - val_acc: 0.5273\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.6936 - acc: 0.4972 - val_loss: 0.6925 - val_acc: 0.5391\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 8s 253ms/step - loss: 0.6934 - acc: 0.5161 - val_loss: 0.6959 - val_acc: 0.4727\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.6879 - acc: 0.5464 - val_loss: 0.6808 - val_acc: 0.5391\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.6776 - acc: 0.5777 - val_loss: 0.6719 - val_acc: 0.6523\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.6485 - acc: 0.6345 - val_loss: 0.6654 - val_acc: 0.5312\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 7s 214ms/step - loss: 0.5276 - acc: 0.7500 - val_loss: 0.5901 - val_acc: 0.6758\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.4394 - acc: 0.7860 - val_loss: 0.6241 - val_acc: 0.6211\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 5s 157ms/step - loss: 0.3195 - acc: 0.8665 - val_loss: 0.6654 - val_acc: 0.6367\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 170ms/step - loss: 0.2366 - acc: 0.9072 - val_loss: 0.6775 - val_acc: 0.6523\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.2769 - acc: 0.8807 - val_loss: 0.6774 - val_acc: 0.6992\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 170ms/step - loss: 0.2406 - acc: 0.9053 - val_loss: 0.6951 - val_acc: 0.6406\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.1469 - acc: 0.9517 - val_loss: 0.7839 - val_acc: 0.6758\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.2367 - acc: 0.9186 - val_loss: 0.6865 - val_acc: 0.6719\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.2012 - acc: 0.9186 - val_loss: 0.7497 - val_acc: 0.6602\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 8s 237ms/step - loss: 0.1492 - acc: 0.9422 - val_loss: 0.8217 - val_acc: 0.6680\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.1114 - acc: 0.9612 - val_loss: 0.8646 - val_acc: 0.6797\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.938543\n",
      "ACC: 0.885135\n",
      "MCC : 0.776831\n",
      "TPR:0.835443\n",
      "FPR:0.057971\n",
      "Pre:0.942857\n",
      "F1:0.885906\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 14s 410ms/step - loss: 0.7093 - acc: 0.5104 - val_loss: 0.6947 - val_acc: 0.4883\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 168ms/step - loss: 0.6972 - acc: 0.4867 - val_loss: 0.6929 - val_acc: 0.5820\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 169ms/step - loss: 0.6940 - acc: 0.5152 - val_loss: 0.6935 - val_acc: 0.4883\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 0.6906 - acc: 0.5331 - val_loss: 0.6930 - val_acc: 0.5117\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.6907 - acc: 0.5170 - val_loss: 0.6766 - val_acc: 0.6562\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6224 - acc: 0.6572 - val_loss: 0.6074 - val_acc: 0.6680\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.5317 - acc: 0.7415 - val_loss: 0.5898 - val_acc: 0.6562\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.3935 - acc: 0.8362 - val_loss: 0.5332 - val_acc: 0.7344\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.3617 - acc: 0.8343 - val_loss: 0.5164 - val_acc: 0.7422\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.3775 - acc: 0.8371 - val_loss: 0.5141 - val_acc: 0.7617\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.2946 - acc: 0.8902 - val_loss: 0.5650 - val_acc: 0.7227\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.2105 - acc: 0.9252 - val_loss: 0.7684 - val_acc: 0.6562\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.3456 - acc: 0.8494 - val_loss: 0.5092 - val_acc: 0.7695\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.1719 - acc: 0.9498 - val_loss: 0.5626 - val_acc: 0.7734\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 8s 256ms/step - loss: 0.1770 - acc: 0.9299 - val_loss: 0.6796 - val_acc: 0.7148\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.2325 - acc: 0.9044 - val_loss: 0.6261 - val_acc: 0.7227\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 187ms/step - loss: 0.1455 - acc: 0.9451 - val_loss: 0.6212 - val_acc: 0.7109\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.1507 - acc: 0.9366 - val_loss: 0.7036 - val_acc: 0.7188\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 5s 167ms/step - loss: 0.1227 - acc: 0.9517 - val_loss: 0.6426 - val_acc: 0.7734\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.1171 - acc: 0.9489 - val_loss: 0.6538 - val_acc: 0.7656\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 7s 204ms/step - loss: 0.1444 - acc: 0.9432 - val_loss: 0.6944 - val_acc: 0.7305\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 5s 164ms/step - loss: 0.1279 - acc: 0.9508 - val_loss: 0.8132 - val_acc: 0.6875\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.1108 - acc: 0.9489 - val_loss: 0.7101 - val_acc: 0.7383\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.936797\n",
      "ACC: 0.837838\n",
      "MCC : 0.690805\n",
      "TPR:0.765432\n",
      "FPR:0.074627\n",
      "Pre:0.925373\n",
      "F1:0.837838\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 15s 441ms/step - loss: 0.7125 - acc: 0.5237 - val_loss: 0.7000 - val_acc: 0.4688\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.6976 - acc: 0.4735 - val_loss: 0.6967 - val_acc: 0.4688\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 8s 246ms/step - loss: 0.6931 - acc: 0.5114 - val_loss: 0.6908 - val_acc: 0.5312\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 246ms/step - loss: 0.6938 - acc: 0.4905 - val_loss: 0.6903 - val_acc: 0.5312\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 241ms/step - loss: 0.6882 - acc: 0.5549 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.6864 - acc: 0.6080 - val_loss: 0.6936 - val_acc: 0.5312\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 8s 247ms/step - loss: 0.6847 - acc: 0.5549 - val_loss: 0.6801 - val_acc: 0.5977\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.6843 - acc: 0.5521 - val_loss: 0.6948 - val_acc: 0.4688\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.6304 - acc: 0.6307 - val_loss: 0.6918 - val_acc: 0.5039\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.5095 - acc: 0.7472 - val_loss: 0.9004 - val_acc: 0.4609\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 6s 187ms/step - loss: 0.4377 - acc: 0.7936 - val_loss: 0.7142 - val_acc: 0.5898\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.4089 - acc: 0.8087 - val_loss: 0.6694 - val_acc: 0.6055\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 167ms/step - loss: 0.3371 - acc: 0.8542 - val_loss: 0.7646 - val_acc: 0.5547\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.3654 - acc: 0.8352 - val_loss: 0.6919 - val_acc: 0.6250\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.2961 - acc: 0.8731 - val_loss: 0.7616 - val_acc: 0.6055\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 170ms/step - loss: 0.2163 - acc: 0.9261 - val_loss: 0.7108 - val_acc: 0.6680\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.2039 - acc: 0.9195 - val_loss: 0.7552 - val_acc: 0.6641\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.2026 - acc: 0.9242 - val_loss: 0.9393 - val_acc: 0.5977\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 8s 254ms/step - loss: 0.1533 - acc: 0.9460 - val_loss: 0.9080 - val_acc: 0.6289\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.1460 - acc: 0.9403 - val_loss: 0.8035 - val_acc: 0.6602\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.1771 - acc: 0.9252 - val_loss: 1.0204 - val_acc: 0.6289\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.1771 - acc: 0.9366 - val_loss: 0.7667 - val_acc: 0.6992\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.956522\n",
      "ACC: 0.851351\n",
      "MCC : 0.713920\n",
      "TPR:0.927536\n",
      "FPR:0.215190\n",
      "Pre:0.790123\n",
      "F1:0.853333\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 15s 452ms/step - loss: 0.7092 - acc: 0.4621 - val_loss: 0.7008 - val_acc: 0.4570\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.6926 - acc: 0.5246 - val_loss: 0.6887 - val_acc: 0.5430\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 5s 165ms/step - loss: 0.6900 - acc: 0.5322 - val_loss: 0.6952 - val_acc: 0.4531\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.6823 - acc: 0.5511 - val_loss: 0.6757 - val_acc: 0.5938\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 7s 203ms/step - loss: 0.6105 - acc: 0.6506 - val_loss: 0.6558 - val_acc: 0.5781\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 5s 163ms/step - loss: 0.5066 - acc: 0.7481 - val_loss: 0.6419 - val_acc: 0.6250\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 170ms/step - loss: 0.4709 - acc: 0.7670 - val_loss: 0.5618 - val_acc: 0.6992\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.3215 - acc: 0.8741 - val_loss: 1.1679 - val_acc: 0.4844\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 8s 242ms/step - loss: 0.3125 - acc: 0.8816 - val_loss: 0.6186 - val_acc: 0.7148\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 247ms/step - loss: 0.2712 - acc: 0.8930 - val_loss: 0.6371 - val_acc: 0.6680\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.1890 - acc: 0.9299 - val_loss: 0.6121 - val_acc: 0.6992\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 8s 238ms/step - loss: 0.1907 - acc: 0.9271 - val_loss: 0.6363 - val_acc: 0.7031\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.2003 - acc: 0.9271 - val_loss: 1.0519 - val_acc: 0.5938\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.1914 - acc: 0.9233 - val_loss: 0.7532 - val_acc: 0.6641\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 8s 239ms/step - loss: 0.2662 - acc: 0.8911 - val_loss: 0.7743 - val_acc: 0.6484\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.1479 - acc: 0.9489 - val_loss: 0.7381 - val_acc: 0.6758\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 7s 215ms/step - loss: 0.1052 - acc: 0.9602 - val_loss: 0.7135 - val_acc: 0.7070\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.935348\n",
      "ACC: 0.891892\n",
      "MCC : 0.783121\n",
      "TPR:0.871429\n",
      "FPR:0.089744\n",
      "Pre:0.897059\n",
      "F1:0.884058\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 15s 448ms/step - loss: 0.7033 - acc: 0.4801 - val_loss: 0.6945 - val_acc: 0.4727\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.6950 - acc: 0.5123 - val_loss: 0.6944 - val_acc: 0.4727\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 8s 234ms/step - loss: 0.6925 - acc: 0.5218 - val_loss: 0.6879 - val_acc: 0.5273\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 246ms/step - loss: 0.6909 - acc: 0.5294 - val_loss: 0.6839 - val_acc: 0.5273\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 241ms/step - loss: 0.6552 - acc: 0.5928 - val_loss: 0.6346 - val_acc: 0.6328\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 8s 240ms/step - loss: 0.5724 - acc: 0.6884 - val_loss: 0.5958 - val_acc: 0.6797\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 9s 259ms/step - loss: 0.4197 - acc: 0.8267 - val_loss: 0.6083 - val_acc: 0.6914\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 8s 253ms/step - loss: 0.3815 - acc: 0.8352 - val_loss: 0.5897 - val_acc: 0.6758\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 8s 255ms/step - loss: 0.2996 - acc: 0.8693 - val_loss: 0.6083 - val_acc: 0.6914\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.2799 - acc: 0.8873 - val_loss: 0.6621 - val_acc: 0.6602\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.2001 - acc: 0.9261 - val_loss: 0.6805 - val_acc: 0.6758\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 0.1725 - acc: 0.9384 - val_loss: 0.7775 - val_acc: 0.6836\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.2197 - acc: 0.9138 - val_loss: 0.7415 - val_acc: 0.6875\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.1906 - acc: 0.9214 - val_loss: 0.7376 - val_acc: 0.6797\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 6s 187ms/step - loss: 0.1567 - acc: 0.9384 - val_loss: 0.8017 - val_acc: 0.6797\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 186ms/step - loss: 0.1432 - acc: 0.9451 - val_loss: 0.9145 - val_acc: 0.6562\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.1206 - acc: 0.9479 - val_loss: 0.7590 - val_acc: 0.6953\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 0.2321 - acc: 0.9072 - val_loss: 0.7473 - val_acc: 0.6719\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.934432\n",
      "ACC: 0.871622\n",
      "MCC : 0.744557\n",
      "TPR:0.923077\n",
      "FPR:0.185714\n",
      "Pre:0.847059\n",
      "F1:0.883436\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 15s 469ms/step - loss: 0.7130 - acc: 0.4972 - val_loss: 0.6920 - val_acc: 0.5273\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 8s 246ms/step - loss: 0.6954 - acc: 0.5227 - val_loss: 0.6923 - val_acc: 0.5273\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.6954 - acc: 0.5000 - val_loss: 0.6943 - val_acc: 0.4727\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 242ms/step - loss: 0.6939 - acc: 0.5057 - val_loss: 0.6939 - val_acc: 0.4727\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 239ms/step - loss: 0.6933 - acc: 0.5303 - val_loss: 0.7022 - val_acc: 0.4727\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 7s 200ms/step - loss: 0.6915 - acc: 0.5199 - val_loss: 0.6919 - val_acc: 0.5273\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6913 - acc: 0.5294 - val_loss: 0.6930 - val_acc: 0.4961\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 5s 163ms/step - loss: 0.6801 - acc: 0.5483 - val_loss: 0.6917 - val_acc: 0.5391\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.6459 - acc: 0.6354 - val_loss: 0.6582 - val_acc: 0.5820\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.6141 - acc: 0.6799 - val_loss: 0.6411 - val_acc: 0.6250\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 6s 194ms/step - loss: 0.5726 - acc: 0.7169 - val_loss: 0.7684 - val_acc: 0.5430\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 0.4907 - acc: 0.7765 - val_loss: 0.7156 - val_acc: 0.5938\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.4733 - acc: 0.7831 - val_loss: 0.7388 - val_acc: 0.6055\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.4614 - acc: 0.7699 - val_loss: 0.6516 - val_acc: 0.6172\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.4222 - acc: 0.8068 - val_loss: 0.6615 - val_acc: 0.6250\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.4132 - acc: 0.8201 - val_loss: 0.7345 - val_acc: 0.6133\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.3773 - acc: 0.8352 - val_loss: 0.6945 - val_acc: 0.6133\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 8s 255ms/step - loss: 0.3402 - acc: 0.8542 - val_loss: 0.8290 - val_acc: 0.5898\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.3607 - acc: 0.8314 - val_loss: 0.7864 - val_acc: 0.6055\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.3775 - acc: 0.8248 - val_loss: 0.7059 - val_acc: 0.6406\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.868864\n",
      "ACC: 0.770270\n",
      "MCC : 0.539697\n",
      "TPR:0.833333\n",
      "FPR:0.300000\n",
      "Pre:0.755814\n",
      "F1:0.792683\n",
      "--------------------------\n",
      "\n",
      "mean AUC: 0.918612\n",
      "mean ACC: 0.842946\n",
      "mean MCC : 0.694031\n",
      "mean TPR:0.827649\n",
      "mean FPR:0.136130\n",
      "mean Pre:0.863277\n",
      "mean F1:0.840063\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 17s 523ms/step - loss: 0.7048 - acc: 0.5038 - val_loss: 0.6918 - val_acc: 0.5234\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.6956 - acc: 0.4991 - val_loss: 0.6922 - val_acc: 0.5234\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6957 - acc: 0.4991 - val_loss: 0.6939 - val_acc: 0.4766\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.6945 - acc: 0.5114 - val_loss: 0.6947 - val_acc: 0.4766\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.6916 - acc: 0.5076 - val_loss: 0.6933 - val_acc: 0.4766\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6928 - acc: 0.5218 - val_loss: 0.6924 - val_acc: 0.4766\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6852 - acc: 0.5729 - val_loss: 0.6891 - val_acc: 0.4805\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 5s 164ms/step - loss: 0.6445 - acc: 0.6023 - val_loss: 0.6827 - val_acc: 0.5078\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 7s 218ms/step - loss: 0.6061 - acc: 0.6449 - val_loss: 0.6961 - val_acc: 0.5078\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.5166 - acc: 0.7434 - val_loss: 0.6395 - val_acc: 0.6133\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 8s 253ms/step - loss: 0.4448 - acc: 0.8021 - val_loss: 0.6826 - val_acc: 0.6172\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 8s 254ms/step - loss: 0.4124 - acc: 0.8116 - val_loss: 0.6830 - val_acc: 0.6641\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 8s 240ms/step - loss: 0.4601 - acc: 0.7737 - val_loss: 0.6678 - val_acc: 0.6680\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 8s 246ms/step - loss: 0.5399 - acc: 0.7244 - val_loss: 0.6753 - val_acc: 0.6680\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 8s 240ms/step - loss: 0.4337 - acc: 0.7926 - val_loss: 0.6789 - val_acc: 0.6719\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.4052 - acc: 0.8239 - val_loss: 0.6840 - val_acc: 0.6055\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.3426 - acc: 0.8627 - val_loss: 0.7534 - val_acc: 0.6562\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 7s 204ms/step - loss: 0.3249 - acc: 0.8494 - val_loss: 0.7688 - val_acc: 0.6484\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.3236 - acc: 0.8636 - val_loss: 0.7647 - val_acc: 0.6484\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 5s 163ms/step - loss: 0.3047 - acc: 0.8636 - val_loss: 0.8166 - val_acc: 0.6641\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.868529\n",
      "ACC: 0.760000\n",
      "MCC : 0.534560\n",
      "TPR:0.662338\n",
      "FPR:0.136986\n",
      "Pre:0.836066\n",
      "F1:0.739130\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 15s 454ms/step - loss: 0.7179 - acc: 0.4953 - val_loss: 0.6912 - val_acc: 0.5352\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.6942 - acc: 0.4867 - val_loss: 0.6938 - val_acc: 0.4648\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.6935 - acc: 0.5095 - val_loss: 0.6922 - val_acc: 0.5352\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 257ms/step - loss: 0.6930 - acc: 0.5350 - val_loss: 0.6975 - val_acc: 0.4648\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 247ms/step - loss: 0.6945 - acc: 0.5218 - val_loss: 0.6847 - val_acc: 0.5977\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.6877 - acc: 0.5587 - val_loss: 0.6669 - val_acc: 0.6875\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.6301 - acc: 0.6307 - val_loss: 0.6257 - val_acc: 0.5859\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 8s 254ms/step - loss: 0.5365 - acc: 0.7027 - val_loss: 0.5587 - val_acc: 0.7227\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.5459 - acc: 0.7358 - val_loss: 0.6555 - val_acc: 0.5664\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.3990 - acc: 0.8381 - val_loss: 0.6872 - val_acc: 0.6484\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.4281 - acc: 0.7907 - val_loss: 0.7001 - val_acc: 0.6016\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.3425 - acc: 0.8655 - val_loss: 0.6421 - val_acc: 0.6797\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.2410 - acc: 0.9062 - val_loss: 0.5903 - val_acc: 0.7148\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 5s 167ms/step - loss: 0.2090 - acc: 0.9167 - val_loss: 0.6594 - val_acc: 0.7070\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.2122 - acc: 0.9100 - val_loss: 0.6219 - val_acc: 0.7383\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.1667 - acc: 0.9394 - val_loss: 0.6488 - val_acc: 0.7227\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.1262 - acc: 0.9489 - val_loss: 0.7005 - val_acc: 0.7109\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 168ms/step - loss: 0.2115 - acc: 0.9138 - val_loss: 1.0410 - val_acc: 0.6484\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.915673\n",
      "ACC: 0.833333\n",
      "MCC : 0.667327\n",
      "TPR:0.794521\n",
      "FPR:0.129870\n",
      "Pre:0.852941\n",
      "F1:0.822695\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 17s 513ms/step - loss: 0.7172 - acc: 0.5114 - val_loss: 0.6947 - val_acc: 0.4766\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.6949 - acc: 0.4886 - val_loss: 0.6938 - val_acc: 0.4766\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.6944 - acc: 0.4773 - val_loss: 0.6929 - val_acc: 0.5234\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.6917 - acc: 0.5284 - val_loss: 0.6917 - val_acc: 0.5234\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 242ms/step - loss: 0.6965 - acc: 0.4602 - val_loss: 0.6932 - val_acc: 0.4766\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 188ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6937 - val_acc: 0.4766\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.6936 - acc: 0.5199 - val_loss: 0.6918 - val_acc: 0.5117\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 167ms/step - loss: 0.6933 - acc: 0.5009 - val_loss: 0.6916 - val_acc: 0.5234\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.6943 - acc: 0.4934 - val_loss: 0.6929 - val_acc: 0.5820\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6927 - acc: 0.5218 - val_loss: 0.6936 - val_acc: 0.4766\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 7s 205ms/step - loss: 0.6935 - acc: 0.5142 - val_loss: 0.6949 - val_acc: 0.4766\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.6941 - acc: 0.4877 - val_loss: 0.6934 - val_acc: 0.4766\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6934 - acc: 0.5133 - val_loss: 0.6935 - val_acc: 0.4766\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.6933 - acc: 0.5066 - val_loss: 0.6940 - val_acc: 0.4766\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6932 - acc: 0.5066 - val_loss: 0.6937 - val_acc: 0.4766\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.6934 - acc: 0.5019 - val_loss: 0.6937 - val_acc: 0.4766\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 8s 257ms/step - loss: 0.6933 - acc: 0.5066 - val_loss: 0.6939 - val_acc: 0.4766\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 9s 258ms/step - loss: 0.6932 - acc: 0.5066 - val_loss: 0.6938 - val_acc: 0.4766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n",
      "AUC: 0.584270\n",
      "ACC: 0.398649\n",
      "MCC : 0.000000\n",
      "TPR:1.000000\n",
      "FPR:1.000000\n",
      "Pre:0.398649\n",
      "F1:0.570048\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 19s 580ms/step - loss: 0.7210 - acc: 0.4725 - val_loss: 0.7004 - val_acc: 0.4844\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.6967 - acc: 0.4896 - val_loss: 0.6932 - val_acc: 0.4844\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6934 - acc: 0.4943 - val_loss: 0.6921 - val_acc: 0.5156\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.6927 - acc: 0.5038 - val_loss: 0.6898 - val_acc: 0.5742\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 179ms/step - loss: 0.6859 - acc: 0.5502 - val_loss: 0.7017 - val_acc: 0.4844\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.6669 - acc: 0.5767 - val_loss: 0.7206 - val_acc: 0.5156\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6165 - acc: 0.6733 - val_loss: 0.7224 - val_acc: 0.5195\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.5981 - acc: 0.6932 - val_loss: 0.7058 - val_acc: 0.5273\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 188ms/step - loss: 0.5907 - acc: 0.6667 - val_loss: 0.6237 - val_acc: 0.6055\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.4810 - acc: 0.7964 - val_loss: 0.6917 - val_acc: 0.5977\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.4300 - acc: 0.8144 - val_loss: 0.6478 - val_acc: 0.6680\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 8s 246ms/step - loss: 0.4056 - acc: 0.8277 - val_loss: 0.6617 - val_acc: 0.6133\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 8s 247ms/step - loss: 0.5009 - acc: 0.7519 - val_loss: 0.6657 - val_acc: 0.6133\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 8s 246ms/step - loss: 0.3847 - acc: 0.8466 - val_loss: 0.9290 - val_acc: 0.5586\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.4391 - acc: 0.7841 - val_loss: 0.6204 - val_acc: 0.6367\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.3600 - acc: 0.8494 - val_loss: 0.6875 - val_acc: 0.6445\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.4105 - acc: 0.8087 - val_loss: 0.6899 - val_acc: 0.6172\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 7s 205ms/step - loss: 0.3552 - acc: 0.8428 - val_loss: 0.7133 - val_acc: 0.6523\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.3248 - acc: 0.8665 - val_loss: 0.7297 - val_acc: 0.6211\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.3329 - acc: 0.8608 - val_loss: 0.8126 - val_acc: 0.6641\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 5s 164ms/step - loss: 0.3416 - acc: 0.8494 - val_loss: 0.7168 - val_acc: 0.6250\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.3533 - acc: 0.8494 - val_loss: 0.7338 - val_acc: 0.6406\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.3168 - acc: 0.8665 - val_loss: 0.7545 - val_acc: 0.6367\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.3541 - acc: 0.8390 - val_loss: 0.7430 - val_acc: 0.6367\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.3425 - acc: 0.8447 - val_loss: 0.7181 - val_acc: 0.6484\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.888828\n",
      "ACC: 0.770270\n",
      "MCC : 0.558045\n",
      "TPR:0.683544\n",
      "FPR:0.130435\n",
      "Pre:0.857143\n",
      "F1:0.760563\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 18s 553ms/step - loss: 0.7158 - acc: 0.4877 - val_loss: 0.6945 - val_acc: 0.4922\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 8s 255ms/step - loss: 0.6937 - acc: 0.5038 - val_loss: 0.6926 - val_acc: 0.5078\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.6948 - acc: 0.5114 - val_loss: 0.6925 - val_acc: 0.5078\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 247ms/step - loss: 0.6955 - acc: 0.4962 - val_loss: 0.6926 - val_acc: 0.5078\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6933 - acc: 0.5095 - val_loss: 0.6924 - val_acc: 0.4922\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6895 - acc: 0.5246 - val_loss: 0.6851 - val_acc: 0.5430\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 169ms/step - loss: 0.6863 - acc: 0.5634 - val_loss: 0.6729 - val_acc: 0.5664\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.6188 - acc: 0.6591 - val_loss: 0.6076 - val_acc: 0.6523\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.5561 - acc: 0.6913 - val_loss: 0.5923 - val_acc: 0.6836\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.4688 - acc: 0.7718 - val_loss: 0.6092 - val_acc: 0.6406\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.3795 - acc: 0.8277 - val_loss: 0.7114 - val_acc: 0.5977\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.3493 - acc: 0.8390 - val_loss: 0.5778 - val_acc: 0.7188\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.2461 - acc: 0.9006 - val_loss: 0.6304 - val_acc: 0.7148\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.2287 - acc: 0.8968 - val_loss: 0.6455 - val_acc: 0.7031\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.2241 - acc: 0.8987 - val_loss: 0.5996 - val_acc: 0.7266\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 7s 218ms/step - loss: 0.1742 - acc: 0.9261 - val_loss: 0.6867 - val_acc: 0.7266\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.1092 - acc: 0.9640 - val_loss: 0.7366 - val_acc: 0.7266\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.1498 - acc: 0.9394 - val_loss: 0.7494 - val_acc: 0.7148\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 8s 246ms/step - loss: 0.1757 - acc: 0.9223 - val_loss: 0.6588 - val_acc: 0.7148\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.3165 - acc: 0.8570 - val_loss: 0.7587 - val_acc: 0.6211\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.1435 - acc: 0.9470 - val_loss: 0.6220 - val_acc: 0.7422\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0888 - acc: 0.9744 - val_loss: 0.7644 - val_acc: 0.7109\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.947729\n",
      "ACC: 0.864865\n",
      "MCC : 0.733429\n",
      "TPR:0.738462\n",
      "FPR:0.036145\n",
      "Pre:0.941176\n",
      "F1:0.827586\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 16s 497ms/step - loss: 0.7220 - acc: 0.4934 - val_loss: 0.6932 - val_acc: 0.4961\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6952 - acc: 0.4943 - val_loss: 0.6934 - val_acc: 0.4961\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6952 - acc: 0.4943 - val_loss: 0.6933 - val_acc: 0.4961\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6950 - acc: 0.4953 - val_loss: 0.6933 - val_acc: 0.5039\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.6935 - acc: 0.5095 - val_loss: 0.6929 - val_acc: 0.5039\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.6934 - acc: 0.5189 - val_loss: 0.6926 - val_acc: 0.4961\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.6935 - acc: 0.4943 - val_loss: 0.6931 - val_acc: 0.5039\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 8s 254ms/step - loss: 0.6934 - acc: 0.4905 - val_loss: 0.6931 - val_acc: 0.5039\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.6932 - acc: 0.4991 - val_loss: 0.6932 - val_acc: 0.5039\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 9s 258ms/step - loss: 0.6933 - acc: 0.4915 - val_loss: 0.6932 - val_acc: 0.5039\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 8s 255ms/step - loss: 0.6941 - acc: 0.4943 - val_loss: 0.6932 - val_acc: 0.4961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.6932 - acc: 0.4981 - val_loss: 0.6932 - val_acc: 0.4961\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4961\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.6931 - acc: 0.5009 - val_loss: 0.6930 - val_acc: 0.4961\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 8s 253ms/step - loss: 0.6933 - acc: 0.4763 - val_loss: 0.6931 - val_acc: 0.4961\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 8s 228ms/step - loss: 0.6932 - acc: 0.4896 - val_loss: 0.6931 - val_acc: 0.5039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n",
      "AUC: 0.750092\n",
      "ACC: 0.459459\n",
      "MCC : 0.000000\n",
      "TPR:1.000000\n",
      "FPR:1.000000\n",
      "Pre:0.459459\n",
      "F1:0.629630\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 19s 561ms/step - loss: 0.7060 - acc: 0.5180 - val_loss: 0.7161 - val_acc: 0.4453\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6930 - acc: 0.4905 - val_loss: 0.6934 - val_acc: 0.4453\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.6936 - acc: 0.5104 - val_loss: 0.6936 - val_acc: 0.4453\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 247ms/step - loss: 0.6929 - acc: 0.5085 - val_loss: 0.6911 - val_acc: 0.5547\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 247ms/step - loss: 0.6957 - acc: 0.4991 - val_loss: 0.6944 - val_acc: 0.4453\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.6937 - acc: 0.5104 - val_loss: 0.6951 - val_acc: 0.4453\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 8s 242ms/step - loss: 0.6930 - acc: 0.5104 - val_loss: 0.6951 - val_acc: 0.4453\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 8s 240ms/step - loss: 0.6928 - acc: 0.4877 - val_loss: 0.6930 - val_acc: 0.5547\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.6929 - acc: 0.5057 - val_loss: 0.6931 - val_acc: 0.4922\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.6938 - acc: 0.5189 - val_loss: 0.6985 - val_acc: 0.4453\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.6945 - acc: 0.5076 - val_loss: 0.6961 - val_acc: 0.4453\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.6939 - acc: 0.4991 - val_loss: 0.6910 - val_acc: 0.5547\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6935 - acc: 0.5057 - val_loss: 0.6961 - val_acc: 0.4453\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.6932 - acc: 0.5104 - val_loss: 0.6950 - val_acc: 0.4453\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 0.6930 - acc: 0.5104 - val_loss: 0.6954 - val_acc: 0.4453\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 170ms/step - loss: 0.6930 - acc: 0.5114 - val_loss: 0.6935 - val_acc: 0.4453\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6929 - acc: 0.5114 - val_loss: 0.6941 - val_acc: 0.4453\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.6924 - acc: 0.5180 - val_loss: 0.6972 - val_acc: 0.4453\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 6s 194ms/step - loss: 0.6936 - acc: 0.5019 - val_loss: 0.6967 - val_acc: 0.4453\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6931 - acc: 0.5104 - val_loss: 0.6963 - val_acc: 0.4453\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6931 - acc: 0.5104 - val_loss: 0.6952 - val_acc: 0.4453\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6931 - acc: 0.5104 - val_loss: 0.6950 - val_acc: 0.4453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n",
      "AUC: 0.584847\n",
      "ACC: 0.533784\n",
      "MCC : 0.000000\n",
      "TPR:1.000000\n",
      "FPR:1.000000\n",
      "Pre:0.533784\n",
      "F1:0.696035\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 22s 663ms/step - loss: 0.7152 - acc: 0.5133 - val_loss: 0.6921 - val_acc: 0.5312\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 9s 261ms/step - loss: 0.6941 - acc: 0.5133 - val_loss: 0.6962 - val_acc: 0.4688\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.6938 - acc: 0.5133 - val_loss: 0.7039 - val_acc: 0.4688\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.6977 - acc: 0.4877 - val_loss: 0.6913 - val_acc: 0.5312\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 256ms/step - loss: 0.6943 - acc: 0.5066 - val_loss: 0.6919 - val_acc: 0.5742\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.6899 - acc: 0.5275 - val_loss: 0.6966 - val_acc: 0.4688\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6574 - acc: 0.6146 - val_loss: 0.6479 - val_acc: 0.6172\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.6708 - acc: 0.5956 - val_loss: 0.6509 - val_acc: 0.6562\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 192ms/step - loss: 0.6256 - acc: 0.6278 - val_loss: 0.6556 - val_acc: 0.6016\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 191ms/step - loss: 0.5899 - acc: 0.6629 - val_loss: 0.6370 - val_acc: 0.5898\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.4805 - acc: 0.7794 - val_loss: 0.5744 - val_acc: 0.6953\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.3436 - acc: 0.8561 - val_loss: 0.6346 - val_acc: 0.6562\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 193ms/step - loss: 0.3211 - acc: 0.8551 - val_loss: 0.5762 - val_acc: 0.7188\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 194ms/step - loss: 0.3352 - acc: 0.8409 - val_loss: 0.5725 - val_acc: 0.7031\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 193ms/step - loss: 0.2173 - acc: 0.9261 - val_loss: 0.6194 - val_acc: 0.7148\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 194ms/step - loss: 0.1774 - acc: 0.9384 - val_loss: 0.8204 - val_acc: 0.6406\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.2171 - acc: 0.9138 - val_loss: 0.6476 - val_acc: 0.7266\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.1609 - acc: 0.9413 - val_loss: 0.8975 - val_acc: 0.6367\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 6s 186ms/step - loss: 0.1950 - acc: 0.9233 - val_loss: 0.7335 - val_acc: 0.7109\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.1648 - acc: 0.9413 - val_loss: 0.6743 - val_acc: 0.7148\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.1304 - acc: 0.9517 - val_loss: 0.7053 - val_acc: 0.7188\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.1233 - acc: 0.9536 - val_loss: 0.9702 - val_acc: 0.6406\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 6s 187ms/step - loss: 0.1753 - acc: 0.9271 - val_loss: 0.7553 - val_acc: 0.7227\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 6s 182ms/step - loss: 0.1120 - acc: 0.9555 - val_loss: 0.7837 - val_acc: 0.7227\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.950868\n",
      "ACC: 0.851351\n",
      "MCC : 0.720463\n",
      "TPR:0.958904\n",
      "FPR:0.253333\n",
      "Pre:0.786517\n",
      "F1:0.864198\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 18s 541ms/step - loss: 0.7028 - acc: 0.4962 - val_loss: 0.6930 - val_acc: 0.4922\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 0.6952 - acc: 0.4981 - val_loss: 0.6926 - val_acc: 0.5078\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 0.6921 - acc: 0.5312 - val_loss: 0.6960 - val_acc: 0.5078\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.6949 - acc: 0.5189 - val_loss: 0.6929 - val_acc: 0.4922\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 0.6923 - acc: 0.5189 - val_loss: 0.6947 - val_acc: 0.4922\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6873 - acc: 0.5473 - val_loss: 0.6936 - val_acc: 0.5078\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.6952 - acc: 0.4811 - val_loss: 0.6927 - val_acc: 0.5078\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.6929 - acc: 0.4962 - val_loss: 0.6914 - val_acc: 0.5078\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 191ms/step - loss: 0.6933 - acc: 0.5085 - val_loss: 0.6934 - val_acc: 0.4922\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 192ms/step - loss: 0.6936 - acc: 0.4915 - val_loss: 0.6932 - val_acc: 0.4922\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 6s 188ms/step - loss: 0.6929 - acc: 0.5047 - val_loss: 0.6928 - val_acc: 0.4922\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 190ms/step - loss: 0.6958 - acc: 0.5019 - val_loss: 0.6933 - val_acc: 0.4922\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 193ms/step - loss: 0.6932 - acc: 0.5019 - val_loss: 0.6930 - val_acc: 0.4922\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.6932 - acc: 0.5114 - val_loss: 0.6929 - val_acc: 0.5078\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 196ms/step - loss: 0.6939 - acc: 0.4896 - val_loss: 0.6933 - val_acc: 0.4922\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.6947 - acc: 0.5047 - val_loss: 0.6932 - val_acc: 0.4922\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.6934 - acc: 0.5057 - val_loss: 0.6931 - val_acc: 0.5039\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 186ms/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6929 - val_acc: 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n",
      "AUC: 0.719101\n",
      "ACC: 0.601351\n",
      "MCC : 0.000000\n",
      "TPR:1.000000\n",
      "FPR:1.000000\n",
      "Pre:0.601351\n",
      "F1:0.751055\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 20s 596ms/step - loss: 0.7220 - acc: 0.5152 - val_loss: 0.6942 - val_acc: 0.4922\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.6958 - acc: 0.4943 - val_loss: 0.6930 - val_acc: 0.5078\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.6937 - acc: 0.4953 - val_loss: 0.6931 - val_acc: 0.4883\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 189ms/step - loss: 0.6932 - acc: 0.4991 - val_loss: 0.6930 - val_acc: 0.5469\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.6929 - acc: 0.5161 - val_loss: 0.6938 - val_acc: 0.4922\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 186ms/step - loss: 0.6938 - acc: 0.4896 - val_loss: 0.6937 - val_acc: 0.4922\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.6917 - acc: 0.5312 - val_loss: 0.6882 - val_acc: 0.4961\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.6745 - acc: 0.5786 - val_loss: 0.6612 - val_acc: 0.6406\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 187ms/step - loss: 0.6003 - acc: 0.6847 - val_loss: 0.5917 - val_acc: 0.6484\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.5236 - acc: 0.7367 - val_loss: 0.5906 - val_acc: 0.6875\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 5s 166ms/step - loss: 0.4183 - acc: 0.8134 - val_loss: 0.5364 - val_acc: 0.6992\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.3294 - acc: 0.8608 - val_loss: 0.6367 - val_acc: 0.6836\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.3486 - acc: 0.8390 - val_loss: 0.9238 - val_acc: 0.6367\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.3666 - acc: 0.8343 - val_loss: 0.5486 - val_acc: 0.7305\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 182ms/step - loss: 0.2022 - acc: 0.9356 - val_loss: 0.6064 - val_acc: 0.7266\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 192ms/step - loss: 0.1627 - acc: 0.9309 - val_loss: 0.7731 - val_acc: 0.7031\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 193ms/step - loss: 0.1967 - acc: 0.9261 - val_loss: 0.6175 - val_acc: 0.7461\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 192ms/step - loss: 0.2169 - acc: 0.9053 - val_loss: 0.6085 - val_acc: 0.7461\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 6s 191ms/step - loss: 0.1160 - acc: 0.9545 - val_loss: 0.6673 - val_acc: 0.7305\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 6s 194ms/step - loss: 0.1452 - acc: 0.9451 - val_loss: 0.9451 - val_acc: 0.6758\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 6s 187ms/step - loss: 0.0989 - acc: 0.9640 - val_loss: 0.7240 - val_acc: 0.7500\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.935662\n",
      "ACC: 0.858108\n",
      "MCC : 0.722474\n",
      "TPR:0.812500\n",
      "FPR:0.088235\n",
      "Pre:0.915493\n",
      "F1:0.860927\n",
      "--------------------------\n",
      "\n",
      "mean AUC: 0.814560\n",
      "mean ACC: 0.693117\n",
      "mean MCC : 0.393630\n",
      "mean TPR:0.865027\n",
      "mean FPR:0.477500\n",
      "mean Pre:0.718258\n",
      "mean F1:0.752187\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 18s 558ms/step - loss: 0.7159 - acc: 0.4839 - val_loss: 0.6957 - val_acc: 0.4648\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.6942 - acc: 0.4972 - val_loss: 0.6989 - val_acc: 0.4648\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.6928 - acc: 0.5199 - val_loss: 0.6914 - val_acc: 0.5625\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 186ms/step - loss: 0.6905 - acc: 0.5379 - val_loss: 0.7030 - val_acc: 0.4648\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 186ms/step - loss: 0.6952 - acc: 0.5057 - val_loss: 0.6919 - val_acc: 0.5625\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.6931 - acc: 0.5199 - val_loss: 0.6961 - val_acc: 0.4648\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 179ms/step - loss: 0.6913 - acc: 0.5436 - val_loss: 0.6875 - val_acc: 0.5352\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 186ms/step - loss: 0.6423 - acc: 0.6506 - val_loss: 0.6172 - val_acc: 0.6289\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.5356 - acc: 0.7405 - val_loss: 0.5873 - val_acc: 0.6484\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.4225 - acc: 0.8125 - val_loss: 0.5626 - val_acc: 0.6953\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.3326 - acc: 0.8722 - val_loss: 0.7141 - val_acc: 0.6094\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 182ms/step - loss: 0.2976 - acc: 0.8788 - val_loss: 0.6432 - val_acc: 0.6797\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.3043 - acc: 0.8608 - val_loss: 1.2214 - val_acc: 0.5430\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.3443 - acc: 0.8589 - val_loss: 0.7845 - val_acc: 0.6016\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 179ms/step - loss: 0.2011 - acc: 0.9242 - val_loss: 0.7136 - val_acc: 0.6836\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.1669 - acc: 0.9384 - val_loss: 0.9070 - val_acc: 0.6211\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 179ms/step - loss: 0.1955 - acc: 0.9100 - val_loss: 0.6608 - val_acc: 0.6953\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.1766 - acc: 0.9318 - val_loss: 0.7439 - val_acc: 0.6875\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.0986 - acc: 0.9659 - val_loss: 0.9008 - val_acc: 0.6797\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 6s 188ms/step - loss: 0.1369 - acc: 0.9498 - val_loss: 0.8587 - val_acc: 0.6914\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.938300\n",
      "ACC: 0.880000\n",
      "MCC : 0.763988\n",
      "TPR:0.824324\n",
      "FPR:0.065789\n",
      "Pre:0.924242\n",
      "F1:0.871429\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 21s 625ms/step - loss: 0.7144 - acc: 0.4886 - val_loss: 0.6945 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.6934 - acc: 0.5208 - val_loss: 0.6956 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.6927 - acc: 0.5322 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6967 - acc: 0.4934 - val_loss: 0.6929 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.6916 - acc: 0.5085 - val_loss: 0.6897 - val_acc: 0.5039\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 5s 165ms/step - loss: 0.6982 - acc: 0.5028 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6928 - acc: 0.5256 - val_loss: 0.6941 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.6943 - acc: 0.5076 - val_loss: 0.6917 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6849 - acc: 0.6231 - val_loss: 0.6805 - val_acc: 0.5977\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.6742 - acc: 0.5568 - val_loss: 0.6766 - val_acc: 0.5820\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.6310 - acc: 0.6373 - val_loss: 0.6305 - val_acc: 0.6250\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 179ms/step - loss: 0.5469 - acc: 0.7263 - val_loss: 0.6234 - val_acc: 0.6094\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.5287 - acc: 0.7197 - val_loss: 0.6270 - val_acc: 0.6484\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.4903 - acc: 0.7708 - val_loss: 0.7760 - val_acc: 0.5547\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.4390 - acc: 0.8049 - val_loss: 0.6702 - val_acc: 0.6094\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 170ms/step - loss: 0.4234 - acc: 0.8125 - val_loss: 0.7767 - val_acc: 0.5664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.3691 - acc: 0.8390 - val_loss: 0.7087 - val_acc: 0.5898\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.3511 - acc: 0.8551 - val_loss: 0.7588 - val_acc: 0.5781\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.3457 - acc: 0.8523 - val_loss: 0.7235 - val_acc: 0.5859\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.3498 - acc: 0.8381 - val_loss: 0.8635 - val_acc: 0.6016\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 0.3557 - acc: 0.8438 - val_loss: 0.7568 - val_acc: 0.6523\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 0.3235 - acc: 0.8608 - val_loss: 0.7448 - val_acc: 0.6055\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.875112\n",
      "ACC: 0.793333\n",
      "MCC : 0.589668\n",
      "TPR:0.666667\n",
      "FPR:0.098765\n",
      "Pre:0.851852\n",
      "F1:0.747967\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 19s 583ms/step - loss: 0.7124 - acc: 0.5057 - val_loss: 0.6995 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 187ms/step - loss: 0.6986 - acc: 0.4508 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 187ms/step - loss: 0.6945 - acc: 0.5180 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 182ms/step - loss: 0.6924 - acc: 0.5436 - val_loss: 0.6921 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.6881 - acc: 0.5294 - val_loss: 0.6924 - val_acc: 0.5039\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.6909 - acc: 0.5237 - val_loss: 0.6849 - val_acc: 0.6367\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 186ms/step - loss: 0.6471 - acc: 0.6174 - val_loss: 0.6450 - val_acc: 0.6172\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.5879 - acc: 0.7017 - val_loss: 0.6066 - val_acc: 0.7070\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.5295 - acc: 0.7131 - val_loss: 0.8188 - val_acc: 0.5156\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.5993 - acc: 0.6742 - val_loss: 0.6017 - val_acc: 0.7109\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.3967 - acc: 0.8333 - val_loss: 0.6045 - val_acc: 0.7266\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.3084 - acc: 0.8646 - val_loss: 0.8472 - val_acc: 0.5820\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.3247 - acc: 0.8598 - val_loss: 0.8900 - val_acc: 0.5781\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.2531 - acc: 0.8949 - val_loss: 0.7130 - val_acc: 0.6445\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.1791 - acc: 0.9309 - val_loss: 0.7479 - val_acc: 0.6719\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 179ms/step - loss: 0.1678 - acc: 0.9394 - val_loss: 0.6538 - val_acc: 0.7227\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 187ms/step - loss: 0.1393 - acc: 0.9479 - val_loss: 0.6966 - val_acc: 0.7109\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.2668 - acc: 0.8883 - val_loss: 0.5738 - val_acc: 0.7227\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.1682 - acc: 0.9356 - val_loss: 0.6316 - val_acc: 0.7188\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.1156 - acc: 0.9593 - val_loss: 0.6858 - val_acc: 0.7227\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.1884 - acc: 0.9214 - val_loss: 0.6721 - val_acc: 0.7227\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.1256 - acc: 0.9498 - val_loss: 0.6716 - val_acc: 0.7227\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 5s 166ms/step - loss: 0.2356 - acc: 0.9044 - val_loss: 1.1019 - val_acc: 0.5820\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 6s 179ms/step - loss: 0.2130 - acc: 0.9205 - val_loss: 0.6144 - val_acc: 0.7344\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0949 - acc: 0.9640 - val_loss: 0.6951 - val_acc: 0.7266\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.1237 - acc: 0.9432 - val_loss: 0.7468 - val_acc: 0.7227\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0875 - acc: 0.9669 - val_loss: 0.8105 - val_acc: 0.7148\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.0822 - acc: 0.9725 - val_loss: 0.7658 - val_acc: 0.7305\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.944475\n",
      "ACC: 0.898649\n",
      "MCC : 0.797296\n",
      "TPR:0.890411\n",
      "FPR:0.093333\n",
      "Pre:0.902778\n",
      "F1:0.896552\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 20s 597ms/step - loss: 0.7101 - acc: 0.4839 - val_loss: 0.6927 - val_acc: 0.5156\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.6938 - acc: 0.5047 - val_loss: 0.6902 - val_acc: 0.5391\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6897 - acc: 0.5170 - val_loss: 0.6837 - val_acc: 0.5781\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.6861 - acc: 0.5473 - val_loss: 0.6923 - val_acc: 0.4727\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6446 - acc: 0.6042 - val_loss: 0.6213 - val_acc: 0.6367\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.6227 - acc: 0.6780 - val_loss: 0.6914 - val_acc: 0.4844\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.4935 - acc: 0.7453 - val_loss: 0.5958 - val_acc: 0.6172\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.4900 - acc: 0.7528 - val_loss: 0.7011 - val_acc: 0.5547\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 182ms/step - loss: 0.3575 - acc: 0.8532 - val_loss: 0.5775 - val_acc: 0.7188\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.3723 - acc: 0.8248 - val_loss: 0.7307 - val_acc: 0.5625\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.2879 - acc: 0.8864 - val_loss: 0.7077 - val_acc: 0.6133\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 182ms/step - loss: 0.2123 - acc: 0.9110 - val_loss: 0.6245 - val_acc: 0.6875\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.2518 - acc: 0.8845 - val_loss: 0.5769 - val_acc: 0.7227\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.1790 - acc: 0.9290 - val_loss: 0.7165 - val_acc: 0.6484\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 182ms/step - loss: 0.1689 - acc: 0.9337 - val_loss: 0.8482 - val_acc: 0.7070\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.2374 - acc: 0.8968 - val_loss: 0.7236 - val_acc: 0.6445\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.1245 - acc: 0.9555 - val_loss: 0.7297 - val_acc: 0.7070\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 182ms/step - loss: 0.1417 - acc: 0.9489 - val_loss: 0.8732 - val_acc: 0.7188\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.2738 - acc: 0.8845 - val_loss: 0.8239 - val_acc: 0.5820\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 6s 179ms/step - loss: 0.2278 - acc: 0.9015 - val_loss: 0.6024 - val_acc: 0.7227\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.1553 - acc: 0.9432 - val_loss: 0.6718 - val_acc: 0.7227\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.2526 - acc: 0.8958 - val_loss: 0.6097 - val_acc: 0.7070\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.0882 - acc: 0.9782 - val_loss: 0.7790 - val_acc: 0.7188\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.951935\n",
      "ACC: 0.864865\n",
      "MCC : 0.741131\n",
      "TPR:0.797468\n",
      "FPR:0.057971\n",
      "Pre:0.940299\n",
      "F1:0.863014\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 22s 652ms/step - loss: 0.7093 - acc: 0.4820 - val_loss: 0.6951 - val_acc: 0.4531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "33/33 [==============================] - 5s 167ms/step - loss: 0.6942 - acc: 0.5246 - val_loss: 0.6975 - val_acc: 0.4531\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.6944 - acc: 0.5161 - val_loss: 0.6938 - val_acc: 0.4531\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.6942 - acc: 0.4943 - val_loss: 0.6963 - val_acc: 0.4531\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.6936 - acc: 0.5047 - val_loss: 0.6934 - val_acc: 0.4531\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.6913 - acc: 0.5284 - val_loss: 0.7042 - val_acc: 0.4531\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.6909 - acc: 0.5369 - val_loss: 0.6922 - val_acc: 0.4688\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.6809 - acc: 0.5720 - val_loss: 0.6786 - val_acc: 0.6289\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6294 - acc: 0.6515 - val_loss: 0.6083 - val_acc: 0.6875\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.5149 - acc: 0.7434 - val_loss: 0.6009 - val_acc: 0.7109\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.4799 - acc: 0.7812 - val_loss: 0.6421 - val_acc: 0.6484\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.4676 - acc: 0.7680 - val_loss: 0.5892 - val_acc: 0.7188\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.4248 - acc: 0.7973 - val_loss: 0.6163 - val_acc: 0.6875\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.4093 - acc: 0.8163 - val_loss: 0.7547 - val_acc: 0.6484\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.4293 - acc: 0.8153 - val_loss: 0.6040 - val_acc: 0.7227\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 0.3647 - acc: 0.8466 - val_loss: 0.6509 - val_acc: 0.7109\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 171ms/step - loss: 0.3863 - acc: 0.8371 - val_loss: 0.6349 - val_acc: 0.7188\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.4035 - acc: 0.8201 - val_loss: 0.6915 - val_acc: 0.6992\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.3582 - acc: 0.8532 - val_loss: 0.6489 - val_acc: 0.7188\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.3486 - acc: 0.8400 - val_loss: 0.6967 - val_acc: 0.7227\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.3726 - acc: 0.8314 - val_loss: 0.6412 - val_acc: 0.6992\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.3235 - acc: 0.8636 - val_loss: 0.6697 - val_acc: 0.7109\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.848652\n",
      "ACC: 0.756757\n",
      "MCC : 0.541293\n",
      "TPR:0.536232\n",
      "FPR:0.050633\n",
      "Pre:0.902439\n",
      "F1:0.672727\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 21s 641ms/step - loss: 0.7108 - acc: 0.5019 - val_loss: 0.6943 - val_acc: 0.4961\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.6943 - acc: 0.5038 - val_loss: 0.6936 - val_acc: 0.5039\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 182ms/step - loss: 0.6942 - acc: 0.4924 - val_loss: 0.6933 - val_acc: 0.4961\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.6954 - acc: 0.5057 - val_loss: 0.6929 - val_acc: 0.5039\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.6927 - acc: 0.5369 - val_loss: 0.6946 - val_acc: 0.4961\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.6946 - acc: 0.4848 - val_loss: 0.6930 - val_acc: 0.5039\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.6932 - acc: 0.5275 - val_loss: 0.6923 - val_acc: 0.5586\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.6921 - acc: 0.5218 - val_loss: 0.7007 - val_acc: 0.4961\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6949 - acc: 0.4981 - val_loss: 0.6931 - val_acc: 0.5039\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.6938 - acc: 0.5085 - val_loss: 0.6931 - val_acc: 0.5039\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 8s 231ms/step - loss: 0.6933 - acc: 0.4830 - val_loss: 0.6930 - val_acc: 0.5039\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 7s 212ms/step - loss: 0.6933 - acc: 0.4839 - val_loss: 0.6932 - val_acc: 0.4961\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 8s 254ms/step - loss: 0.6926 - acc: 0.5189 - val_loss: 0.6926 - val_acc: 0.5039\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.6918 - acc: 0.5019 - val_loss: 0.6933 - val_acc: 0.4961\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.6938 - acc: 0.4981 - val_loss: 0.6921 - val_acc: 0.5195\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 8s 255ms/step - loss: 0.6936 - acc: 0.5227 - val_loss: 0.6934 - val_acc: 0.4961\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.6924 - acc: 0.5009 - val_loss: 0.6823 - val_acc: 0.5508\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 8s 256ms/step - loss: 0.6911 - acc: 0.5180 - val_loss: 0.6918 - val_acc: 0.5195\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 8s 251ms/step - loss: 0.6853 - acc: 0.5549 - val_loss: 0.6831 - val_acc: 0.4961\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 8s 241ms/step - loss: 0.6038 - acc: 0.6667 - val_loss: 0.6457 - val_acc: 0.6211\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 6s 194ms/step - loss: 0.5554 - acc: 0.6979 - val_loss: 0.6279 - val_acc: 0.6406\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.4709 - acc: 0.7765 - val_loss: 0.6141 - val_acc: 0.6406\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.4358 - acc: 0.7898 - val_loss: 0.6219 - val_acc: 0.6562\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 6s 168ms/step - loss: 0.3955 - acc: 0.8419 - val_loss: 0.6908 - val_acc: 0.6211\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.3801 - acc: 0.8400 - val_loss: 0.6471 - val_acc: 0.6445\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.3426 - acc: 0.8570 - val_loss: 0.6715 - val_acc: 0.6484\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.4094 - acc: 0.8097 - val_loss: 0.6542 - val_acc: 0.6992\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 8s 237ms/step - loss: 0.3562 - acc: 0.8456 - val_loss: 0.6587 - val_acc: 0.6680\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 8s 238ms/step - loss: 0.3281 - acc: 0.8580 - val_loss: 0.6762 - val_acc: 0.6250\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.3427 - acc: 0.8485 - val_loss: 0.7084 - val_acc: 0.6758\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.3119 - acc: 0.8561 - val_loss: 0.6871 - val_acc: 0.6445\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 8s 237ms/step - loss: 0.3240 - acc: 0.8551 - val_loss: 0.7399 - val_acc: 0.6523\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.923991\n",
      "ACC: 0.844595\n",
      "MCC : 0.686042\n",
      "TPR:0.864198\n",
      "FPR:0.179104\n",
      "Pre:0.853659\n",
      "F1:0.858896\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 21s 639ms/step - loss: 0.7207 - acc: 0.4697 - val_loss: 0.6932 - val_acc: 0.4922\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 8s 228ms/step - loss: 0.6947 - acc: 0.5208 - val_loss: 0.6940 - val_acc: 0.4922\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 8s 238ms/step - loss: 0.6942 - acc: 0.5000 - val_loss: 0.6929 - val_acc: 0.5586\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 237ms/step - loss: 0.6930 - acc: 0.5227 - val_loss: 0.6917 - val_acc: 0.5078\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 239ms/step - loss: 0.6943 - acc: 0.5407 - val_loss: 0.6916 - val_acc: 0.5391\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.6820 - acc: 0.5634 - val_loss: 0.6948 - val_acc: 0.4922\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 8s 250ms/step - loss: 0.6714 - acc: 0.6259 - val_loss: 0.6694 - val_acc: 0.5703\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.5699 - acc: 0.7131 - val_loss: 0.6144 - val_acc: 0.6328\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 8s 247ms/step - loss: 0.4932 - acc: 0.7680 - val_loss: 0.6453 - val_acc: 0.6055\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.4446 - acc: 0.7822 - val_loss: 0.5708 - val_acc: 0.7031\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 8s 246ms/step - loss: 0.4074 - acc: 0.8134 - val_loss: 0.6993 - val_acc: 0.6055\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.3213 - acc: 0.8684 - val_loss: 0.5699 - val_acc: 0.7227\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 7s 209ms/step - loss: 0.2970 - acc: 0.8778 - val_loss: 0.7094 - val_acc: 0.6133\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.1930 - acc: 0.9271 - val_loss: 0.7745 - val_acc: 0.6406\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.2139 - acc: 0.9100 - val_loss: 0.6785 - val_acc: 0.7109\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 0.2381 - acc: 0.9072 - val_loss: 1.0561 - val_acc: 0.5508\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.2710 - acc: 0.8826 - val_loss: 0.6279 - val_acc: 0.7188\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 7s 203ms/step - loss: 0.1496 - acc: 0.9470 - val_loss: 0.7383 - val_acc: 0.7383\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.1434 - acc: 0.9394 - val_loss: 0.8315 - val_acc: 0.6758\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.1001 - acc: 0.9621 - val_loss: 1.0597 - val_acc: 0.6445\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 6s 185ms/step - loss: 0.0952 - acc: 0.9659 - val_loss: 0.8131 - val_acc: 0.7109\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 8s 234ms/step - loss: 0.0704 - acc: 0.9754 - val_loss: 0.8139 - val_acc: 0.7148\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.933333\n",
      "ACC: 0.878378\n",
      "MCC : 0.767360\n",
      "TPR:0.800000\n",
      "FPR:0.041096\n",
      "Pre:0.952381\n",
      "F1:0.869565\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 27s 807ms/step - loss: 0.7168 - acc: 0.5133 - val_loss: 0.6924 - val_acc: 0.5195\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.6957 - acc: 0.4697 - val_loss: 0.6934 - val_acc: 0.4805\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.6928 - acc: 0.5294 - val_loss: 0.6918 - val_acc: 0.4883\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 179ms/step - loss: 0.6785 - acc: 0.5625 - val_loss: 0.6887 - val_acc: 0.4922\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 5s 162ms/step - loss: 0.6301 - acc: 0.6383 - val_loss: 0.6334 - val_acc: 0.6875\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.5624 - acc: 0.7339 - val_loss: 0.6708 - val_acc: 0.5625\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 7s 223ms/step - loss: 0.5051 - acc: 0.7453 - val_loss: 0.5822 - val_acc: 0.7188\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.3456 - acc: 0.8466 - val_loss: 0.6246 - val_acc: 0.6562\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.3558 - acc: 0.8447 - val_loss: 0.5635 - val_acc: 0.7383\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.2601 - acc: 0.8892 - val_loss: 0.5892 - val_acc: 0.7227\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 7s 223ms/step - loss: 0.2220 - acc: 0.9091 - val_loss: 0.6230 - val_acc: 0.7305\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 8s 235ms/step - loss: 0.1694 - acc: 0.9384 - val_loss: 0.7506 - val_acc: 0.6797\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 8s 231ms/step - loss: 0.3035 - acc: 0.8712 - val_loss: 0.7086 - val_acc: 0.6172\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 8s 236ms/step - loss: 0.1693 - acc: 0.9337 - val_loss: 0.6799 - val_acc: 0.7188\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 8s 241ms/step - loss: 0.1497 - acc: 0.9413 - val_loss: 0.7544 - val_acc: 0.6953\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 8s 238ms/step - loss: 0.1059 - acc: 0.9631 - val_loss: 0.9712 - val_acc: 0.6250\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 8s 242ms/step - loss: 0.1467 - acc: 0.9413 - val_loss: 0.7281 - val_acc: 0.7617\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 8s 242ms/step - loss: 0.1625 - acc: 0.9375 - val_loss: 0.6940 - val_acc: 0.7305\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 8s 239ms/step - loss: 0.2061 - acc: 0.9157 - val_loss: 0.6202 - val_acc: 0.7578\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.969686\n",
      "ACC: 0.905405\n",
      "MCC : 0.811107\n",
      "TPR:0.891892\n",
      "FPR:0.081081\n",
      "Pre:0.916667\n",
      "F1:0.904110\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 24s 723ms/step - loss: 0.7123 - acc: 0.4972 - val_loss: 0.6983 - val_acc: 0.4531\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 6s 187ms/step - loss: 0.6944 - acc: 0.4991 - val_loss: 0.6947 - val_acc: 0.4531\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 6s 181ms/step - loss: 0.6934 - acc: 0.4886 - val_loss: 0.6985 - val_acc: 0.4531\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.6931 - acc: 0.5360 - val_loss: 0.6941 - val_acc: 0.4766\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 6s 184ms/step - loss: 0.6933 - acc: 0.5407 - val_loss: 0.6958 - val_acc: 0.4609\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 8s 234ms/step - loss: 0.6685 - acc: 0.5994 - val_loss: 0.6697 - val_acc: 0.5938\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 8s 250ms/step - loss: 0.6072 - acc: 0.6525 - val_loss: 0.6327 - val_acc: 0.6484\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 8s 248ms/step - loss: 0.6107 - acc: 0.6638 - val_loss: 0.7229 - val_acc: 0.4531\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 9s 259ms/step - loss: 0.5590 - acc: 0.7178 - val_loss: 0.6480 - val_acc: 0.6445\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 8s 254ms/step - loss: 0.5060 - acc: 0.7519 - val_loss: 0.6655 - val_acc: 0.6016\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 8s 254ms/step - loss: 0.4365 - acc: 0.8049 - val_loss: 0.6491 - val_acc: 0.6680\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 8s 252ms/step - loss: 0.4395 - acc: 0.7917 - val_loss: 0.6507 - val_acc: 0.6797\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 8s 249ms/step - loss: 0.4014 - acc: 0.8172 - val_loss: 0.6760 - val_acc: 0.6758\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.4332 - acc: 0.7955 - val_loss: 0.6648 - val_acc: 0.6836\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.3832 - acc: 0.8163 - val_loss: 0.6680 - val_acc: 0.6797\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 6s 177ms/step - loss: 0.4138 - acc: 0.8116 - val_loss: 0.6961 - val_acc: 0.6484\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 6s 168ms/step - loss: 0.3802 - acc: 0.8314 - val_loss: 0.8289 - val_acc: 0.5820\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.855314\n",
      "ACC: 0.770270\n",
      "MCC : 0.541583\n",
      "TPR:0.753247\n",
      "FPR:0.211268\n",
      "Pre:0.794521\n",
      "F1:0.773333\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 23s 690ms/step - loss: 0.6991 - acc: 0.5312 - val_loss: 0.6948 - val_acc: 0.4766\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 8s 241ms/step - loss: 0.6954 - acc: 0.5000 - val_loss: 0.6949 - val_acc: 0.4766\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 8s 237ms/step - loss: 0.6945 - acc: 0.5076 - val_loss: 0.6906 - val_acc: 0.5234\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.6960 - acc: 0.4953 - val_loss: 0.6933 - val_acc: 0.4766\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 8s 234ms/step - loss: 0.6933 - acc: 0.5076 - val_loss: 0.6943 - val_acc: 0.4766\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 6s 182ms/step - loss: 0.6933 - acc: 0.5076 - val_loss: 0.6940 - val_acc: 0.4766\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 6s 178ms/step - loss: 0.6933 - acc: 0.5076 - val_loss: 0.6936 - val_acc: 0.4766\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 6s 180ms/step - loss: 0.6935 - acc: 0.5076 - val_loss: 0.6941 - val_acc: 0.4766\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 6s 170ms/step - loss: 0.6935 - acc: 0.4886 - val_loss: 0.6941 - val_acc: 0.4766\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.6940 - acc: 0.5208 - val_loss: 0.6940 - val_acc: 0.4766\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 6s 178ms/step - loss: 0.6932 - acc: 0.5076 - val_loss: 0.6940 - val_acc: 0.4766\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 7s 218ms/step - loss: 0.6931 - acc: 0.5076 - val_loss: 0.6943 - val_acc: 0.4766\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 6s 179ms/step - loss: 0.6931 - acc: 0.5076 - val_loss: 0.6942 - val_acc: 0.4766\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.715749\n",
      "ACC: 0.479730\n",
      "MCC : 0.000000\n",
      "TPR:1.000000\n",
      "FPR:1.000000\n",
      "Pre:0.479730\n",
      "F1:0.648402\n",
      "--------------------------\n",
      "\n",
      "mean AUC: 0.895655\n",
      "mean ACC: 0.807198\n",
      "mean MCC : 0.623947\n",
      "mean TPR:0.802444\n",
      "mean FPR:0.187904\n",
      "mean Pre:0.851857\n",
      "mean F1:0.810599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "dataset_name = 'DM2'\n",
    "for rep in range(3):\n",
    "    n_splits = 10\n",
    "    TPRs =  np.zeros(n_splits)\n",
    "    FPRs = np.zeros(n_splits)\n",
    "    Precs = np.zeros(n_splits)\n",
    "    ACCs = np.zeros(n_splits)\n",
    "    F1s = np.zeros(n_splits)\n",
    "    MCCs = np.zeros(n_splits)\n",
    "    AUCs = np.zeros(n_splits)\n",
    "    count = 0\n",
    "    for split in range(n_splits):\n",
    "        train_pairs_file = 'CV/train'+str(rep)+'-'+str(split)\n",
    "        test_pairs_file = 'CV/test'+str(rep)+'-'+str(split)\n",
    "        valid_pairs_file = 'CV/valid'+str(rep)+'-'+str(split)\n",
    "\n",
    "        batch_size = 32\n",
    "        train_generator = DataGenerator(   train_pairs_file,batch_size = batch_size )\n",
    "        test_generator = DataGenerator(   test_pairs_file,batch_size = batch_size)\n",
    "        valid_generator = DataGenerator(   valid_pairs_file,batch_size = batch_size)\n",
    "         \n",
    "\n",
    "        model = build_model()\n",
    "        save_model_name = 'CV/seq'+str(rep)+'-'+str(split) + '.hdf5'\n",
    "        \n",
    "        earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "        save_checkpoint = ModelCheckpoint(save_model_name, save_best_only=True, monitor='val_loss', mode='min', save_weights_only=True)\n",
    "\n",
    "         \n",
    "        # validation_data = (valid_X, valid_Y),  verbose=1,callbacks=[earlyStopping, save_checkpoint]\n",
    "        hist = model.fit_generator(generator=train_generator,\n",
    "                    validation_data=valid_generator,\n",
    "                    epochs = 100,verbose=1,callbacks=[earlyStopping, save_checkpoint] )\n",
    "         \n",
    "        \n",
    "        # model = load_model(save_model_name)\n",
    "        model.load_weights(save_model_name)\n",
    "        with open(test_pairs_file, 'r') as f:\n",
    "            test_ppi_pairs  =  f.readlines()\n",
    "\n",
    "        test_len = len(test_ppi_pairs) \n",
    "        list_IDs_temp = np.arange(test_len)\n",
    "\n",
    "        test_x, y_test = test_generator.all_data(list_IDs_temp)\n",
    "\n",
    "        y_pred_prob = model.predict(test_x)\n",
    "\n",
    "       \n",
    "        y_pred = (y_pred_prob > 0.5)\n",
    "        auc = metrics.roc_auc_score(y_test, y_pred_prob) \n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        pre = precision_score(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        precision, recall, _thresholds = metrics.precision_recall_curve(y_test, y_pred_prob)\n",
    "        pr_auc = metrics.auc(recall, precision)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total=tn+fp+fn+tp\n",
    "        sen = float(tp)/float(tp+fn)\n",
    "        sps = float(tn)/float((tn+fp))\n",
    "\n",
    "        tpr = float(tp)/float(tp+fn)\n",
    "        fpr = float(fp)/float((tn+fp))\n",
    "        print('--------------------------\\n')\n",
    "        print ('AUC: %f' % auc)\n",
    "        print ('ACC: %f' % acc) \n",
    "        # print(\"PRAUC: %f\" % pr_auc)\n",
    "        print ('MCC : %f' % mcc)\n",
    "        # print ('SEN: %f' % sen)\n",
    "        # print ('SEP: %f' % sps)\n",
    "        print('TPR:%f'%tpr)\n",
    "        print('FPR:%f'%fpr)\n",
    "        print('Pre:%f'%pre)\n",
    "        print('F1:%f'%f1)\n",
    "        print('--------------------------\\n')\n",
    "        TPRs[count] = tpr\n",
    "        FPRs[count] = fpr\n",
    "        Precs[count] =pre\n",
    "        ACCs[count] =acc\n",
    "        F1s[count] =f1\n",
    "        MCCs[count] =mcc\n",
    "        AUCs[count] =auc\n",
    "        count += 1\n",
    "    print ('mean AUC: %f' % np.mean(AUCs))\n",
    "    print ('mean ACC: %f' % np.mean(ACCs)) \n",
    "    print ('mean MCC : %f' % np.mean(MCCs))\n",
    "    print('mean TPR:%f'% np.mean(TPRs))\n",
    "    print('mean FPR:%f'% np.mean(FPRs))\n",
    "    print('mean Pre:%f'% np.mean(Precs))\n",
    "    print('mean F1:%f'% np.mean(F1s))\n",
    "    np.savez('sp_seq_'+str(rep), AUCs=AUCs, ACCs=ACCs, MCCs=MCCs, TPRs = TPRs, FPRs=FPRs, Precs=Precs, F1s=F1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean AUC: 0.876276\n",
      "mean ACC: 0.781087\n",
      "mean MCC : 0.570536\n",
      "mean TPR:0.831707\n",
      "mean FPR:0.267178\n",
      "mean Pre:0.811130\n",
      "mean F1:0.800950\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "results1 =   np.load( 'sp_seq_0.npz')\n",
    "results2 =   np.load( 'sp_seq_1.npz')\n",
    "results3 =   np.load( 'sp_seq_2.npz')\n",
    "print ('mean AUC: %f' %  ( (np.mean( results1[ 'AUCs' ] )  + np.mean(  results2[ 'AUCs' ] )  + np.mean(results3[ 'AUCs' ]))/3     ) )\n",
    "print ('mean ACC: %f' %   ( (np.mean( results1[ 'ACCs' ] )  + np.mean(  results2[ 'ACCs' ] )  + np.mean(results3[ 'ACCs' ]))/3) )\n",
    "print ('mean MCC : %f' %  (  (np.mean( results1[ 'MCCs' ] )  + np.mean(  results2[ 'MCCs' ] )  + np.mean(results3[ 'MCCs' ])     )/3))\n",
    "print('mean TPR:%f'%    ((np.mean( results1[ 'TPRs' ] )  + np.mean(  results2[ 'TPRs' ] )  + np.mean(results3[ 'TPRs' ])     )/3))\n",
    "print('mean FPR:%f'%   ( (np.mean( results1[ 'FPRs' ] )  + np.mean(  results2[ 'FPRs' ] )  + np.mean(results3[ 'FPRs' ])     )/3))\n",
    "print('mean Pre:%f'%    ((np.mean( results1[ 'Precs' ] )  + np.mean(  results2[ 'Precs' ] )  + np.mean(results3[ 'Precs' ])     )/3))\n",
    "print('mean F1:%f'%    ((np.mean( results1[ 'F1s' ] )  + np.mean(  results2[ 'F1s' ] )  + np.mean(results3[ 'F1s' ])     )/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
