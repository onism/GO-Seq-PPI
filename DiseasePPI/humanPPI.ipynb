{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_name = 'PPI_dataset/Innate_Man/train.pos.19.txt'\n",
    "train_neg_name = 'PPI_dataset/Innate_Man/train.neg.19.txt'\n",
    "class PPI_Data():\n",
    "    def __init__(self, line, label):\n",
    "        self.p1, self.p2 = line.rstrip().split(' ')\n",
    "        self.label = label\n",
    "\n",
    "PPI_pairs = []\n",
    "with open(train_pos_name, 'r') as infile:\n",
    "    all_lines = infile.readlines()\n",
    "    for line in all_lines:\n",
    "        ppi_object = PPI_Data(line, 1)\n",
    "        PPI_pairs.append(ppi_object)\n",
    "\n",
    "with open(train_neg_name, 'r') as infile:\n",
    "    all_lines = infile.readlines()\n",
    "    for line in all_lines:\n",
    "        ppi_object = PPI_Data(line,0)\n",
    "        PPI_pairs.append(ppi_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_protein = []\n",
    "for ppi_object in PPI_pairs:\n",
    "    unique_protein.append(ppi_object.p1)\n",
    "    unique_protein.append(ppi_object.p2)\n",
    "\n",
    "unique_protein = list(set(unique_protein))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests, sys\n",
    "# import json\n",
    "# from tqdm import tqdm\n",
    "# ppi_go_terms = {}\n",
    "# remain_proteins = []\n",
    "# for uniprotid in tqdm(unique_protein):\n",
    "     \n",
    "#     requestURL = \"https://www.ebi.ac.uk/QuickGO/services/annotation/search?geneProductId=\"+uniprotid\n",
    "#     r = requests.get(requestURL, headers={ \"Accept\" : \"application/json\"})\n",
    "#     if r.ok:\n",
    "#         responseBody = r.text\n",
    "#         data=json.loads(responseBody)\n",
    "#         for k in data['results']: \n",
    "#             go_id = k['goId'] \n",
    "#             if  uniprotid not in ppi_go_terms.keys():\n",
    "#                 ppi_go_terms[uniprotid] = go_id\n",
    "#             else:\n",
    "#                 ppi_go_terms[uniprotid] = ppi_go_terms[uniprotid] + ';' + go_id\n",
    "#         if len(data['results']) == 0:\n",
    "#             remain_proteins.append(uniprotid)\n",
    "#     else:\n",
    "#         remain_proteins.append(uniprotid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from six.moves import cPickle as pickle #for performance\n",
    "\n",
    " \n",
    "def save_dict(di_, filename_):\n",
    "    with open(filename_, 'wb') as f:\n",
    "        pickle.dump(di_, f)\n",
    "\n",
    "def load_dict(filename_):\n",
    "    with open(filename_, 'rb') as f:\n",
    "        ret_di = pickle.load(f)\n",
    "    return ret_di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dict(ppi_go_terms, 'ppi_go_terms.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_go_terms = load_dict('ppi_go_terms.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ppi_pairs = []\n",
    "for ppi_obj in PPI_pairs:\n",
    "    if ppi_obj.p1 in ppi_go_terms.keys() and ppi_obj.p2 in ppi_go_terms.keys():\n",
    "        new_ppi_pairs.append(ppi_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "records = list(SeqIO.parse(\"Uniprot_human_protein_sequences.fasta\", \"fasta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_seqs = {}\n",
    "for seq_rec in records:\n",
    "    pid = seq_rec.id\n",
    "    seq = str(seq_rec.seq)\n",
    "    ppi_seqs[pid] = seq\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.layers import  GlobalAveragePooling1D, Input, Activation, MaxPooling1D, BatchNormalization, Dense, Dropout, Conv1D,GlobalMaxPooling1D\n",
    "from keras.layers import GRU,AveragePooling1D,CuDNNGRU\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model \n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "alphabet = np.array(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "                     'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y'])\n",
    "\n",
    "def label_sequence(line, MAX_SEQ_LEN, smi_ch_ind):\n",
    "\tX = np.zeros(MAX_SEQ_LEN)\n",
    "\n",
    "\tfor i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
    "\t\tX[i] = smi_ch_ind[ch]\n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "def letter_one_hot(aa):\n",
    "    one_hot = np.zeros(20)\n",
    "    for idx, letter in enumerate(alphabet):\n",
    "        if aa == letter:\n",
    "            one_hot[idx] = 1\n",
    "            return one_hot\n",
    "\n",
    "\n",
    "# Convert an entire protein to one-hot representation.\n",
    "def protein_one_hot(protein_sequence, MAX_SEQ_LEN):\n",
    "    #  Remove non-specific AA codes (very few are actually present in this dataset)\n",
    "    protein_sequence = protein_sequence.replace('B', '')\n",
    "    protein_sequence = protein_sequence.replace('J', '')\n",
    "    protein_sequence = protein_sequence.replace('O', '')\n",
    "    protein_sequence = protein_sequence.replace('U', '')\n",
    "    protein_sequence = protein_sequence.replace('X', '')\n",
    "    protein_sequence = protein_sequence.replace('Z', '')\n",
    "    one_hot_seq = np.zeros( (MAX_SEQ_LEN, 20))\n",
    "    for idx, aa in enumerate(protein_sequence[:MAX_SEQ_LEN]):\n",
    "        one_hot_seq[idx, :] = letter_one_hot(aa)\n",
    "    return one_hot_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "feature_len = 768\n",
    "max_go_len = 64\n",
    "max_seq_len = 1000\n",
    "\n",
    "prot2emb = {}\n",
    "for key, value in ppi_go_terms.items():\n",
    "    X_go1 =  np.zeros((1,768))\n",
    "    allgos = value.split(';') \n",
    "    allgos = list(set(allgos))\n",
    "    count = 0\n",
    "    for  go in  allgos:\n",
    "        if  os.path.exists('../ncbi_allfeatures4go/'+go+'_0.npy'):\n",
    "            feature = np.load('../ncbi_allfeatures4go/'+go+'_0.npy')[1:-1]\n",
    "        else:\n",
    "            feature = np.random.rand(1, 768)\n",
    "        if count + feature.shape[0] > max_go_len:\n",
    "            break\n",
    "        X_go1 = np.concatenate((X_go1,feature ))    \n",
    "        count += feature.shape[0]\n",
    "    prot2emb[key] =  X_go1[1:] \n",
    "protein2onehot = {}\n",
    "for key, value in ppi_seqs.items():\n",
    "    protein2onehot[key] =  protein_one_hot(value, max_seq_len)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K, initializers, regularizers, constraints\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        # todo: check that this is correct\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True,\n",
    "                 return_attention=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Note: The layer has been tested with Keras 1.x\n",
    "        Example:\n",
    "            # 1\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "            # next add a Dense layer (for classification/regression) or whatever...\n",
    "            # 2 - Get the attention scores\n",
    "            hidden = LSTM(64, return_sequences=True)(words)\n",
    "            sentence, word_scores = Attention(return_attention=True)(hidden)\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        weighted_input = x * K.expand_dims(a)\n",
    "\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [result, a]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], input_shape[-1]),\n",
    "                    (input_shape[0], input_shape[1])]\n",
    "        else:\n",
    "            return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 768)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 64, 768)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 64, 64)       147520      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 64, 64)       49216       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 64, 64)       147520      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 64, 64)       49216       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1000, 16)     976         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1000, 16)     336         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1000, 16)     976         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1000, 16)     336         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 64, 64)       20544       conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 64, 64)       12352       conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 64, 64)       147520      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 64, 64)       49216       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 64, 64)       20544       conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 64, 64)       12352       conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 64, 64)       147520      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 64, 64)       49216       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1000, 16)     1296        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1000, 16)     784         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1000, 16)     976         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1000, 16)     336         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1000, 16)     1296        conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1000, 16)     784         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1000, 16)     976         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1000, 16)     336         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 256)      0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 64, 128)      320256      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 256)      0           conv1d_8[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 64, 128)      320256      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 64)     0           conv1d_14[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 128)    33024       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 64)     0           conv1d_20[0][0]                  \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 128)    33024       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 256)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 128)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 256)      0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64, 128)      0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1000, 64)     0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000, 128)    0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 64)     0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000, 128)    0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 256)          320         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 128)          192         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 256)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 256)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 256)          320         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 128)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         (None, 128)          192         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 64)           0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 64)           0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         (None, 64)           1064        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 128)          0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 128)          0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         (None, 128)          1128        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 64)           0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 64)           0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         (None, 64)           1064        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 128)          0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 128)          0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         (None, 128)          1128        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1152)         0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 attention_1[0][0]                \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1152)         0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 attention_3[0][0]                \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 576)          0           global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 attention_5[0][0]                \n",
      "                                                                 global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 576)          0           global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 attention_7[0][0]                \n",
      "                                                                 global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          295168      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          295168      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          147712      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          147712      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 1024)         0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         1049600     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         1049600     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 1024)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          524800      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            513         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,084,385\n",
      "Trainable params: 5,084,385\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import   Embedding\n",
    "from keras.layers import  GRU, Bidirectional, CuDNNGRU, Lambda, Flatten\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.layers.merge import concatenate\n",
    "from keras_radam import RAdam\n",
    "from keras_lookahead import Lookahead\n",
    "\n",
    "\n",
    "def inception_block(input_tensor, output_size):\n",
    "    \"\"\"\"\"\"\n",
    "    con1d_filters = int(output_size/4)\n",
    "    y = Conv1D(con1d_filters, 3, activation=\"relu\", padding='same')(input_tensor)\n",
    "    x1 = Conv1D(con1d_filters, 5, activation=\"relu\", padding='same')(y)\n",
    "\n",
    "    y = Conv1D(con1d_filters, 1, activation=\"relu\", padding='valid')(input_tensor)\n",
    "    x2 = Conv1D(con1d_filters, 3, activation=\"relu\", padding='same')(y)\n",
    "\n",
    "    x3 = Conv1D(con1d_filters, 3, activation=\"relu\", padding='same')(input_tensor)\n",
    "    x4 = Conv1D(con1d_filters, 1, activation=\"relu\", padding='same')(input_tensor)\n",
    "\n",
    "    y = Concatenate()([x1, x2, x3, x4])\n",
    "#     y = MaxPooling1D(4)(mix0)\n",
    "    # y = AveragePooling1D()(mix0)\n",
    "#     y = BatchNormalization()(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def build_cnn_gru_model(input_x, con_filters, gru_units):\n",
    "    x = inception_block(input_x,con_filters )\n",
    "    x = Dropout(0.3)(x)\n",
    "    x_gru = Bidirectional(CuDNNGRU(gru_units, return_sequences=True))(input_x)\n",
    "    x_gru = Dropout(0.3)(x_gru)\n",
    "     \n",
    "    x_a = GlobalAveragePooling1D()(x)\n",
    "    x_b = GlobalMaxPooling1D()(x)\n",
    "    x_c = Attention()(x)\n",
    "    x_gru_a = GlobalAveragePooling1D()(x_gru)\n",
    "    x_gru_b = GlobalMaxPooling1D()(x_gru)\n",
    "    x_gru_c = Attention()(x_gru)\n",
    "    x = Concatenate()([x_a, x_b, x_c, x_gru_a, x_gru_b,   x_gru_c])\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    con_filters = 256\n",
    "    gru_units = 64\n",
    "    left_input_go = Input(shape=(max_go_len,feature_len))\n",
    "    right_input_go = Input(shape=(max_go_len,feature_len))\n",
    "    \n",
    "    \n",
    "    left_input_seq = Input(shape=(max_seq_len,20))\n",
    "    right_input_seq = Input(shape=(max_seq_len,20))\n",
    "    \n",
    "     \n",
    " \n",
    "     \n",
    "    left_x_go = build_cnn_gru_model(left_input_go, con_filters, gru_units)\n",
    "    right_x_go = build_cnn_gru_model(right_input_go, con_filters,gru_units)\n",
    "    \n",
    "    left_x_seq = build_cnn_gru_model(left_input_seq, con_filters//4, gru_units)\n",
    "    right_x_seq = build_cnn_gru_model(right_input_seq, con_filters//4, gru_units)\n",
    "     \n",
    "    \n",
    "   \n",
    "    x =   Concatenate()([left_x_go  , right_x_go, left_x_seq, right_x_seq])\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "  \n",
    "     \n",
    "    x = Dense(1)(x)\n",
    "    output = Activation('sigmoid')(x)\n",
    "    # model = Model([left_input_go, right_input_go], output)\n",
    "  \n",
    "    model = Model([left_input_go, right_input_go, left_input_seq, right_input_seq], output)\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "    optimizer = Lookahead(RAdam())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model_name = '../SC_CV/sc_GoplusSeq0-0.hdf5'\n",
    "# model.load_weights(save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_go_left = np.zeros((len(new_ppi_pairs), max_go_len, 768))\n",
    "X_seq_left = np.zeros((len(new_ppi_pairs), max_seq_len, 20))\n",
    "\n",
    "X_go_right = np.zeros((len(new_ppi_pairs), max_go_len, 768))\n",
    "X_seq_right = np.zeros((len(new_ppi_pairs), max_seq_len, 20))\n",
    "\n",
    "y = np.zeros((len(new_ppi_pairs),1))\n",
    "for i, ppi_obj in enumerate(new_ppi_pairs):\n",
    "    p1 = ppi_obj.p1\n",
    "    p2 = ppi_obj.p2\n",
    "    y[i] = ppi_obj.label\n",
    "    feature_left = prot2emb[p1]\n",
    "    X_go_left[i,:feature_left.shape[0]] = feature_left\n",
    "    \n",
    "    feature_right = prot2emb[p2]\n",
    "    X_go_right[i,:feature_right.shape[0]] = feature_right\n",
    "    \n",
    "    \n",
    "    X_seq_left[i] = protein2onehot[p1]\n",
    "    X_seq_right[i] = protein2onehot[p2]\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6796 samples, validate on 756 samples\n",
      "Epoch 1/100\n",
      "6796/6796 [==============================] - 31s 5ms/step - loss: 0.5573 - acc: 0.6979 - val_loss: 0.6903 - val_acc: 0.6243\n",
      "Epoch 2/100\n",
      "6796/6796 [==============================] - 19s 3ms/step - loss: 0.3534 - acc: 0.8451 - val_loss: 0.6977 - val_acc: 0.6640\n",
      "Epoch 3/100\n",
      "6796/6796 [==============================] - 19s 3ms/step - loss: 0.3003 - acc: 0.8696 - val_loss: 0.3189 - val_acc: 0.8624\n",
      "Epoch 4/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.2302 - acc: 0.9094 - val_loss: 1.0518 - val_acc: 0.5516\n",
      "Epoch 5/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.2154 - acc: 0.9161 - val_loss: 1.3873 - val_acc: 0.3598\n",
      "Epoch 6/100\n",
      "6796/6796 [==============================] - 19s 3ms/step - loss: 0.2006 - acc: 0.9211 - val_loss: 0.6313 - val_acc: 0.7077\n",
      "Epoch 7/100\n",
      "6796/6796 [==============================] - 19s 3ms/step - loss: 0.1538 - acc: 0.9382 - val_loss: 0.8969 - val_acc: 0.6111\n",
      "Epoch 8/100\n",
      "6796/6796 [==============================] - 19s 3ms/step - loss: 0.1364 - acc: 0.9453 - val_loss: 0.5036 - val_acc: 0.7698\n",
      "Epoch 9/100\n",
      "6796/6796 [==============================] - 19s 3ms/step - loss: 0.1546 - acc: 0.9351 - val_loss: 0.4133 - val_acc: 0.8161\n",
      "Epoch 10/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.1089 - acc: 0.9587 - val_loss: 0.2614 - val_acc: 0.8942\n",
      "Epoch 11/100\n",
      "6796/6796 [==============================] - 19s 3ms/step - loss: 0.0717 - acc: 0.9731 - val_loss: 0.9320 - val_acc: 0.6733\n",
      "Epoch 12/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.1153 - acc: 0.9592 - val_loss: 0.6066 - val_acc: 0.7553\n",
      "Epoch 13/100\n",
      "6796/6796 [==============================] - 19s 3ms/step - loss: 0.0523 - acc: 0.9806 - val_loss: 0.7792 - val_acc: 0.7196\n",
      "Epoch 14/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0465 - acc: 0.9841 - val_loss: 0.4814 - val_acc: 0.8241\n",
      "Epoch 15/100\n",
      "6796/6796 [==============================] - 19s 3ms/step - loss: 0.0931 - acc: 0.9650 - val_loss: 1.1151 - val_acc: 0.6310\n",
      "Epoch 16/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0542 - acc: 0.9810 - val_loss: 0.0953 - val_acc: 0.9537\n",
      "Epoch 17/100\n",
      "6796/6796 [==============================] - 19s 3ms/step - loss: 0.0657 - acc: 0.9750 - val_loss: 0.4292 - val_acc: 0.8452\n",
      "Epoch 18/100\n",
      "6796/6796 [==============================] - 19s 3ms/step - loss: 0.0245 - acc: 0.9916 - val_loss: 0.5274 - val_acc: 0.8280\n",
      "Epoch 19/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0463 - acc: 0.9825 - val_loss: 0.5297 - val_acc: 0.8201\n",
      "Epoch 20/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0498 - acc: 0.9813 - val_loss: 0.7932 - val_acc: 0.7434\n",
      "Epoch 21/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0191 - acc: 0.9938 - val_loss: 0.9022 - val_acc: 0.7381\n",
      "Epoch 22/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0265 - acc: 0.9910 - val_loss: 0.3650 - val_acc: 0.8704\n",
      "Epoch 23/100\n",
      "6796/6796 [==============================] - 17s 3ms/step - loss: 0.0367 - acc: 0.9862 - val_loss: 0.5409 - val_acc: 0.8175\n",
      "Epoch 24/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0360 - acc: 0.9882 - val_loss: 0.8921 - val_acc: 0.7063\n",
      "Epoch 25/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0177 - acc: 0.9940 - val_loss: 1.0550 - val_acc: 0.7262\n",
      "Epoch 26/100\n",
      "6796/6796 [==============================] - 17s 3ms/step - loss: 0.0251 - acc: 0.9907 - val_loss: 0.1688 - val_acc: 0.9418\n",
      "Epoch 27/100\n",
      "6796/6796 [==============================] - 17s 3ms/step - loss: 0.0699 - acc: 0.9751 - val_loss: 0.8192 - val_acc: 0.7407\n",
      "Epoch 28/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0310 - acc: 0.9887 - val_loss: 1.8096 - val_acc: 0.5701\n",
      "Epoch 29/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0644 - acc: 0.9772 - val_loss: 0.4887 - val_acc: 0.8056\n",
      "Epoch 30/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0149 - acc: 0.9963 - val_loss: 1.2647 - val_acc: 0.6892\n",
      "Epoch 31/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0209 - acc: 0.9928 - val_loss: 0.3399 - val_acc: 0.8929\n",
      "Epoch 32/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0120 - acc: 0.9956 - val_loss: 1.4452 - val_acc: 0.6878\n",
      "Epoch 33/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0088 - acc: 0.9974 - val_loss: 0.8646 - val_acc: 0.7989\n",
      "Epoch 34/100\n",
      "6796/6796 [==============================] - 17s 3ms/step - loss: 0.0315 - acc: 0.9893 - val_loss: 0.1283 - val_acc: 0.9524\n",
      "Epoch 35/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0347 - acc: 0.9869 - val_loss: 0.5428 - val_acc: 0.8373\n",
      "Epoch 36/100\n",
      "6796/6796 [==============================] - 18s 3ms/step - loss: 0.0142 - acc: 0.9946 - val_loss: 0.8132 - val_acc: 0.7976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c54124198>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_name = 'Innate_Man_19_2'\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=20, verbose=0, mode='max')\n",
    "save_checkpoint = ModelCheckpoint(save_model_name, save_best_only=True, monitor='val_acc', mode='max', save_weights_only=True)\n",
    "\n",
    "model.fit([X_go_left, X_go_right, X_seq_left, X_seq_right], y, epochs=100, batch_size=128, validation_split=0.1,callbacks=[earlyStopping, save_checkpoint])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_PPI_pairs = []\n",
    "all_test_protein = []\n",
    "with open('PPI_dataset/Innate_Man/test.pos.c1.19.txt', 'r') as infile:\n",
    "    all_lines = infile.readlines()\n",
    "    for line in all_lines:\n",
    "        p1,p2 = line.rstrip().split(' ')\n",
    "        ppi_obj = PPI_Data(line,1)\n",
    "        test_PPI_pairs.append(ppi_obj)\n",
    "        all_test_protein.append(p1)\n",
    "        all_test_protein.append(p2)\n",
    "with open('PPI_dataset/Innate_Man/test.neg.c1.19.txt', 'r') as infile:\n",
    "    all_lines = infile.readlines()\n",
    "    for line in all_lines:\n",
    "        p1,p2 = line.rstrip().split(' ')\n",
    "        ppi_obj = PPI_Data(line,0)\n",
    "        test_PPI_pairs.append(ppi_obj)\n",
    "        all_test_protein.append(p1)\n",
    "        all_test_protein.append(p2)\n",
    "    \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_test_protein = list(set(all_test_protein))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1198/1198 [25:02<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# import requests, sys\n",
    "# import json\n",
    "# from tqdm import tqdm\n",
    "# ppi_go_terms = {}\n",
    "# remain_proteins = []\n",
    "# for uniprotid in tqdm(unique_test_protein):\n",
    "     \n",
    "#     requestURL = \"https://www.ebi.ac.uk/QuickGO/services/annotation/search?geneProductId=\"+uniprotid\n",
    "#     r = requests.get(requestURL, headers={ \"Accept\" : \"application/json\"})\n",
    "#     if r.ok:\n",
    "#         responseBody = r.text\n",
    "#         data=json.loads(responseBody)\n",
    "#         for k in data['results']: \n",
    "#             go_id = k['goId'] \n",
    "#             if  uniprotid not in ppi_go_terms.keys():\n",
    "#                 ppi_go_terms[uniprotid] = go_id\n",
    "#             else:\n",
    "#                 ppi_go_terms[uniprotid] = ppi_go_terms[uniprotid] + ';' + go_id\n",
    "#         if len(data['results']) == 0:\n",
    "#             remain_proteins.append(uniprotid)\n",
    "#     else:\n",
    "#         remain_proteins.append(uniprotid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dict(ppi_go_terms, 'ppi_goterms_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_go_terms = load_dict('ppi_goterms_test.pkl')\n",
    "ppi_disease = load_dict('ppi_disease_terms_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1156/1156 [53:59<00:00,  2.80s/it] \n"
     ]
    }
   ],
   "source": [
    "# import requests, sys\n",
    "# import json\n",
    "# from tqdm import tqdm\n",
    "# ppi_disease_terms = {}\n",
    "# remain_proteins = []\n",
    "# for uniprotid in tqdm(ppi_go_terms.keys()):\n",
    "     \n",
    "#     requestURL = \"https://www.disgenet.org/api/gda/gene/uniprot/\"+uniprotid+\"?type=disease&format=json\"\n",
    "#     r = requests.get(requestURL, headers={ \"Accept\" : \"application/json\"})\n",
    "#     if r.ok:\n",
    "#         responseBody = r.text\n",
    "#         data=json.loads(responseBody)\n",
    "#         for k in  data: \n",
    "#             go_id = k['diseaseid'] \n",
    "#             if  uniprotid not in ppi_disease_terms.keys():\n",
    "#                 ppi_disease_terms[uniprotid] = go_id\n",
    "#             else:\n",
    "#                 ppi_disease_terms[uniprotid] = ppi_disease_terms[uniprotid] + ';' + go_id\n",
    "#         if len(data) == 0:\n",
    "#             remain_proteins.append(uniprotid)\n",
    "#     else:\n",
    "#         remain_proteins.append(uniprotid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dict(ppi_disease_terms, 'ppi_disease_terms_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_PPI_pairs = []\n",
    "for ppi_obj in test_PPI_pairs:\n",
    "    if ppi_obj.p1 in ppi_disease.keys() and ppi_obj.p2 in ppi_disease.keys() and ppi_obj.p1 in ppi_go_terms.keys() and ppi_obj.p2 in ppi_go_terms.keys():\n",
    "        new_test_PPI_pairs.append(ppi_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7552 575\n"
     ]
    }
   ],
   "source": [
    "print(len(new_ppi_pairs), len(new_test_PPI_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6841 4352 3775\n"
     ]
    }
   ],
   "source": [
    "all_prots = []\n",
    "pos_num = 0\n",
    "neg_num = 0\n",
    "for ppi_obj in new_ppi_pairs:\n",
    "    all_prots.append(ppi_obj.p1)\n",
    "    all_prots.append(ppi_obj.p2)\n",
    "    if ppi_obj.label == 1:\n",
    "        pos_num += 1\n",
    "    else:\n",
    "        neg_num += 1\n",
    "\n",
    "for ppi_obj in new_test_PPI_pairs:\n",
    "    all_prots.append(ppi_obj.p1)\n",
    "    all_prots.append(ppi_obj.p2)\n",
    "    if ppi_obj.label == 1:\n",
    "        pos_num += 1\n",
    "    else:\n",
    "        neg_num += 1\n",
    "print(len(set(all_prots)), pos_num,neg_num )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute jaccard_similarity\n",
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_jaccard = []\n",
    "neg_jaccard = []\n",
    "for ppi_obj in new_test_PPI_pairs:\n",
    " \n",
    "    p1_disease = ppi_disease[ppi_obj.p1].split(';')\n",
    "    p2_disease = ppi_disease[ppi_obj.p2].split(';')\n",
    "    jaccard_s = jaccard_similarity(p1_disease, p2_disease)\n",
    "    if ppi_obj.label == 1:\n",
    "        pos_jaccard.append(jaccard_s)\n",
    "    else:\n",
    "        neg_jaccard.append(jaccard_s)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05779666112444239 0.017382196855757384\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pos_jaccard = np.array(pos_jaccard)\n",
    "neg_jaccard = np.array(neg_jaccard)\n",
    "print(np.mean(pos_jaccard), np.mean(neg_jaccard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_len = 768\n",
    "max_go_len = 64\n",
    "max_seq_len = 1000\n",
    "\n",
    "prot2emb = {}\n",
    "for key, value in ppi_go_terms.items():\n",
    "    X_go1 =  np.zeros((1,768))\n",
    "    allgos = value.split(';') \n",
    "    allgos = list(set(allgos))\n",
    "    count = 0\n",
    "    for  go in  allgos:\n",
    "        if  os.path.exists('../ncbi_allfeatures4go/'+go+'_0.npy'):\n",
    "            feature = np.load('../ncbi_allfeatures4go/'+go+'_0.npy')[1:-1]\n",
    "        else:\n",
    "            feature = np.random.rand(1, 768)\n",
    "        if count + feature.shape[0] > max_go_len:\n",
    "            break\n",
    "        X_go1 = np.concatenate((X_go1,feature ))    \n",
    "        count += feature.shape[0]\n",
    "    prot2emb[key] =  X_go1[1:] \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_go_left = np.zeros((len(new_test_PPI_pairs), max_go_len, 768))\n",
    "X_seq_left = np.zeros((len(new_test_PPI_pairs), max_seq_len, 20))\n",
    "\n",
    "X_go_right = np.zeros((len(new_test_PPI_pairs), max_go_len, 768))\n",
    "X_seq_right = np.zeros((len(new_test_PPI_pairs), max_seq_len, 20))\n",
    "\n",
    "y = np.zeros((len(new_test_PPI_pairs),1))\n",
    "for i, ppi_obj in enumerate(new_test_PPI_pairs):\n",
    "    p1 = ppi_obj.p1\n",
    "    p2 = ppi_obj.p2\n",
    "    y[i] = ppi_obj.label\n",
    "    feature_left = prot2emb[p1]\n",
    "    X_go_left[i,:feature_left.shape[0]] = feature_left\n",
    "    \n",
    "    feature_right = prot2emb[p2]\n",
    "    X_go_right[i,:feature_right.shape[0]] = feature_right\n",
    "    \n",
    "    \n",
    "    X_seq_left[i] = protein2onehot[p1]\n",
    "    X_seq_right[i] = protein2onehot[p2]\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('Innate_Man_19_2')\n",
    "# model.load_weights('../SC_CV/sc_GoplusSeq1-0.hdf5')\n",
    "y_pred_prob = model.predict([X_go_left,X_go_right, X_seq_left, X_seq_right ], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9078260869565218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = (y_pred_prob > 0.5)\n",
    "acc = accuracy_score(y, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.argsort(y_pred_prob, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select worst 1%\n",
    "top20_len = 20 #int(np.floor(y_pred_prob.shape[0]*0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_top20_ind = ind[:top20_len]\n",
    "best_top20_ind = ind[y_pred_prob.shape[0]-top20_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predict_prob.txt', 'w') as wfile:\n",
    "    for i in range(ind.shape[0]):\n",
    "        index = ind[i]\n",
    "        ppi_obj = new_test_PPI_pairs[index[0]]\n",
    "        p1_disease = ppi_disease[ppi_obj.p1].split(';')\n",
    "        p2_disease = ppi_disease[ppi_obj.p2].split(';')\n",
    "        intersection = len(list(set(p1_disease).intersection(p2_disease)))\n",
    "        is_common = intersection > 0\n",
    "        wfile.writelines(ppi_obj.p1+';'+ppi_obj.p2+';'+str(len(p1_disease)) +';'+ str(len(p2_disease)) +';'+ str(ppi_obj.label)+';'+ str(y_pred_prob[index][0])+';'+str(intersection)+';'+str(is_common)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_probs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98517776\n",
      "0.828\n",
      "207\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top20_len = 250\n",
    "worst_top20_ind = ind[:top20_len]\n",
    "best_top20_ind = ind[y_pred_prob.shape[0]-top20_len:]\n",
    "best_top20_jaccard = 0\n",
    "for bi in best_top20_ind:\n",
    "    ppi_obj = new_test_PPI_pairs[bi[0]]\n",
    "    p1_disease = ppi_disease[ppi_obj.p1].split(';')\n",
    "    p2_disease = ppi_disease[ppi_obj.p2].split(';')\n",
    "    intersection = len(list(set(p1_disease).intersection(p2_disease)))\n",
    "    if intersection > 0:\n",
    "        best_top20_jaccard += 1\n",
    "    \n",
    "print(np.mean(y_pred_prob[best_top20_ind]))\n",
    "print(best_top20_jaccard/top20_len)\n",
    "print(best_top20_jaccard)\n",
    "    \n",
    "#     else:\n",
    "#         print(ppi_obj.p1, ppi_obj.p2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(best_top20_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0980835e-05\n",
      "0.2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "top20_len = 5\n",
    "worst_top20_ind = ind[:top20_len]\n",
    "\n",
    "worst_top20_jaccard = 0\n",
    "for bi in worst_top20_ind:\n",
    "    ppi_obj = new_test_PPI_pairs[bi[0]]\n",
    "    p1_disease = ppi_disease[ppi_obj.p1].split(';')\n",
    "    p2_disease = ppi_disease[ppi_obj.p2].split(';')\n",
    "    intersection = len(list(set(p1_disease).intersection(p2_disease)))\n",
    "    if intersection > 0:\n",
    "        worst_top20_jaccard += 1\n",
    "\n",
    "print(np.mean(y_pred_prob[worst_top20_ind]))\n",
    "print(worst_top20_jaccard/top20_len)\n",
    "print(worst_top20_jaccard)\n",
    "#     else:\n",
    "#         print(ppi_obj.p1, ppi_obj.p2)\n",
    "#     worst_top10_jaccard += jaccard_similarity(p1_disease, p2_disease)\n",
    "        \n",
    "#     best_top10_jaccard += jaccard_similarity(p1_disease, p2_disease)\n",
    "# print(best_top20_jaccard, worst_top20_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9799621269004444 8.951176678778831e-10\n"
     ]
    }
   ],
   "source": [
    "mean_probs = [0.9995886, 0.99943006, 0.9991978, 0.998612, 0.9972, 0.99172 , 0.985177 , 0.114573, 0.02742,\n",
    "              0.001659 , 0.000433, 9.042323e-05, 4.4602155e-05 , 2.0980835e-05]\n",
    "ppcds = [1, 0.9, 0.95, 0.84, 0.86, 0.82, 0.828, 0.424, 0.375, 0.29, 0.28, 0.2, 0.3, 0.2]\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    " \n",
    "r_row, p_value = pearsonr(mean_probs, ppcds)\n",
    "print(r_row, p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 115.0 575\n"
     ]
    }
   ],
   "source": [
    "print(best_top20_jaccard, y.shape[0]*0.2,  y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_top10_jaccard = 0\n",
    "for bi in worst_top10_ind:\n",
    "    ppi_obj = new_test_PPI_pairs[bi[0]]\n",
    "    p1_disease = ppi_disease[ppi_obj.p1].split(';')\n",
    "    p2_disease = ppi_disease[ppi_obj.p2].split(';')\n",
    "    worst_top10_jaccard += jaccard_similarity(p1_disease, p2_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056705748937831424 0.011323716207573458\n"
     ]
    }
   ],
   "source": [
    "print(best_top10_jaccard/top10_len, worst_top10_jaccard/top10_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_len = int(np.floor(y_pred_prob.shape[0]*0.2))\n",
    "worst_top20_ind = ind[:top20_len]\n",
    "best_top20_ind = ind[y_pred_prob.shape[0]-top20_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_top20_jaccard = 0\n",
    "for bi in best_top20_ind:\n",
    "    ppi_obj = new_test_PPI_pairs[bi[0]]\n",
    "    p1_disease = ppi_disease[ppi_obj.p1].split(';')\n",
    "    p2_disease = ppi_disease[ppi_obj.p2].split(';')\n",
    "    best_top20_jaccard += jaccard_similarity(p1_disease, p2_disease)\n",
    "worst_top20_jaccard = 0\n",
    "for bi in worst_top20_ind:\n",
    "    ppi_obj = new_test_PPI_pairs[bi[0]]\n",
    "    p1_disease = ppi_disease[ppi_obj.p1].split(';')\n",
    "    p2_disease = ppi_disease[ppi_obj.p2].split(';')\n",
    "    worst_top20_jaccard += jaccard_similarity(p1_disease, p2_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06034204469281473 0.011811925199367117\n"
     ]
    }
   ],
   "source": [
    "print(best_top20_jaccard/top20_len, worst_top20_jaccard/top20_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "top30_len = int(np.floor(y_pred_prob.shape[0]*0.3))\n",
    "worst_top30_ind = ind[:top30_len]\n",
    "best_top30_ind = ind[y_pred_prob.shape[0]-top30_len:]\n",
    "best_top30_jaccard = 0\n",
    "for bi in best_top30_ind:\n",
    "    ppi_obj = new_test_PPI_pairs[bi[0]]\n",
    "    p1_disease = ppi_disease[ppi_obj.p1].split(';')\n",
    "    p2_disease = ppi_disease[ppi_obj.p2].split(';')\n",
    "    best_top30_jaccard += jaccard_similarity(p1_disease, p2_disease)\n",
    "worst_top30_jaccard = 0\n",
    "for bi in worst_top30_ind:\n",
    "    ppi_obj = new_test_PPI_pairs[bi[0]]\n",
    "    p1_disease = ppi_disease[ppi_obj.p1].split(';')\n",
    "    p2_disease = ppi_disease[ppi_obj.p2].split(';')\n",
    "    worst_top30_jaccard += jaccard_similarity(p1_disease, p2_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06038744522127595 0.015712698183245187\n"
     ]
    }
   ],
   "source": [
    "print(best_top30_jaccard/top30_len, worst_top30_jaccard/top30_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
