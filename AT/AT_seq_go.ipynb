{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.layers import  GlobalAveragePooling1D, Input, Activation, MaxPooling1D, BatchNormalization, Dense, Dropout, Conv1D,GlobalMaxPooling1D\n",
    "from keras.layers import GRU,AveragePooling1D,CuDNNGRU\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model \n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "alphabet = np.array(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "                     'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y'])\n",
    "\n",
    "def label_sequence(line, MAX_SEQ_LEN, smi_ch_ind):\n",
    "\tX = np.zeros(MAX_SEQ_LEN)\n",
    "\n",
    "\tfor i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
    "\t\tX[i] = smi_ch_ind[ch]\n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "def letter_one_hot(aa):\n",
    "    one_hot = np.zeros(20)\n",
    "    for idx, letter in enumerate(alphabet):\n",
    "        if aa == letter:\n",
    "            one_hot[idx] = 1\n",
    "            return one_hot\n",
    "\n",
    "\n",
    "# Convert an entire protein to one-hot representation.\n",
    "def protein_one_hot(protein_sequence, MAX_SEQ_LEN):\n",
    "    #  Remove non-specific AA codes (very few are actually present in this dataset)\n",
    "    protein_sequence = protein_sequence.replace('B', '')\n",
    "    protein_sequence = protein_sequence.replace('J', '')\n",
    "    protein_sequence = protein_sequence.replace('O', '')\n",
    "    protein_sequence = protein_sequence.replace('U', '')\n",
    "    protein_sequence = protein_sequence.replace('X', '')\n",
    "    protein_sequence = protein_sequence.replace('Z', '')\n",
    "    one_hot_seq = np.zeros( (MAX_SEQ_LEN, 20))\n",
    "    for idx, aa in enumerate(protein_sequence[:MAX_SEQ_LEN]):\n",
    "        one_hot_seq[idx, :] = letter_one_hot(aa)\n",
    "    return one_hot_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "feature_len = 768\n",
    "max_go_len = 280\n",
    "max_seq_len = 1024\n",
    "\n",
    "from six.moves import cPickle as pickle #for performance\n",
    "\n",
    " \n",
    "def save_dict(di_, filename_):\n",
    "    with open(filename_, 'wb') as f:\n",
    "        pickle.dump(di_, f)\n",
    "\n",
    "def load_dict(filename_):\n",
    "    with open(filename_, 'rb') as f:\n",
    "        ret_di = pickle.load(f)\n",
    "    return ret_di\n",
    "\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self,  ppi_pair_file, batch_size=128):\n",
    "        'Initialization' \n",
    "        self.batch_size = batch_size\n",
    "        self.ppi_pair_file = ppi_pair_file\n",
    "         \n",
    "        self.max_seqlen = max_seq_len\n",
    "        self.max_golen = max_go_len\n",
    "        self.protein2go =  load_dict('ATprot2go.pkl')\n",
    "        self.protein2seq = load_dict('ATprot2seq.pkl')\n",
    "        self.read_ppi()\n",
    "        self.protein2onehot = {}\n",
    "        self.onehot_seqs()\n",
    "        self.prot2emb = {}\n",
    "        self.prot2embedding() \n",
    "         \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def read_ppi(self):\n",
    "        with open(self.ppi_pair_file, 'r') as f:\n",
    "            self.ppi_pairs  =  f.readlines()\n",
    "    \n",
    "    def onehot_seqs(self):\n",
    "        for key, value in self.protein2seq.items():\n",
    "            self.protein2onehot[key] =  protein_one_hot(value, self.max_seqlen) \n",
    "    \n",
    "    def prot2embedding(self):\n",
    "        for key, value in self.protein2go.items():\n",
    "            X_go1 =  np.zeros((1,768))\n",
    "            allgos = value.split(',') \n",
    "            allgos = list(set(allgos))\n",
    "            count = 0\n",
    "            for  go in  allgos:\n",
    "                if len(go) > 2:\n",
    "                    feature = np.load('../ncbi_allfeatures4go/'+go+'_0.npy')[1:-1]\n",
    "                else:\n",
    "                    feature = np.zeros((1,768))\n",
    "                if count + feature.shape[0] > max_go_len:\n",
    "                    break\n",
    "                X_go1 = np.concatenate((X_go1,feature ))    \n",
    "                count += feature.shape[0]   \n",
    "            self.prot2emb[key] =  X_go1[1:]   \n",
    "    \n",
    "   \n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.ppi_pairs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.ppi_pairs))\n",
    "         \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "\n",
    "         \n",
    "        X_seq1 = np.empty((self.batch_size, self.max_seqlen,20))\n",
    "        X_seq2 = np.empty((self.batch_size, self.max_seqlen,20))\n",
    "        y = np.empty((self.batch_size))\n",
    "        X_go1 = np.empty((self.batch_size, self.max_golen,768))\n",
    "        X_go2 = np.empty((self.batch_size, self.max_golen,768))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            ppi_pair = self.ppi_pairs[ID]\n",
    "            p1, p2, label = ppi_pair.rstrip().split('\\t')\n",
    "            if label == '+':\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "            X_seq1[i] =  self.protein2onehot[p1]\n",
    "            X_seq2[i] =  self.protein2onehot[p2]\n",
    "            \n",
    "            prot1emb = self.prot2emb[p1]\n",
    "            X_go1[i,:prot1emb.shape[0]] = prot1emb\n",
    "            \n",
    "            prot2emb = self.prot2emb[p2]\n",
    "            X_go2[i,:prot2emb.shape[0]] = prot2emb\n",
    "             \n",
    "            \n",
    "            \n",
    "        return [X_go1, X_go2,  X_seq1, X_seq2] ,  y\n",
    "\n",
    "\n",
    "\n",
    "    def all_data(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "\n",
    "         \n",
    "        X_seq1 = np.empty((len(list_IDs_temp), self.max_seqlen,20))\n",
    "\n",
    "         \n",
    "        X_seq2 = np.empty((len(list_IDs_temp), self.max_seqlen,20))\n",
    "        y = np.empty((len(list_IDs_temp)))\n",
    "        X_go1 = np.empty((len(list_IDs_temp), self.max_golen,768))\n",
    "        X_go2 = np.empty((len(list_IDs_temp), self.max_golen,768))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            ppi_pair = self.ppi_pairs[ID]\n",
    "            p1, p2, label = ppi_pair.rstrip().split('\\t')\n",
    "            if label == '+':\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "            X_seq1[i] =  self.protein2onehot[p1]\n",
    "            X_seq2[i] =  self.protein2onehot[p2]\n",
    "            \n",
    "            prot1emb = self.prot2emb[p1]\n",
    "            X_go1[i,:prot1emb.shape[0]] = prot1emb\n",
    "            \n",
    "            prot2emb = self.prot2emb[p2]\n",
    "            X_go2[i,:prot2emb.shape[0]] = prot2emb\n",
    "           \n",
    "        return [X_go1, X_go2,  X_seq1, X_seq2] ,  y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K, initializers, regularizers, constraints\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        # todo: check that this is correct\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True,\n",
    "                 return_attention=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Note: The layer has been tested with Keras 1.x\n",
    "        Example:\n",
    "            # 1\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "            # next add a Dense layer (for classification/regression) or whatever...\n",
    "            # 2 - Get the attention scores\n",
    "            hidden = LSTM(64, return_sequences=True)(words)\n",
    "            sentence, word_scores = Attention(return_attention=True)(hidden)\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        weighted_input = x * K.expand_dims(a)\n",
    "\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [result, a]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], input_shape[-1]),\n",
    "                    (input_shape[0], input_shape[1])]\n",
    "        else:\n",
    "            return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xhh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 280, 768)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 280, 768)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1024, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1024, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 280, 64)      147520      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 280, 64)      49216       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 280, 64)      147520      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 280, 64)      49216       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1024, 16)     976         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1024, 16)     336         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1024, 16)     976         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1024, 16)     336         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 280, 64)      20544       conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 280, 64)      12352       conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 280, 64)      147520      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 280, 64)      49216       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 280, 64)      20544       conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 280, 64)      12352       conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 280, 64)      147520      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 280, 64)      49216       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1024, 16)     1296        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1024, 16)     784         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1024, 16)     976         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1024, 16)     336         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1024, 16)     1296        conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1024, 16)     784         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1024, 16)     976         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1024, 16)     336         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 280, 256)     0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 280, 128)     320256      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 280, 256)     0           conv1d_8[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 280, 128)     320256      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1024, 64)     0           conv1d_14[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1024, 128)    33024       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1024, 64)     0           conv1d_20[0][0]                  \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1024, 128)    33024       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 280, 256)     0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 280, 128)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 280, 256)     0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 280, 128)     0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024, 64)     0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024, 128)    0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1024, 64)     0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1024, 128)    0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 256)          536         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 128)          408         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 256)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 256)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 256)          536         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 128)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         (None, 128)          408         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 64)           0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 64)           0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         (None, 64)           1088        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 128)          0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 128)          0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         (None, 128)          1152        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 64)           0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 64)           0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         (None, 64)           1088        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 128)          0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 128)          0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         (None, 128)          1152        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1152)         0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 attention_1[0][0]                \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1152)         0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 attention_3[0][0]                \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 576)          0           global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 attention_5[0][0]                \n",
      "                                                                 global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 576)          0           global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 attention_7[0][0]                \n",
      "                                                                 global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          295168      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          295168      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          147712      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          147712      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 1024)         0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         1049600     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         1049600     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 1024)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          524800      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            513         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,085,345\n",
      "Trainable params: 5,085,345\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import   Embedding\n",
    "from keras.layers import  GRU, Bidirectional, CuDNNGRU, Lambda, Flatten\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.layers.merge import concatenate\n",
    "from keras_radam import RAdam\n",
    "from keras_lookahead import Lookahead\n",
    "\n",
    "def inception_block(input_tensor, output_size):\n",
    "    \"\"\"\"\"\"\n",
    "    con1d_filters = int(output_size/4)\n",
    "    y = Conv1D(con1d_filters, 3, activation=\"relu\", padding='same')(input_tensor)\n",
    "    x1 = Conv1D(con1d_filters, 5, activation=\"relu\", padding='same')(y)\n",
    "\n",
    "    y = Conv1D(con1d_filters, 1, activation=\"relu\", padding='valid')(input_tensor)\n",
    "    x2 = Conv1D(con1d_filters, 3, activation=\"relu\", padding='same')(y)\n",
    "\n",
    "    x3 = Conv1D(con1d_filters, 3, activation=\"relu\", padding='same')(input_tensor)\n",
    "    x4 = Conv1D(con1d_filters, 1, activation=\"relu\", padding='same')(input_tensor)\n",
    "\n",
    "    y = Concatenate()([x1, x2, x3, x4])\n",
    "#     y = MaxPooling1D(4)(mix0)\n",
    "    # y = AveragePooling1D()(mix0)\n",
    "#     y = BatchNormalization()(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    " \n",
    "def build_cnn_gru_model(input_x, con_filters, gru_units):\n",
    "    x = inception_block(input_x,con_filters )\n",
    "    x = Dropout(0.3)(x)\n",
    "    x_gru = Bidirectional(CuDNNGRU(gru_units, return_sequences=True))(input_x)\n",
    "    x_gru = Dropout(0.3)(x_gru)\n",
    "     \n",
    "    x_a = GlobalAveragePooling1D()(x)\n",
    "    x_b = GlobalMaxPooling1D()(x)\n",
    "    x_c = Attention()(x)\n",
    "    x_gru_a = GlobalAveragePooling1D()(x_gru)\n",
    "    x_gru_b = GlobalMaxPooling1D()(x_gru)\n",
    "    x_gru_c = Attention()(x_gru)\n",
    "    x = Concatenate()([x_a, x_b, x_c, x_gru_a, x_gru_b,   x_gru_c])\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    return x\n",
    "\n",
    " \n",
    "\n",
    "def build_model():\n",
    "    con_filters = 256\n",
    "    gru_units = 64\n",
    "     \n",
    "    left_input_go = Input(shape=(max_go_len,feature_len))\n",
    "    right_input_go = Input(shape=(max_go_len,feature_len))\n",
    "    \n",
    "    \n",
    "    left_input_seq = Input(shape=(max_seq_len,20))\n",
    "    right_input_seq = Input(shape=(max_seq_len,20))\n",
    "    \n",
    "    left_x_go = build_cnn_gru_model(left_input_go, con_filters, gru_units)\n",
    "    right_x_go = build_cnn_gru_model(right_input_go, con_filters,gru_units)\n",
    "    \n",
    "    left_x_seq = build_cnn_gru_model(left_input_seq, con_filters//4, gru_units)\n",
    "    right_x_seq = build_cnn_gru_model(right_input_seq, con_filters//4, gru_units)\n",
    "    \n",
    "   \n",
    "   \n",
    "    x =   Concatenate()([left_x_go, right_x_go, left_x_seq, right_x_seq])\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "  \n",
    "     \n",
    "    x = Dense(1)(x)\n",
    "    output = Activation('sigmoid')(x)\n",
    "    # model = Model([left_input_go, right_input_go], output)\n",
    "  \n",
    "    model = Model([left_input_go, right_input_go, left_input_seq, right_input_seq], output)\n",
    "    optimizer = Lookahead(RAdam())\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n",
      "AUC: 0.995333\n",
      "ACC: 0.972727\n",
      "MCC : 0.945068\n",
      "TPR:0.983333\n",
      "FPR:0.040000\n",
      "Pre:0.967213\n",
      "F1:0.975207\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.989443\n",
      "ACC: 0.953704\n",
      "MCC : 0.904617\n",
      "TPR:0.940299\n",
      "FPR:0.024390\n",
      "Pre:0.984375\n",
      "F1:0.961832\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.983069\n",
      "ACC: 0.953704\n",
      "MCC : 0.907115\n",
      "TPR:0.977778\n",
      "FPR:0.063492\n",
      "Pre:0.916667\n",
      "F1:0.946237\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.988007\n",
      "ACC: 0.935185\n",
      "MCC : 0.866828\n",
      "TPR:0.888889\n",
      "FPR:0.031746\n",
      "Pre:0.952381\n",
      "F1:0.919540\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.973512\n",
      "ACC: 0.972222\n",
      "MCC : 0.944493\n",
      "TPR:0.980392\n",
      "FPR:0.035088\n",
      "Pre:0.961538\n",
      "F1:0.970874\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.975862\n",
      "ACC: 0.916667\n",
      "MCC : 0.834397\n",
      "TPR:0.896552\n",
      "FPR:0.060000\n",
      "Pre:0.945455\n",
      "F1:0.920354\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.966448\n",
      "ACC: 0.925926\n",
      "MCC : 0.851676\n",
      "TPR:0.915254\n",
      "FPR:0.061224\n",
      "Pre:0.947368\n",
      "F1:0.931034\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.853801\n",
      "ACC: 0.740741\n",
      "MCC : 0.493604\n",
      "TPR:0.823529\n",
      "FPR:0.333333\n",
      "Pre:0.688525\n",
      "F1:0.750000\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.990690\n",
      "ACC: 0.944444\n",
      "MCC : 0.889197\n",
      "TPR:0.931034\n",
      "FPR:0.040000\n",
      "Pre:0.964286\n",
      "F1:0.947368\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "\n",
      "AUC: 0.937217\n",
      "ACC: 0.916667\n",
      "MCC : 0.831044\n",
      "TPR:0.914894\n",
      "FPR:0.081967\n",
      "Pre:0.895833\n",
      "F1:0.905263\n",
      "--------------------------\n",
      "\n",
      "mean AUC: 0.965338\n",
      "mean ACC: 0.923199\n",
      "mean MCC : 0.846804\n",
      "mean TPR:0.925195\n",
      "mean FPR:0.077124\n",
      "mean Pre:0.922364\n",
      "mean F1:0.922771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "dataset_name = 'AT'\n",
    "for rep in range(2,3):\n",
    "    n_splits = 10\n",
    "    TPRs =  np.zeros(n_splits)\n",
    "    FPRs = np.zeros(n_splits)\n",
    "    Precs = np.zeros(n_splits)\n",
    "    ACCs = np.zeros(n_splits)\n",
    "    F1s = np.zeros(n_splits)\n",
    "    MCCs = np.zeros(n_splits)\n",
    "    AUCs = np.zeros(n_splits)\n",
    "     \n",
    "    count = 0\n",
    "    for split in range(n_splits):\n",
    "        train_pairs_file = 'CV/train'+str(rep)+'-'+str(split)\n",
    "        test_pairs_file = 'CV/test'+str(rep)+'-'+str(split)\n",
    "        valid_pairs_file = 'CV/valid'+str(rep)+'-'+str(split)\n",
    "\n",
    "        batch_size = 32\n",
    "        train_generator = DataGenerator(   train_pairs_file,batch_size = batch_size )\n",
    "        test_generator = DataGenerator(   test_pairs_file,batch_size = batch_size)\n",
    "        valid_generator = DataGenerator(   valid_pairs_file,batch_size = batch_size)\n",
    "         \n",
    "        # model = build_model_without_att()\n",
    "        model = build_model()\n",
    "        save_model_name = 'CV/GoplusSeq'+str(rep)+'-'+str(split) + '.hdf5'\n",
    "        \n",
    "        earlyStopping = EarlyStopping(monitor='val_acc', patience=20, verbose=0, mode='max')\n",
    "        save_checkpoint = ModelCheckpoint(save_model_name, save_best_only=True, monitor='val_acc', mode='max', save_weights_only=True)\n",
    "\n",
    "         \n",
    "        # validation_data = (valid_X, valid_Y),  verbose=1,callbacks=[earlyStopping, save_checkpoint]\n",
    "        #  max_queue_size=16, workers=8, use_multiprocessing=True,\n",
    "#         hist = model.fit_generator(generator=train_generator,\n",
    "#                     validation_data=valid_generator,\n",
    "#                     epochs = 100,verbose=1,callbacks=[earlyStopping, save_checkpoint] )\n",
    "         \n",
    "        \n",
    "        # model = load_model(save_model_name)\n",
    "        model.load_weights(save_model_name)\n",
    "        with open(test_pairs_file, 'r') as f:\n",
    "            test_ppi_pairs  =  f.readlines()\n",
    "\n",
    "        test_len = len(test_ppi_pairs) \n",
    "        list_IDs_temp = np.arange(test_len)\n",
    "\n",
    "        test_x, y_test = test_generator.all_data(list_IDs_temp)\n",
    "\n",
    "        y_pred_prob = model.predict(test_x)\n",
    "\n",
    "       \n",
    "        y_pred = (y_pred_prob > 0.5)\n",
    "        auc = metrics.roc_auc_score(y_test, y_pred_prob) \n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        pre = precision_score(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        precision, recall, _thresholds = metrics.precision_recall_curve(y_test, y_pred_prob)\n",
    "        pr_auc = metrics.auc(recall, precision)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total=tn+fp+fn+tp\n",
    "        sen = float(tp)/float(tp+fn)\n",
    "        sps = float(tn)/float((tn+fp))\n",
    "\n",
    "        tpr = float(tp)/float(tp+fn)\n",
    "        fpr = float(fp)/float((tn+fp))\n",
    "        print('--------------------------\\n')\n",
    "        print ('AUC: %f' % auc)\n",
    "        print ('ACC: %f' % acc) \n",
    "        # print(\"PRAUC: %f\" % pr_auc)\n",
    "        print ('MCC : %f' % mcc)\n",
    "        # print ('SEN: %f' % sen)\n",
    "        # print ('SEP: %f' % sps)\n",
    "        print('TPR:%f'%tpr)\n",
    "        print('FPR:%f'%fpr)\n",
    "        print('Pre:%f'%pre)\n",
    "        print('F1:%f'%f1)\n",
    "        print('--------------------------\\n')\n",
    "        TPRs[count] = tpr\n",
    "        FPRs[count] = fpr\n",
    "        Precs[count] =pre\n",
    "        ACCs[count] =acc\n",
    "        F1s[count] =f1\n",
    "        MCCs[count] =mcc\n",
    "        AUCs[count] =auc\n",
    "        count += 1\n",
    "        del test_x\n",
    "        del y_test\n",
    "    print ('mean AUC: %f' % np.mean(AUCs))\n",
    "    print ('mean ACC: %f' % np.mean(ACCs)) \n",
    "    print ('mean MCC : %f' % np.mean(MCCs))\n",
    "    print('mean TPR:%f'% np.mean(TPRs))\n",
    "    print('mean FPR:%f'% np.mean(FPRs))\n",
    "    print('mean Pre:%f'% np.mean(Precs))\n",
    "    print('mean F1:%f'% np.mean(F1s))\n",
    "    np.savez('seq_and_go__incep_'+str(rep), AUCs=AUCs, ACCs=ACCs, MCCs=MCCs, TPRs = TPRs, FPRs=FPRs, Precs=Precs, F1s=F1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean AUC: 0.971330\n",
      "mean ACC: 0.934338\n",
      "mean MCC : 0.869972\n",
      "mean TPR:0.935769\n",
      "mean FPR:0.065808\n",
      "mean Pre:0.933894\n",
      "mean F1:0.933725\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "results1 =   np.load( 'seq_and_go__incep_0.npz')\n",
    "results2 =   np.load( 'seq_and_go__incep_1.npz')\n",
    "results3 =   np.load( 'seq_and_go__incep_2.npz')\n",
    "print ('mean AUC: %f' %  ( (np.mean( results1[ 'AUCs' ] )  + np.mean(  results2[ 'AUCs' ] )  + np.mean(results3[ 'AUCs' ]))/3     ) )\n",
    "print ('mean ACC: %f' %   ( (np.mean( results1[ 'ACCs' ] )  + np.mean(  results2[ 'ACCs' ] )  + np.mean(results3[ 'ACCs' ]))/3) )\n",
    "print ('mean MCC : %f' %  (  (np.mean( results1[ 'MCCs' ] )  + np.mean(  results2[ 'MCCs' ] )  + np.mean(results3[ 'MCCs' ])     )/3))\n",
    "print('mean TPR:%f'%    ((np.mean( results1[ 'TPRs' ] )  + np.mean(  results2[ 'TPRs' ] )  + np.mean(results3[ 'TPRs' ])     )/3))\n",
    "print('mean FPR:%f'%   ( (np.mean( results1[ 'FPRs' ] )  + np.mean(  results2[ 'FPRs' ] )  + np.mean(results3[ 'FPRs' ])     )/3))\n",
    "print('mean Pre:%f'%    ((np.mean( results1[ 'Precs' ] )  + np.mean(  results2[ 'Precs' ] )  + np.mean(results3[ 'Precs' ])     )/3))\n",
    "print('mean F1:%f'%    ((np.mean( results1[ 'F1s' ] )  + np.mean(  results2[ 'F1s' ] )  + np.mean(results3[ 'F1s' ])     )/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
